This file is a merged representation of a subset of the codebase, containing specifically included files and files not matching ignore patterns, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: examples/**, src/**, tests/**, config.yaml
- Files matching these patterns are excluded: **\__pycache__
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
examples/
  __init__.py
  buggy_review_target.py
  README.md
  run_code_review_simulation.py
  run_controller_probe.py
  run_counting_conversation.py
  run_orchestrated_discussion.py
  run_three_agent_discussion.py
src/
  controllers/
    __init__.py
    claude_controller.py
    codex_controller.py
    gemini_controller.py
    qwen_controller.py
    session_backend.py
    tmux_controller.py
    tmux_controller.py.backup
  orchestrator/
    __init__.py
    context_manager.py
    conversation_manager.py
    message_router.py
    orchestrator.py
  utils/
    __init__.py
    auto_restart.py
    config_loader.py
    exceptions.py
    health_check.py
    logger.py
    output_parser.py
    path_helpers.py
    retry.py
  __init__.py
tests/
  run_parser_accuracy_test.py
  run_single_ai_wait_probe.py
  test_advanced_suite.py
  test_auto_restart.py
  test_automation_pause.py
  test_backend_refactor.py
  test_claude_refactored.py
  test_code_review_topic.py
  test_codex_startup.py
  test_config.py
  test_controller_auto.py
  test_controller.py
  test_conversation_manager.py
  test_counting_smoke.py
  test_dual_ai_observable.py
  test_dual_ai.py
  test_gemini_controller.py
  test_gemini_input.py
  test_gemini_manual.py
  test_gemini_output_parser.py
  test_health_check.py
  test_manual_together.py
  test_orchestrator_automation.py
  test_orchestrator_discussion_pause.py
  test_output_parser_cleanup.py
  test_output_parser.py
  test_qwen_standalone.py
  test_retry.py
  test_startup_detection.py
  test_tmux_controller_ready.py
config.yaml
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="src/utils/path_helpers.py">
"""
Path resolution helpers for orchestrator utilities and tests.

These helpers centralize how we locate the primary project directory and the
separate tmux/testing worktree so that individual scripts avoid hard-coded
absolute paths. Environment variables take precedence, falling back to values
defined in config.yaml, and ultimately to sensible defaults relative to the
repository root.
"""

from __future__ import annotations

import os
from pathlib import Path
from typing import Optional

from .config_loader import get_config

ENV_PROJECT_ROOT = "ORCHESTRATOR_PROJECT_ROOT"
ENV_TMUX_WORKTREE = "ORCHESTRATOR_TEST_DIR"


def _resolve_path(value: Optional[str]) -> Optional[Path]:
    """Expand environment variables and ~ in a configured path."""
    if not value:
        return None
    return Path(os.path.expanduser(os.path.expandvars(str(value)))).resolve()


def get_repo_root() -> Path:
    """
    Return the repository root path.

    Resolution order:
      1. Environment variable ORCHESTRATOR_PROJECT_ROOT
      2. config.yaml worktree.main_path
      3. Two levels up from this file (default repository layout)
    """
    env_value = os.getenv(ENV_PROJECT_ROOT)
    if env_value:
        resolved = _resolve_path(env_value)
        if resolved:
            return resolved

    config = get_config().get_section("worktree")
    configured = _resolve_path(config.get("main_path") if isinstance(config, dict) else None)
    if configured:
        return configured

    return Path(__file__).resolve().parents[2]


def get_tmux_worktree_path() -> Path:
    """
    Return the tmux/testing worktree path.

    Resolution order mirrors get_repo_root but uses ORCHESTRATOR_TEST_DIR
    and worktree.tmux_path. Defaults to the repository root when no override
    is provided.
    """
    env_value = os.getenv(ENV_TMUX_WORKTREE)
    if env_value:
        resolved = _resolve_path(env_value)
        if resolved:
            return resolved

    config = get_config().get_section("worktree")
    configured = _resolve_path(config.get("tmux_path") if isinstance(config, dict) else None)
    if configured:
        return configured

    return get_repo_root()


def ensure_directory(path: Path) -> Path:
    """
    Ensure a directory exists, returning the path.

    This is primarily a convenience for tests that need a writable location.
    """
    path.mkdir(parents=True, exist_ok=True)
    return path
</file>

<file path="examples/__init__.py">
"""Example orchestration scenarios and helper scripts."""

__all__ = []
</file>

<file path="examples/buggy_review_target.py">
"""Review target for the CLAUDE↔Gemini code review simulation."""

from __future__ import annotations


def find_max_in_range(numbers: list[int], start: int, end: int) -> int:
    """Return the maximum value between start and end indices in numbers."""

    max_val = numbers[start]
    for i in range(start, end):
        if numbers[i] > max_val:
            max_val = numbers[i]
    return max_val


__all__ = ["find_max_in_range"]
</file>

<file path="src/controllers/codex_controller.py">
"""
Codex CLI Controller

Provides Codex-specific defaults for the shared TmuxController. The Codex CLI
behaves similarly to Claude (Enter submits, standard prompt markers), so we
reuse the same mechanics but keep configuration isolated in case future builds
diverge.
"""

from typing import Optional

from .tmux_controller import TmuxController
from ..utils.config_loader import get_config


class CodexController(TmuxController):
    """Controller configured for the Codex CLI."""

    def __init__(
        self,
        session_name: Optional[str] = None,
        working_dir: Optional[str] = None,
    ):
        """
        Initialize CodexController with Codex-specific configuration.

        Args:
            session_name: Optional tmux session name (uses config default when omitted).
            working_dir: Working directory for the Codex process.
        """
        config = get_config()
        codex_config = config.get_section("codex")
        tmux_config = config.get_section("tmux")

        if session_name is None:
            session_name = tmux_config.get("codex_session", "codex")

        executable = codex_config.get("executable", "codex")
        executable_args = codex_config.get("executable_args", [])

        super().__init__(
            session_name=session_name,
            executable=executable,
            working_dir=working_dir,
            ai_config=codex_config,
            executable_args=executable_args,
        )

        self.response_marker = codex_config.get("response_marker", "▸")
</file>

<file path="src/controllers/qwen_controller.py">
"""
Qwen CLI Controller

Provides Qwen-specific defaults for the shared TmuxController. Qwen's CLI uses
an `(esc to cancel` loading indicator, so we rely on loading indicator clears
plus a configurable stabilization delay before submitting new input.
"""

from typing import Optional

from .tmux_controller import TmuxController
from ..utils.config_loader import get_config


class QwenController(TmuxController):
    """Controller configured for the Qwen CLI."""

    def __init__(
        self,
        session_name: Optional[str] = None,
        working_dir: Optional[str] = None,
    ):
        """
        Initialize QwenController with Qwen-specific configuration.

        Args:
            session_name: Optional tmux session name (defaults to config value).
            working_dir: Working directory for the Qwen process.
        """
        config = get_config()
        qwen_config = dict(config.get_section("qwen") or {})
        tmux_config = config.get_section("tmux")

        # Override for tmux reliability: Use C-m for consistent command submission
        # This enables the double-submit pattern (C-m + fallback Enter) which is
        # essential for complex/normalized multiline commands in orchestrated scenarios
        qwen_config["submit_key"] = "C-m"
        qwen_config["submit_fallback_keys"] = ["M-Enter", "C-m", "Enter", "C-j"]
        qwen_config["submit_retry_delay"] = 0.2
        qwen_config["text_enter_delay"] = 0.6
        qwen_config["post_text_delay"] = 0.0

        if session_name is None:
            session_name = tmux_config.get("qwen_session", "qwen")

        executable = qwen_config.get("executable", "qwen")
        executable_args = qwen_config.get("executable_args", [])

        super().__init__(
            session_name=session_name,
            executable=executable,
            working_dir=working_dir,
            ai_config=qwen_config,
            executable_args=executable_args,
        )

        self.response_marker = qwen_config.get("response_marker", "▸")
</file>

<file path="src/controllers/tmux_controller.py.backup">
"""
Tmux Controller for AI CLI Interaction

This module provides programmatic control over AI CLI tools
(Claude Code, Gemini CLI, etc.) running in tmux sessions.
"""

import subprocess
import time
import shutil
from typing import Optional, List, Dict, Any

from ..utils.exceptions import (
    SessionAlreadyExists,
    SessionDead,
    SessionUnresponsive,
    SessionStartupTimeout,
    CommandTimeout,
    ExecutableNotFound,
    TmuxNotFound,
    TmuxError
)
from ..utils.logger import get_logger
from ..utils.retry import retry_with_backoff, STANDARD_RETRY
from ..utils.health_check import HealthChecker
from ..utils.auto_restart import AutoRestarter, RestartPolicy


class TmuxController:
    """
    Controls AI CLI tools running in tmux sessions.

    AI-agnostic controller that works with any interactive CLI tool.
    AI-specific behaviors are configured via parameters.
    """

    def __init__(
        self,
        session_name: str,
        executable: str,
        working_dir: Optional[str] = None,
        ai_config: Optional[Dict[str, Any]] = None
    ):
        """
        Initialize TmuxController.

        Args:
            session_name: Name of the tmux session
            executable: Command to run (e.g., "claude", "gemini")
            working_dir: Working directory (defaults to current dir)
            ai_config: AI-specific configuration dictionary with:
                - startup_timeout: Seconds to wait for startup
                - response_timeout: Max seconds for responses
                - ready_check_interval: Seconds between ready checks
                - ready_stable_checks: Consecutive stable checks needed
                - ready_indicators: List of patterns indicating ready state
        """
        self.session_name = session_name
        self.executable = executable
        self.working_dir = working_dir or subprocess.check_output(
            ["pwd"], text=True
        ).strip()

        # Set up logging
        self.logger = get_logger(f"{__name__}.{session_name}")
        self.logger.info(f"Initializing TmuxController for {executable} in session {session_name}")

        # AI-specific configuration with defaults
        self.config = ai_config or {}
        self.startup_timeout = self.config.get('startup_timeout', 10)
        self.response_timeout = self.config.get('response_timeout', 30)
        self.ready_check_interval = self.config.get('ready_check_interval', 0.5)
        self.ready_stable_checks = self.config.get('ready_stable_checks', 3)
        self.ready_indicators = self.config.get('ready_indicators', [])

        # Verify environment on initialization
        self._verify_environment()

        # Initialize health checker
        self.health_checker = HealthChecker(
            check_interval=self.config.get('health_check_interval', 30.0),
            response_timeout=self.config.get('health_check_timeout', 5.0),
            max_failed_checks=self.config.get('max_failed_health_checks', 3)
        )

        # Initialize auto-restarter
        restart_policy_str = self.config.get('restart_policy', 'on_failure')
        try:
            restart_policy = RestartPolicy(restart_policy_str)
        except ValueError:
            self.logger.warning(f"Invalid restart_policy '{restart_policy_str}', using ON_FAILURE")
            restart_policy = RestartPolicy.ON_FAILURE

        self.auto_restarter = AutoRestarter(
            policy=restart_policy,
            max_restart_attempts=self.config.get('max_restart_attempts', 3),
            restart_window=self.config.get('restart_window', 300.0),
            initial_backoff=self.config.get('restart_initial_backoff', 5.0),
            max_backoff=self.config.get('restart_max_backoff', 60.0)
        )

    def _verify_environment(self):
        """
        Verify that required executables are available.

        Raises:
            TmuxNotFound: If tmux is not installed
            ExecutableNotFound: If AI executable is not in PATH
        """
        # Check tmux
        if not shutil.which('tmux'):
            self.logger.error("tmux not found in PATH")
            raise TmuxNotFound("tmux is not installed or not in PATH")

        # Check AI executable
        if not shutil.which(self.executable):
            self.logger.error(f"Executable '{self.executable}' not found in PATH")
            raise ExecutableNotFound(self.executable)

        self.logger.debug("Environment verification passed")

    @retry_with_backoff(max_attempts=2, initial_delay=0.5, exceptions=(TmuxError,))
    def _run_tmux_command(self, args: List[str]) -> subprocess.CompletedProcess:
        """
        Run a tmux command with error handling and automatic retry.

        Args:
            args: Command arguments to pass to tmux

        Returns:
            CompletedProcess result

        Raises:
            TmuxError: If tmux command fails unexpectedly after retries
        """
        cmd = ["tmux"] + args
        try:
            result = subprocess.run(cmd, capture_output=True, text=True)

            # Log tmux errors (but don't raise for expected failures like has-session)
            if result.returncode != 0 and result.stderr:
                self.logger.debug(f"tmux command returned {result.returncode}: {' '.join(args)}")
                self.logger.debug(f"stderr: {result.stderr.strip()}")

            return result
        except Exception as e:
            self.logger.error(f"Failed to run tmux command: {' '.join(args)}")
            self.logger.error(f"Error: {e}")
            raise TmuxError(f"Failed to execute tmux command: {e}", command=cmd)

    def session_exists(self) -> bool:
        """
        Check if the tmux session exists.

        Returns:
            True if session exists, False otherwise
        """
        result = self._run_tmux_command(["has-session", "-t", self.session_name])
        return result.returncode == 0

    def start_session(self, auto_confirm_trust: bool = True) -> bool:
        """
        Start AI CLI in a new tmux session.

        Args:
            auto_confirm_trust: Automatically confirm trust prompt (for Claude/Gemini)

        Returns:
            True if session started successfully

        Raises:
            SessionAlreadyExists: If session with this name already exists
            SessionStartupTimeout: If session fails to become ready in time
        """
        self.logger.info(f"Starting session '{self.session_name}'")

        if self.session_exists():
            self.logger.error(f"Session '{self.session_name}' already exists")
            raise SessionAlreadyExists(f"Session '{self.session_name}' already exists")

        # Create detached tmux session with AI executable
        self.logger.debug(f"Creating tmux session with executable: {self.executable}")
        result = self._run_tmux_command([
            "new-session",
            "-d",  # Detached
            "-s", self.session_name,  # Session name
            "-c", self.working_dir,  # Working directory
            self.executable  # Command to run (claude, gemini, etc.)
        ])

        if result.returncode != 0:
            self.logger.error(f"Failed to create tmux session: {result.stderr}")
            raise TmuxError(
                f"Failed to start session: {result.stderr}",
                command=["new-session"],
                return_code=result.returncode
            )

        # Wait for AI to start (brief initial wait for process to spawn)
        init_wait = self.config.get('init_wait', 3)
        self.logger.debug(f"Waiting {init_wait}s for AI process to spawn")
        time.sleep(init_wait)

        # Auto-confirm trust prompt if requested
        if auto_confirm_trust:
            self.logger.debug("Auto-confirming trust prompt")
            # Press Enter to confirm "Yes, proceed" (works for Claude/Gemini)
            self._run_tmux_command([
                "send-keys", "-t", self.session_name, "Enter"
            ])
            # Brief wait for Enter to be processed
            time.sleep(1)

        # Wait for AI to be fully ready (detect ready indicators)
        self.logger.debug("Waiting for AI to be fully ready...")
        if not self.wait_for_startup(timeout=self.startup_timeout):
            self.logger.error("AI failed to show ready indicators within timeout")
            raise SessionStartupTimeout(f"Session failed to be ready within {self.startup_timeout}s")

        # Stabilization delay after detecting ready indicator
        # Ensures input buffer is fully initialized and ready for first command
        # Critical for Gemini which can show prompt before buffer is ready
        stabilization_delay = 2.0 if self.executable == "gemini" else 1.0
        self.logger.debug(f"Ready indicator found, allowing input buffer to stabilize ({stabilization_delay}s)...")
        time.sleep(stabilization_delay)

        # Verify session is actually ready
        if not self.session_exists():
            self.logger.error("Session creation appeared to succeed but session doesn't exist")
            raise SessionStartupTimeout("Session failed to start properly")

        self.logger.info(f"Session '{self.session_name}' started successfully and ready")
        return True

    @retry_with_backoff(max_attempts=3, initial_delay=1.0, exceptions=(TmuxError,))
    def send_command(self, command: str, submit: bool = True) -> bool:
        """
        Send a command to AI CLI with automatic retry on transient failures.

        CRITICAL: Text and Enter must be sent separately to avoid multi-line input.

        Args:
            command: The text command to send
            submit: If True, send Enter to submit the command

        Returns:
            True if command sent successfully

        Raises:
            SessionDead: If session no longer exists (not retried)
            TmuxError: If command fails after retries
        """
        self.logger.info(f"Sending command: {command[:50]}{'...' if len(command) > 50 else ''}")

        if not self.session_exists():
            self.logger.error(f"Cannot send command - session '{self.session_name}' does not exist")
            raise SessionDead(f"Session '{self.session_name}' does not exist")

        # Send the command text
        result = self._run_tmux_command([
            "send-keys", "-t", self.session_name, command
        ])

        if result.returncode != 0:
            self.logger.error(f"Failed to send command text: {result.stderr}")
            raise TmuxError(
                f"Failed to send command: {result.stderr}",
                command=["send-keys"],
                return_code=result.returncode
            )

        # Send Enter separately to submit (not as part of send-keys command)
        if submit:
            time.sleep(0.1)  # Brief pause between text and Enter
            result = self._run_tmux_command([
                "send-keys", "-t", self.session_name, "Enter"
            ])

            if result.returncode != 0:
                self.logger.error(f"Failed to submit command: {result.stderr}")
                raise TmuxError(
                    f"Failed to submit command: {result.stderr}",
                    command=["send-keys", "Enter"],
                    return_code=result.returncode
                )

        self.logger.debug("Command sent successfully")
        return True

    def capture_output(self, lines: int = 100, start_line: Optional[int] = None) -> str:
        """
        Capture output from the tmux pane.

        Args:
            lines: Number of lines to capture (default: 100)
            start_line: Starting line for capture (None = current visible pane)

        Returns:
            Captured output as string
        """
        if not self.session_exists():
            return ""

        args = ["capture-pane", "-t", self.session_name, "-p"]

        if start_line is not None:
            args.extend(["-S", str(start_line)])

        result = self._run_tmux_command(args)
        return result.stdout

    def capture_scrollback(self) -> str:
        """
        Capture entire scrollback buffer.

        Returns:
            Full scrollback buffer as string
        """
        if not self.session_exists():
            return ""

        result = self._run_tmux_command([
            "capture-pane", "-t", self.session_name, "-p", "-S", "-"
        ])
        return result.stdout

    def wait_for_startup(self, timeout: Optional[int] = None) -> bool:
        """
        Wait until AI has fully started and is ready for first input.

        Looks for startup ready indicators AND ensures no loading indicators present.
        This is different from wait_for_ready() which waits for response completion.

        Args:
            timeout: Maximum seconds to wait (uses startup_timeout from config if not specified)

        Returns:
            True if startup indicators detected and no loading indicators, False if timeout
        """
        if not self.session_exists():
            return False

        timeout = timeout or self.startup_timeout
        check_interval = 0.5
        start_time = time.time()

        # Get loading indicators from config (if available)
        loading_indicators = self.config.get('loading_indicators', [])

        self.logger.debug(f"Waiting for startup ready indicators: {self.ready_indicators}")
        if loading_indicators:
            self.logger.debug(f"Will check for absence of loading indicators: {loading_indicators}")

        while (time.time() - start_time) < timeout:
            output = self.capture_output()

            # Check for AI-specific ready indicators
            if self.ready_indicators:
                self.logger.debug(f"Checking for indicators in {len(output)} chars of output")

                # First check if ready indicator is present
                ready_indicator_found = False
                for indicator in self.ready_indicators:
                    if indicator in output:
                        ready_indicator_found = True
                        self.logger.debug(f"Startup ready indicator found: '{indicator}'")
                        break

                if ready_indicator_found:
                    # Now check that no loading indicators are present
                    if loading_indicators:
                        has_loading = any(loading_ind in output for loading_ind in loading_indicators)
                        if has_loading:
                            self.logger.debug("Ready indicator found but loading indicator still present, waiting...")
                            time.sleep(check_interval)
                            continue

                    # Ready indicator present and no loading indicators
                    self.logger.debug("Startup complete: ready indicator found, no loading indicators")
                    return True
                else:
                    self.logger.debug(f"Indicators not found. Looking for: {self.ready_indicators}")
            else:
                # Fallback: if no indicators configured, just check for any output
                if len(output.strip()) > 50:  # Arbitrary threshold for "has started"
                    return True

            time.sleep(check_interval)

        self.logger.warning(f"Startup timeout after {timeout}s")
        return False

    def wait_for_ready(self, timeout: Optional[int] = None, check_interval: Optional[float] = None) -> bool:
        """
        Wait until AI is ready for next input.

        Strategy: Capture output repeatedly and wait until it stabilizes
        (no changes between captures), indicating AI has finished responding.

        Args:
            timeout: Maximum seconds to wait (uses config if not specified)
            check_interval: Seconds between checks (uses config if not specified)

        Returns:
            True if ready detected, False if timeout
        """
        if not self.session_exists():
            return False

        # Use configured values if not overridden
        timeout = timeout or self.response_timeout
        check_interval = check_interval or self.ready_check_interval
        required_stable_checks = self.ready_stable_checks

        start_time = time.time()
        previous_output = ""
        stable_count = 0

        while (time.time() - start_time) < timeout:
            current_output = self.capture_output()

            # Check if output has stabilized (no changes)
            if current_output == previous_output:
                stable_count += 1
                if stable_count >= required_stable_checks:
                    # Check for AI-specific ready indicators
                    if self.ready_indicators:
                        # Check if any ready indicator is present
                        if any(indicator in current_output for indicator in self.ready_indicators):
                            return True
                    else:
                        # No specific indicators configured, just use stabilization
                        return True
            else:
                stable_count = 0  # Reset if output changed

            previous_output = current_output
            time.sleep(check_interval)

        return False  # Timeout

    def kill_session(self) -> bool:
        """
        Terminate the tmux session.

        Returns:
            True if session killed successfully, False otherwise
        """
        if not self.session_exists():
            print(f"Session '{self.session_name}' does not exist")
            return False

        result = self._run_tmux_command([
            "kill-session", "-t", self.session_name
        ])

        return result.returncode == 0

    def attach_for_manual(self, read_only: bool = False) -> None:
        """
        Attach to the session for manual interaction.

        Note: This method will block until the user detaches.
        Use read_only=True to prevent accidental input.

        Args:
            read_only: If True, attach in read-only mode
        """
        if not self.session_exists():
            print(f"Session '{self.session_name}' does not exist")
            return

        args = ["attach-session", "-t", self.session_name]
        if read_only:
            args.append("-r")

        # This will block and take over the terminal
        subprocess.run(["tmux"] + args)

    def send_ctrl_c(self) -> bool:
        """
        Send Ctrl+C to cancel current operation.

        Returns:
            True if sent successfully, False otherwise
        """
        if not self.session_exists():
            return False

        result = self._run_tmux_command([
            "send-keys", "-t", self.session_name, "C-c"
        ])

        return result.returncode == 0

    def perform_health_check(self, check_type: str = "session_exists") -> dict:
        """
        Perform health check on the session.

        Args:
            check_type: Type of health check to perform:
                - "session_exists": Basic liveness check
                - "output_responsive": Check if session produces output
                - "command_echo": Full responsiveness test with test command

        Returns:
            Dictionary with health check results

        Raises:
            ValueError: If check_type is invalid
        """
        if check_type == "session_exists":
            result = self.health_checker.check_session_exists(self.session_exists)
        elif check_type == "output_responsive":
            result = self.health_checker.check_output_responsive(
                lambda: self.capture_output(lines=50),
                min_output_length=10
            )
        elif check_type == "command_echo":
            result = self.health_checker.check_command_echo(
                send_command_func=lambda cmd: self.send_command(cmd, submit=True),
                wait_func=self.wait_for_ready,
                capture_func=self.capture_output,
                test_command="# health_check"
            )
        else:
            raise ValueError(f"Invalid check_type: {check_type}")

        return {
            "healthy": result.healthy,
            "timestamp": result.timestamp.isoformat(),
            "check_type": result.check_type,
            "details": result.details,
            "error_message": result.error_message,
            "consecutive_failures": self.health_checker.consecutive_failures,
            "is_healthy": self.health_checker.is_healthy()
        }

    def get_health_stats(self) -> dict:
        """
        Get health check statistics.

        Returns:
            Dictionary with health metrics
        """
        return self.health_checker.get_stats()

    def is_healthy(self) -> bool:
        """
        Check if session is currently considered healthy.

        Returns:
            True if session is healthy, False otherwise
        """
        return self.health_checker.is_healthy()

    def restart_session(self, reason: str = "manual", auto_confirm_trust: bool = True) -> bool:
        """
        Restart the session (kill and start fresh).

        Args:
            reason: Reason for restart (for logging)
            auto_confirm_trust: Auto-confirm trust prompt on restart

        Returns:
            True if restart succeeded, False otherwise
        """
        self.logger.info(f"Restarting session (reason: {reason})")

        # Kill existing session if it exists
        if self.session_exists():
            self.logger.debug("Killing existing session")
            self.kill_session()
            time.sleep(1)  # Brief pause to ensure cleanup

        # Start new session
        try:
            self.start_session(auto_confirm_trust=auto_confirm_trust)
            self.logger.info("Session restarted successfully")

            # Reset health checker after successful restart
            self.health_checker.reset()

            return True
        except Exception as e:
            self.logger.error(f"Failed to restart session: {e}")
            return False

    def auto_restart_if_needed(self, reason: str = "unknown") -> bool:
        """
        Automatically restart session if policy allows and conditions are met.

        Args:
            reason: Reason for potential restart

        Returns:
            True if restart was attempted and succeeded, False otherwise
        """
        def restart_func():
            return self.restart_session(reason=reason)

        return self.auto_restarter.attempt_restart(
            restart_func=restart_func,
            reason=reason,
            wait_before_restart=True
        )

    def get_restart_stats(self) -> dict:
        """
        Get auto-restart statistics.

        Returns:
            Dictionary with restart metrics
        """
        return self.auto_restarter.get_stats()

    def get_status(self) -> dict:
        """
        Get session status information including health.

        Returns:
            Dictionary with session status
        """
        return {
            "session_name": self.session_name,
            "working_dir": self.working_dir,
            "exists": self.session_exists(),
            "health": self.get_health_stats(),
            "restart": self.get_restart_stats()
        }
</file>

<file path="src/orchestrator/message_router.py">
"""
Message routing between AI controllers orchestrated via tmux sessions.

The router propagates responses from one participant to the others, ensuring
their next prompts include relevant partner updates. It maintains lightweight
mailboxes per participant with bounded history so routing remains predictable.
"""

from __future__ import annotations

from collections import defaultdict, deque
from typing import Any, Deque, Dict, Iterable, List, Optional, Sequence

from ..utils.logger import get_logger


class MessageRouter:
    """
    Route messages between orchestrated participants.

    Producers call ``deliver`` after each turn to broadcast their response.
    Consumers call ``prepare_prompt`` before speaking to pull pending updates.
    """

    def __init__(
        self,
        participants: Optional[Sequence[str]] = None,
        *,
        max_pending: int = 8,
        context_manager: Any | None = None,
    ) -> None:
        self.logger = get_logger("orchestrator.message_router")
        self.participants: List[str] = list(participants or [])
        self._max_pending = max(1, int(max_pending))
        self._mailboxes: Dict[str, Deque[Dict[str, Any]]] = defaultdict(
            lambda: deque(maxlen=self._max_pending)
        )
        self.context_manager = context_manager

        # Pre-create mailboxes for known participants so deliver() can iterate quickly.
        for name in self.participants:
            self._mailboxes[name]  # type: ignore[func-returns-value]

    # ------------------------------------------------------------------ #
    # Participant management
    # ------------------------------------------------------------------ #

    def register_participant(self, name: str) -> None:
        """Ensure a participant has an associated mailbox."""
        if name not in self.participants:
            self.participants.append(name)
        self._mailboxes[name]  # type: ignore[func-returns-value]

    # ------------------------------------------------------------------ #
    # Message routing
    # ------------------------------------------------------------------ #

    def deliver(
        self,
        *,
        sender: str,
        message: str,
        topic: str,
        turn: int,
        metadata: Optional[Dict[str, Any]] = None,
    ) -> None:
        """
        Broadcast a message to all other participants.

        Args:
            sender: Name of the controller that produced the message.
            message: Text body to deliver.
            topic: Current discussion topic.
            turn: Absolute turn index captured by the conversation manager.
            metadata: Optional metadata dictionary for downstream consumers.
        """
        if not message:
            self.logger.debug("Skipping empty message delivery from '%s'", sender)
            return

        payload = {
            "sender": sender,
            "message": message,
            "topic": topic,
            "turn": turn,
            "metadata": metadata.copy() if isinstance(metadata, dict) else None,
        }

        targets = self._targets_for_sender(sender)
        for recipient in targets:
            self._mailboxes[recipient].append(payload)
            self.logger.debug(
                "Delivered message from '%s' to '%s' (pending=%d)",
                sender,
                recipient,
                len(self._mailboxes[recipient]),
            )

        if self.context_manager is not None:
            self._record_delivery(payload)

    def prepare_prompt(
        self,
        *,
        recipient: str,
        topic: str,
        base_prompt: str,
        include_history: bool = True,
    ) -> str:
        """
        Construct a prompt for ``recipient`` including routed messages.

        Args:
            recipient: Target controller name.
            topic: Current discussion topic.
            base_prompt: Default prompt constructed by the conversation manager.
            include_history: Whether to include contextual snippets for older messages.
        """
        mailbox = self._mailboxes.get(recipient)
        if not mailbox:
            return base_prompt

        updates: List[str] = []
        while mailbox:
            payload = mailbox.popleft()
            message = payload.get("message", "")
            sender = payload.get("sender", "unknown")
            snippet = self._trim_message(message)
            updates.append(f"{sender} wrote: {snippet}")

        if not updates:
            return base_prompt

        prompt_lines = [base_prompt, "", f"Topic: {topic}", "Recent partner updates:"]
        prompt_lines.extend(f"- {update}" for update in updates)

        if include_history and self.context_manager is not None:
            summary = self._context_summary()
            if summary:
                prompt_lines.extend(["", f"Shared context: {summary}"])

        return "\n".join(prompt_lines)

    # ------------------------------------------------------------------ #
    # Internal helpers
    # ------------------------------------------------------------------ #

    def _targets_for_sender(self, sender: str) -> Iterable[str]:
        if not self.participants:
            # No participants registered; deliver to everyone except sender via mailboxes keys.
            return [name for name in self._mailboxes.keys() if name != sender]

        return [name for name in self.participants if name != sender]

    def _record_delivery(self, payload: Dict[str, Any]) -> None:
        """Forward delivery metadata to the context manager if it exposes a hook."""
        for attr in ("record_delivery", "note_delivery"):
            handler = getattr(self.context_manager, attr, None)
            if callable(handler):
                try:
                    handler(payload)
                except Exception as exc:  # noqa: BLE001
                    self.logger.debug("Context manager delivery hook failed: %s", exc)
                break

    @staticmethod
    def _trim_message(message: str, *, max_length: int = 400) -> str:
        text = message.strip()
        if len(text) <= max_length:
            return text
        return text[: max_length - 3] + "..."

    def _context_summary(self) -> str:
        """Request a shortened summary from the context manager, if available."""
        if self.context_manager is None:
            return ""
        summarizer = getattr(self.context_manager, "summarize_conversation", None)
        history = getattr(self.context_manager, "history", None)
        if callable(summarizer) and isinstance(history, list):
            try:
                return summarizer(history[-3:], max_length=300)
            except Exception as exc:  # noqa: BLE001
                self.logger.debug("Context summary request failed: %s", exc)
        return ""


__all__ = ["MessageRouter"]
</file>

<file path="src/utils/auto_restart.py">
"""
Auto-restart utilities for session recovery.

Provides mechanisms to automatically restart failed sessions with
configurable policies and backoff strategies.
"""
import time
import logging
from typing import Optional, Callable, Dict, Any
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum

logger = logging.getLogger(__name__)


class RestartPolicy(Enum):
    """Restart policy options."""
    NEVER = "never"  # Never auto-restart
    ON_FAILURE = "on_failure"  # Restart only on unexpected failures
    ALWAYS = "always"  # Always attempt restart regardless of reason


@dataclass
class RestartAttempt:
    """Record of a restart attempt."""
    timestamp: datetime
    success: bool
    reason: str
    error_message: Optional[str] = None
    elapsed_time: float = 0.0


class AutoRestarter:
    """
    Manages automatic session restart with configurable policies.

    Tracks restart attempts, implements backoff strategies, and
    enforces restart limits to prevent infinite loops.
    """

    def __init__(
        self,
        policy: RestartPolicy = RestartPolicy.ON_FAILURE,
        max_restart_attempts: int = 3,
        restart_window: float = 300.0,  # 5 minutes
        initial_backoff: float = 5.0,
        max_backoff: float = 60.0,
        backoff_factor: float = 2.0
    ):
        """
        Initialize AutoRestarter.

        Args:
            policy: When to restart (NEVER, ON_FAILURE, ALWAYS)
            max_restart_attempts: Max restarts within window (default: 3)
            restart_window: Time window in seconds for counting attempts (default: 300)
            initial_backoff: Initial delay before first restart (default: 5.0s)
            max_backoff: Maximum delay between restarts (default: 60.0s)
            backoff_factor: Backoff multiplier (default: 2.0)
        """
        self.policy = policy
        self.max_restart_attempts = max_restart_attempts
        self.restart_window = restart_window
        self.initial_backoff = initial_backoff
        self.max_backoff = max_backoff
        self.backoff_factor = backoff_factor

        # Track restart history
        self.restart_history: list[RestartAttempt] = []
        self.total_restarts = 0
        self.successful_restarts = 0
        self.failed_restarts = 0

    def should_restart(self, reason: str = "unknown") -> bool:
        """
        Determine if restart should be attempted based on policy and limits.

        Args:
            reason: Reason for potential restart

        Returns:
            True if restart should be attempted, False otherwise
        """
        if self.policy == RestartPolicy.NEVER:
            logger.info("Restart policy is NEVER - skipping restart")
            return False

        # Check if we've exceeded restart attempts within the window
        recent_attempts = self._get_recent_attempts()
        if len(recent_attempts) >= self.max_restart_attempts:
            logger.warning(
                f"Max restart attempts ({self.max_restart_attempts}) reached "
                f"within {self.restart_window}s window. Not restarting."
            )
            return False

        logger.info(f"Restart permitted: {len(recent_attempts)}/{self.max_restart_attempts} attempts used")
        return True

    def calculate_backoff(self) -> float:
        """
        Calculate backoff delay based on recent restart attempts.

        Returns:
            Delay in seconds before next restart attempt
        """
        recent_attempts = self._get_recent_attempts()

        if not recent_attempts:
            return self.initial_backoff

        # Exponential backoff based on number of recent attempts
        attempt_count = len(recent_attempts)
        delay = self.initial_backoff * (self.backoff_factor ** (attempt_count - 1))
        delay = min(delay, self.max_backoff)

        logger.debug(f"Calculated backoff delay: {delay:.2f}s (attempt {attempt_count})")
        return delay

    def attempt_restart(
        self,
        restart_func: Callable[[], bool],
        reason: str = "unknown",
        wait_before_restart: bool = True
    ) -> bool:
        """
        Attempt to restart session with backoff and tracking.

        Args:
            restart_func: Function that performs the restart (should return bool)
            reason: Reason for restart (for logging)
            wait_before_restart: If True, apply backoff delay before restart

        Returns:
            True if restart succeeded, False otherwise
        """
        if not self.should_restart(reason):
            return False

        # Apply backoff if requested
        if wait_before_restart:
            delay = self.calculate_backoff()
            logger.info(f"Waiting {delay:.2f}s before restart attempt (reason: {reason})")
            time.sleep(delay)

        # Attempt restart
        logger.info(f"Attempting restart (reason: {reason})")
        start_time = time.time()

        try:
            success = restart_func()
            elapsed = time.time() - start_time

            # Record attempt
            attempt = RestartAttempt(
                timestamp=datetime.now(),
                success=success,
                reason=reason,
                error_message=None if success else "Restart function returned False",
                elapsed_time=elapsed
            )

            self._record_attempt(attempt)

            if success:
                logger.info(f"Restart succeeded in {elapsed:.2f}s")
            else:
                logger.error(f"Restart failed after {elapsed:.2f}s")

            return success

        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"Restart failed with exception after {elapsed:.2f}s: {e}")

            # Record failed attempt
            attempt = RestartAttempt(
                timestamp=datetime.now(),
                success=False,
                reason=reason,
                error_message=str(e),
                elapsed_time=elapsed
            )

            self._record_attempt(attempt)
            return False

    def _get_recent_attempts(self) -> list[RestartAttempt]:
        """
        Get restart attempts within the configured time window.

        Returns:
            List of recent RestartAttempt objects
        """
        cutoff_time = datetime.now() - timedelta(seconds=self.restart_window)
        return [
            attempt for attempt in self.restart_history
            if attempt.timestamp >= cutoff_time
        ]

    def _record_attempt(self, attempt: RestartAttempt):
        """Record a restart attempt and update statistics."""
        self.restart_history.append(attempt)
        self.total_restarts += 1

        if attempt.success:
            self.successful_restarts += 1
        else:
            self.failed_restarts += 1

        # Keep only recent history (last 100 attempts)
        if len(self.restart_history) > 100:
            self.restart_history = self.restart_history[-100:]

    def get_stats(self) -> Dict[str, Any]:
        """
        Get restart statistics.

        Returns:
            Dictionary with restart metrics
        """
        recent_attempts = self._get_recent_attempts()

        success_rate = 0.0
        if self.total_restarts > 0:
            success_rate = self.successful_restarts / self.total_restarts

        return {
            "policy": self.policy.value,
            "total_restarts": self.total_restarts,
            "successful_restarts": self.successful_restarts,
            "failed_restarts": self.failed_restarts,
            "success_rate": success_rate,
            "recent_attempts_count": len(recent_attempts),
            "attempts_remaining": max(0, self.max_restart_attempts - len(recent_attempts)),
            "last_attempt": {
                "timestamp": self.restart_history[-1].timestamp.isoformat(),
                "success": self.restart_history[-1].success,
                "reason": self.restart_history[-1].reason,
                "elapsed_time": self.restart_history[-1].elapsed_time
            } if self.restart_history else None
        }

    def reset_history(self):
        """Reset restart history (useful after successful manual intervention)."""
        logger.info("Resetting restart history")
        self.restart_history.clear()

    def can_restart(self) -> bool:
        """
        Check if restart is currently allowed without attempting.

        Returns:
            True if restart would be allowed, False otherwise
        """
        if self.policy == RestartPolicy.NEVER:
            return False

        recent_attempts = self._get_recent_attempts()
        return len(recent_attempts) < self.max_restart_attempts
</file>

<file path="src/utils/health_check.py">
"""
Health check utilities for monitoring session state and responsiveness.

Provides mechanisms to periodically verify sessions are alive and responsive.
"""
import time
import logging
from typing import Optional, Dict, Any, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)


@dataclass
class HealthCheckResult:
    """Results from a health check operation."""
    healthy: bool
    timestamp: datetime
    check_type: str
    details: Dict[str, Any]
    error_message: Optional[str] = None


class HealthChecker:
    """
    Monitors session health with configurable checks and thresholds.

    Supports various health check strategies:
    - Session existence (tmux session still running)
    - Output responsiveness (session producing output)
    - Command echo (session responding to test commands)
    """

    def __init__(
        self,
        check_interval: float = 30.0,
        response_timeout: float = 5.0,
        max_failed_checks: int = 3
    ):
        """
        Initialize HealthChecker.

        Args:
            check_interval: Seconds between health checks (default: 30)
            response_timeout: Seconds to wait for health check response (default: 5)
            max_failed_checks: Number of consecutive failures before unhealthy (default: 3)
        """
        self.check_interval = check_interval
        self.response_timeout = response_timeout
        self.max_failed_checks = max_failed_checks

        # Track health check history
        self.last_check: Optional[datetime] = None
        self.last_result: Optional[HealthCheckResult] = None
        self.consecutive_failures = 0
        self.total_checks = 0
        self.total_failures = 0

    def should_check(self) -> bool:
        """
        Determine if a health check should be performed based on interval.

        Returns:
            True if enough time has passed since last check
        """
        if self.last_check is None:
            return True

        elapsed = (datetime.now() - self.last_check).total_seconds()
        return elapsed >= self.check_interval

    def check_session_exists(self, session_exists_func: Callable[[], bool]) -> HealthCheckResult:
        """
        Check if session exists (basic liveness check).

        Args:
            session_exists_func: Function that returns True if session exists

        Returns:
            HealthCheckResult with check outcome
        """
        start_time = time.time()

        try:
            exists = session_exists_func()
            elapsed = time.time() - start_time

            result = HealthCheckResult(
                healthy=exists,
                timestamp=datetime.now(),
                check_type="session_exists",
                details={
                    "elapsed_time": elapsed,
                    "exists": exists
                },
                error_message=None if exists else "Session does not exist"
            )

            self._record_result(result)
            return result

        except Exception as e:
            logger.error(f"Health check failed with exception: {e}")
            result = HealthCheckResult(
                healthy=False,
                timestamp=datetime.now(),
                check_type="session_exists",
                details={"error": str(e)},
                error_message=f"Exception during check: {e}"
            )
            self._record_result(result)
            return result

    def check_output_responsive(
        self,
        capture_func: Callable[[], str],
        min_output_length: int = 10
    ) -> HealthCheckResult:
        """
        Check if session is producing output (responsiveness check).

        Args:
            capture_func: Function that captures current output
            min_output_length: Minimum characters expected (default: 10)

        Returns:
            HealthCheckResult with check outcome
        """
        start_time = time.time()

        try:
            output = capture_func()
            elapsed = time.time() - start_time

            # Check if we got meaningful output
            has_output = len(output) >= min_output_length

            result = HealthCheckResult(
                healthy=has_output,
                timestamp=datetime.now(),
                check_type="output_responsive",
                details={
                    "elapsed_time": elapsed,
                    "output_length": len(output),
                    "min_required": min_output_length
                },
                error_message=None if has_output else f"Insufficient output: {len(output)} < {min_output_length}"
            )

            self._record_result(result)
            return result

        except Exception as e:
            logger.error(f"Output check failed with exception: {e}")
            result = HealthCheckResult(
                healthy=False,
                timestamp=datetime.now(),
                check_type="output_responsive",
                details={"error": str(e)},
                error_message=f"Exception during check: {e}"
            )
            self._record_result(result)
            return result

    def check_command_echo(
        self,
        send_command_func: Callable[[str], bool],
        wait_func: Callable[[Optional[float]], bool],
        capture_func: Callable[[], str],
        test_command: str = "# health_check"
    ) -> HealthCheckResult:
        """
        Check if session can execute a test command (full responsiveness check).

        Args:
            send_command_func: Function to send command
            wait_func: Function to wait for response
            capture_func: Function to capture output
            test_command: Safe test command to send (default: comment)

        Returns:
            HealthCheckResult with check outcome
        """
        start_time = time.time()

        try:
            # Send test command (should be harmless like a comment)
            send_success = send_command_func(test_command)
            if not send_success:
                result = HealthCheckResult(
                    healthy=False,
                    timestamp=datetime.now(),
                    check_type="command_echo",
                    details={"stage": "send_failed"},
                    error_message="Failed to send test command"
                )
                self._record_result(result)
                return result

            # Wait for response
            ready = wait_func(self.response_timeout)
            elapsed = time.time() - start_time

            if not ready:
                result = HealthCheckResult(
                    healthy=False,
                    timestamp=datetime.now(),
                    check_type="command_echo",
                    details={
                        "stage": "timeout",
                        "elapsed_time": elapsed,
                        "timeout": self.response_timeout
                    },
                    error_message=f"Timeout waiting for response ({self.response_timeout}s)"
                )
                self._record_result(result)
                return result

            # Capture output to verify command was processed
            output = capture_func()
            command_found = test_command in output

            result = HealthCheckResult(
                healthy=command_found,
                timestamp=datetime.now(),
                check_type="command_echo",
                details={
                    "elapsed_time": elapsed,
                    "test_command": test_command,
                    "command_found": command_found,
                    "output_length": len(output)
                },
                error_message=None if command_found else "Test command not found in output"
            )

            self._record_result(result)
            return result

        except Exception as e:
            logger.error(f"Command echo check failed with exception: {e}")
            result = HealthCheckResult(
                healthy=False,
                timestamp=datetime.now(),
                check_type="command_echo",
                details={"error": str(e)},
                error_message=f"Exception during check: {e}"
            )
            self._record_result(result)
            return result

    def _record_result(self, result: HealthCheckResult):
        """Record health check result and update statistics."""
        self.last_check = result.timestamp
        self.last_result = result
        self.total_checks += 1

        if not result.healthy:
            self.consecutive_failures += 1
            self.total_failures += 1
            logger.warning(
                f"Health check failed ({result.check_type}): {result.error_message}. "
                f"Consecutive failures: {self.consecutive_failures}/{self.max_failed_checks}"
            )
        else:
            if self.consecutive_failures > 0:
                logger.info(f"Health check recovered after {self.consecutive_failures} failures")
            self.consecutive_failures = 0
            logger.debug(f"Health check passed ({result.check_type})")

    def is_healthy(self) -> bool:
        """
        Determine overall health status.

        Returns:
            False if consecutive failures exceed threshold, True otherwise
        """
        return self.consecutive_failures < self.max_failed_checks

    def get_stats(self) -> Dict[str, Any]:
        """
        Get health check statistics.

        Returns:
            Dictionary with health check metrics
        """
        success_rate = 0.0
        if self.total_checks > 0:
            success_rate = (self.total_checks - self.total_failures) / self.total_checks

        return {
            "total_checks": self.total_checks,
            "total_failures": self.total_failures,
            "consecutive_failures": self.consecutive_failures,
            "success_rate": success_rate,
            "is_healthy": self.is_healthy(),
            "last_check": self.last_check.isoformat() if self.last_check else None,
            "last_result": {
                "healthy": self.last_result.healthy,
                "check_type": self.last_result.check_type,
                "error": self.last_result.error_message
            } if self.last_result else None
        }

    def reset(self):
        """Reset health check state (useful after recovery actions)."""
        logger.info("Resetting health check state")
        self.consecutive_failures = 0
        # Keep total_checks and total_failures for historical tracking
</file>

<file path="src/utils/retry.py">
"""
Retry utilities with exponential backoff for handling transient failures.
"""
import time
import logging
from functools import wraps
from typing import Callable, Type, Tuple, Optional

from .exceptions import SessionError, CommandError, CommandTimeout

logger = logging.getLogger(__name__)


def retry_with_backoff(
    max_attempts: int = 3,
    initial_delay: float = 1.0,
    max_delay: float = 10.0,
    backoff_factor: float = 2.0,
    exceptions: Tuple[Type[Exception], ...] = (SessionError, CommandError, CommandTimeout)
):
    """
    Decorator that retries a function with exponential backoff on specified exceptions.

    Args:
        max_attempts: Maximum number of retry attempts (default: 3)
        initial_delay: Initial delay in seconds before first retry (default: 1.0)
        max_delay: Maximum delay between retries in seconds (default: 10.0)
        backoff_factor: Multiplier for delay after each retry (default: 2.0)
        exceptions: Tuple of exception types to catch and retry (default: Session/Command/Timeout)

    Returns:
        Decorated function that implements retry logic

    Example:
        @retry_with_backoff(max_attempts=3, initial_delay=2.0)
        def unstable_operation():
            # May fail transiently
            pass
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            delay = initial_delay
            last_exception = None

            for attempt in range(1, max_attempts + 1):
                try:
                    return func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e

                    if attempt == max_attempts:
                        logger.error(
                            f"Function {func.__name__} failed after {max_attempts} attempts. "
                            f"Last error: {str(e)}"
                        )
                        raise

                    logger.warning(
                        f"Function {func.__name__} failed (attempt {attempt}/{max_attempts}). "
                        f"Retrying in {delay:.2f}s. Error: {str(e)}"
                    )

                    time.sleep(delay)
                    delay = min(delay * backoff_factor, max_delay)

            # Should never reach here, but just in case
            if last_exception:
                raise last_exception

        return wrapper
    return decorator


class RetryStrategy:
    """
    Configurable retry strategy for more complex retry scenarios.
    """

    def __init__(
        self,
        max_attempts: int = 3,
        initial_delay: float = 1.0,
        max_delay: float = 10.0,
        backoff_factor: float = 2.0,
        exceptions: Optional[Tuple[Type[Exception], ...]] = None
    ):
        self.max_attempts = max_attempts
        self.initial_delay = initial_delay
        self.max_delay = max_delay
        self.backoff_factor = backoff_factor
        self.exceptions = exceptions or (SessionError, CommandError, CommandTimeout)

    def execute(self, func: Callable, *args, **kwargs):
        """
        Execute a function with retry logic.

        Args:
            func: Function to execute
            *args: Positional arguments for the function
            **kwargs: Keyword arguments for the function

        Returns:
            Result of the function execution

        Raises:
            Last exception encountered if all retries fail
        """
        delay = self.initial_delay
        last_exception = None

        for attempt in range(1, self.max_attempts + 1):
            try:
                return func(*args, **kwargs)
            except self.exceptions as e:
                last_exception = e

                if attempt == self.max_attempts:
                    logger.error(
                        f"Function {func.__name__} failed after {self.max_attempts} attempts. "
                        f"Last error: {str(e)}"
                    )
                    raise

                logger.warning(
                    f"Function {func.__name__} failed (attempt {attempt}/{self.max_attempts}). "
                    f"Retrying in {delay:.2f}s. Error: {str(e)}"
                )

                time.sleep(delay)
                delay = min(delay * self.backoff_factor, self.max_delay)

        if last_exception:
            raise last_exception


# Predefined retry strategies for common scenarios
QUICK_RETRY = RetryStrategy(max_attempts=2, initial_delay=0.5, max_delay=2.0)
STANDARD_RETRY = RetryStrategy(max_attempts=3, initial_delay=1.0, max_delay=10.0)
PERSISTENT_RETRY = RetryStrategy(max_attempts=5, initial_delay=2.0, max_delay=30.0)
</file>

<file path="tests/run_parser_accuracy_test.py">
#!/usr/bin/env python3
"""
Parser Accuracy Harness

Exercise each tmux-backed AI controller with representative prompts and capture
both the raw pane transcript and the OutputParser's cleaned interpretation.
Artifacts are written to ``scratch/parser_accuracy/<ai>/`` for manual review.
"""

from __future__ import annotations

import argparse
import json
import logging
import shlex
import sys
import time
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Sequence, Tuple

from src.controllers.tmux_controller import (
    SessionBackendError,
    SessionNotFoundError,
    TmuxController,
)
from src.utils.config_loader import get_config
from src.utils.output_parser import OutputParser
from src.utils.exceptions import CommandTimeout, SessionDead


AI_CHOICES: Tuple[str, ...] = ("claude", "gemini", "codex")
DEFAULT_OUTPUT_DIR = Path("scratch/parser_accuracy")


@dataclass(frozen=True)
class PromptScenario:
    """Prompt metadata for a single accuracy probe."""

    key: str
    prompt: str
    description: str


DEFAULT_PROMPTS: Tuple[PromptScenario, ...] = (
    PromptScenario(
        key="simple",
        prompt=(
            "In two sentences, explain why capturing both raw transcripts and cleaned parser "
            "output is useful when verifying an automation pipeline."
        ),
        description="Short, plain-language response grounded in general automation practice.",
    ),
    PromptScenario(
        key="longform",
        prompt=(
            "Provide a detailed checklist (at least eight bullet points) of best practices "
            "for testing command-line automation harnesses that interact with tmux sessions."
        ),
        description="Long structured response with bullet formatting and no repository context.",
    ),
    PromptScenario(
        key="code",
        prompt=(
            "Write a Python function `compare_parser_outputs(raw: str, parsed: str) -> dict` "
            "that compares two strings and returns counts of lines, characters, and "
            "a boolean flag for equality. Include doctest-style usage examples."
        ),
        description="Code-heavy response requiring preserved indentation.",
    ),
    PromptScenario(
        key="markdown",
        prompt=(
            "Create a markdown table with three rows comparing logging strategies, timeout "
            "policies, and retry handling for automation controllers. Add a brief paragraph "
            "interpreting the table."
        ),
        description="Markdown table plus narrative paragraph using general operational themes.",
    ),
)


def parse_args(argv: Optional[Sequence[str]] = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description=__doc__,
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        "--ais",
        nargs="+",
        metavar="AI",
        choices=AI_CHOICES,
        default=list(AI_CHOICES),
        help="Subset of controllers to exercise.",
    )
    parser.add_argument(
        "--categories",
        nargs="+",
        choices=[scenario.key for scenario in DEFAULT_PROMPTS],
        help="Limit the run to specific prompt categories.",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=DEFAULT_OUTPUT_DIR,
        help="Directory for captured artifacts.",
    )
    parser.add_argument(
        "--session",
        action="append",
        metavar="AI=SESSION",
        help="Override tmux session name for an AI (e.g., --session claude=claude-dev).",
    )
    parser.add_argument(
        "--auto-start",
        action="store_true",
        help="Launch tmux session automatically if it is not already running.",
    )
    parser.add_argument(
        "--kill-existing",
        action="store_true",
        help="Kill any existing tmux session before starting fresh.",
    )
    parser.add_argument(
        "--working-dir",
        help="Working directory for launched CLI processes (defaults to config behaviour).",
    )
    parser.add_argument(
        "--bootstrap",
        help="Shell command to run before the executable when auto-starting sessions.",
    )
    parser.add_argument(
        "--timeout",
        type=float,
        help="Override wait_for_ready timeout in seconds (defaults to config response_timeout).",
    )
    parser.add_argument(
        "--check-interval",
        type=float,
        help="Override wait_for_ready polling interval in seconds.",
    )
    parser.add_argument(
        "--tail-lines",
        type=int,
        help="Limit the number of transcript lines saved per prompt.",
    )
    parser.add_argument(
        "--capture-delay",
        type=float,
        help="Extra seconds to wait after wait_for_ready() before capturing output.",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Print planned actions without sending prompts.",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable debug logging.",
    )
    return parser.parse_args(argv)


def load_session_overrides(entries: Optional[Iterable[str]]) -> Dict[str, str]:
    overrides: Dict[str, str] = {}
    if not entries:
        return overrides
    for entry in entries:
        if "=" not in entry:
            raise ValueError(f"Invalid --session override '{entry}'. Expected format AI=SESSION.")
        ai, name = entry.split("=", 1)
        ai = ai.strip().lower()
        if ai not in AI_CHOICES:
            raise ValueError(f"Unknown AI '{ai}' in session override.")
        overrides[ai] = name.strip()
    return overrides


def slugify(text: str, max_length: int = 40) -> str:
    cleaned = "".join(char.lower() if char.isalnum() else "-" for char in text)
    while "--" in cleaned:
        cleaned = cleaned.replace("--", "-")
    cleaned = cleaned.strip("-")
    if len(cleaned) > max_length:
        cleaned = cleaned[:max_length].rstrip("-")
    return cleaned or "prompt"


def select_prompts(categories: Optional[Sequence[str]]) -> List[PromptScenario]:
    if not categories:
        return list(DEFAULT_PROMPTS)
    selected = [scenario for scenario in DEFAULT_PROMPTS if scenario.key in categories]
    if not selected:
        raise ValueError(f"No prompts matched categories {categories}")
    return selected


def build_controller(
    *,
    ai: str,
    session_name: str,
    executable: Optional[str],
    working_dir: Optional[str],
    auto_start: bool,
    kill_existing: bool,
    bootstrap: Optional[str],
    timeout_override: Optional[float],
    check_interval: Optional[float],
) -> TmuxController:
    config_loader = get_config()
    ai_section: Dict[str, object] = dict(config_loader.get_section(ai) or {})
    if not ai_section:
        raise ValueError(f"No configuration section found for '{ai}'.")

    executable_value = executable or ai_section.pop("executable", ai)
    exec_args_value = ai_section.pop("executable_args", [])
    if isinstance(exec_args_value, str):
        exec_args_value = shlex.split(exec_args_value)
    launch_executable = executable_value
    launch_args = list(exec_args_value)

    # Apply overrides for wait_for_ready tuning.
    if timeout_override is not None:
        ai_section["response_timeout"] = timeout_override
    if check_interval is not None:
        ai_section["ready_check_interval"] = check_interval

    ai_section.setdefault("pause_on_manual_clients", False)

    if bootstrap:
        quoted_executable = shlex.quote(executable_value)
        quoted_args = " ".join(shlex.quote(arg) for arg in launch_args)
        command_tail = f"{quoted_executable} {quoted_args}".strip()
        shell_command = f"{bootstrap} && {command_tail}" if command_tail else f"{bootstrap} && {quoted_executable}"
        launch_executable = "bash"
        launch_args = ["-lc", shell_command]

    controller = TmuxController(
        session_name=session_name,
        executable=launch_executable,
        working_dir=working_dir,
        ai_config=ai_section,
        executable_args=launch_args,
    )

    controller.reset_output_cache()

    if controller.session_exists():
        if kill_existing:
            if not controller.kill_session():
                raise SessionBackendError(f"Failed to kill existing session '{session_name}'.")
            time.sleep(1.0)
        else:
            controller.resume_automation(flush_pending=True)
            return controller

    if not auto_start:
        raise SessionNotFoundError(
            f"Session '{session_name}' not found for {ai}. "
            "Start it manually or pass --auto-start."
        )

    controller.start()
    controller.reset_output_cache()
    return controller


def compute_delta(previous: List[str], current: List[str], *, tail_limit: Optional[int]) -> List[str]:
    if previous and len(current) >= len(previous):
        limit = min(len(previous), len(current))
        prefix = 0
        while prefix < limit and previous[prefix] == current[prefix]:
            prefix += 1
        delta = current[prefix:]
    else:
        delta = current

    if tail_limit is not None and len(delta) > tail_limit:
        delta = delta[-tail_limit:]

    return delta


def ensure_directory(path: Path) -> Path:
    path.mkdir(parents=True, exist_ok=True)
    return path


def write_text(path: Path, content: str) -> None:
    if content and not content.endswith("\n"):
        content = f"{content}\n"
    path.write_text(content, encoding="utf-8")


def main(argv: Optional[Sequence[str]] = None) -> int:
    args = parse_args(argv)
    logging.basicConfig(
        level=logging.DEBUG if args.verbose else logging.INFO,
        format="%(asctime)s %(levelname)s %(message)s",
    )
    logger = logging.getLogger("parser_accuracy")

    try:
        session_overrides = load_session_overrides(args.session)
    except ValueError as exc:
        logger.error("%s", exc)
        return 2

    prompts = select_prompts(args.categories)
    cfg = get_config()
    tmux_section = cfg.get_section("tmux") or {}
    capture_delay = (
        args.capture_delay if args.capture_delay is not None else float(tmux_section.get("capture_delay", 0.25))
    )
    tail_limit = args.tail_lines if args.tail_lines is not None else int(tmux_section.get("capture_lines", 500))

    if args.dry_run:
        logger.info("Dry run requested; no prompts will be sent.")
        logger.info("AIs: %s", ", ".join(args.ais))
        for scenario in prompts:
            logger.info("  - %s: %s", scenario.key, scenario.description)
        return 0

    output_root = ensure_directory(args.output_dir)
    parser = OutputParser()

    controllers: Dict[str, TmuxController] = {}
    pane_snapshots: Dict[str, List[str]] = {}
    per_ai_dirs: Dict[str, Path] = {}

    for ai in args.ais:
        session_key = f"{ai}_session"
        session_name = session_overrides.get(ai, tmux_section.get(session_key, ai))
        ai_config = cfg.get_section(ai) or {}
        executable = ai_config.get("executable", ai)
        working_dir = args.working_dir or ai_config.get("working_dir")
        try:
            controller = build_controller(
                ai=ai,
                session_name=session_name,
                executable=executable,
                working_dir=working_dir,
                auto_start=args.auto_start,
                kill_existing=args.kill_existing,
                bootstrap=args.bootstrap,
                timeout_override=args.timeout,
                check_interval=args.check_interval,
            )
        except (SessionNotFoundError, SessionBackendError) as exc:
            logger.error("Failed to prepare %s controller: %s", ai, exc)
            continue

        controllers[ai] = controller
        per_ai_dirs[ai] = ensure_directory(output_root / ai)
        pane_snapshot = controller.capture_scrollback()
        pane_snapshots[ai] = pane_snapshot.splitlines()
        controller.resume_automation(flush_pending=False)
        logger.info("Prepared controller for %s (session=%s).", ai, session_name)

    if not controllers:
        logger.error("No controllers available; aborting.")
        return 1

    summary_rows: List[Dict[str, object]] = []

    for ai, controller in controllers.items():
        ai_dir = per_ai_dirs[ai]
        previous_lines = pane_snapshots[ai]
        logger.info("Running %d prompts against %s.", len(prompts), ai)

        for index, scenario in enumerate(prompts, start=1):
            prompt_slug = slugify(f"{index:02d}-{scenario.key}")
            raw_path = ai_dir / f"{prompt_slug}.raw.txt"
            parsed_path = ai_dir / f"{prompt_slug}.parsed.txt"
            metadata_path = ai_dir / f"{prompt_slug}.meta.json"

            controller.reset_output_cache()
            controller.resume_automation(flush_pending=False)

            start_time = time.perf_counter()
            queued = False
            ready = False
            error: Optional[str] = None
            raw_delta: List[str] = []

            logger.info("[%s] Prompt %s: %s", ai, scenario.key, scenario.description)
            try:
                sent = controller.send_command(scenario.prompt, submit=True)
                queued = not sent
                if queued:
                    logger.debug("[%s] Command queued; resuming automation.", ai)
                    controller.resume_automation(flush_pending=True)

                ready = controller.wait_for_ready(timeout=args.timeout, check_interval=args.check_interval)
                if not ready:
                    error = "wait_for_ready returned False"

                time.sleep(capture_delay)

                pane_output = controller.capture_scrollback()
                current_lines = pane_output.splitlines()
                raw_delta = compute_delta(previous_lines, current_lines, tail_limit=tail_limit)
                if not raw_delta:
                    fallback = controller.get_last_output(tail_lines=tail_limit)
                    if fallback:
                        raw_delta = fallback.splitlines()
                previous_lines = current_lines
            except (SessionBackendError, SessionNotFoundError, SessionDead, CommandTimeout) as exc:
                error = str(exc)
                logger.error("[%s] Error while processing prompt '%s': %s", ai, scenario.key, exc)
            duration = time.perf_counter() - start_time

            raw_text = "\n".join(raw_delta)
            parsed_text = parser.clean_output(raw_text, strip_trailing_prompts=True)
            response_pairs = parser.extract_responses(raw_text)

            write_text(raw_path, raw_text)
            write_text(parsed_path, parsed_text)
            metadata = {
                "ai": ai,
                "prompt_key": scenario.key,
                "prompt": scenario.prompt,
                "description": scenario.description,
                "timestamp": datetime.utcnow().isoformat() + "Z",
                "duration_seconds": duration,
                "queued": queued,
                "ready": ready,
                "error": error,
                "raw_lines": len(raw_delta),
                "parsed_lines": len(parsed_text.splitlines()) if parsed_text else 0,
                "raw_path": str(raw_path),
                "parsed_path": str(parsed_path),
                "response_pairs": response_pairs,
            }
            metadata_path.write_text(json.dumps(metadata, indent=2), encoding="utf-8")

            summary_rows.append(
                {
                    "ai": ai,
                    "prompt": scenario.key,
                    "duration": duration,
                    "raw_lines": len(raw_delta),
                    "parsed_lines": metadata["parsed_lines"],
                    "error": error,
                    "raw_path": raw_path,
                    "parsed_path": parsed_path,
                }
            )

        pane_snapshots[ai] = previous_lines

    logger.info("Run complete. Artifacts stored in %s", output_root)
    logger.info("Summary:")
    for row in summary_rows:
        status = "ok" if row["error"] is None else "error"
        logger.info(
            "  %s | %s | %s | raw=%d lines parsed=%d lines | %s",
            row["ai"],
            row["prompt"],
            f"{row['duration']:.2f}s",
            row["raw_lines"],
            row["parsed_lines"],
            status,
        )

    has_error = any(row["error"] is not None for row in summary_rows)
    return 1 if has_error else 0


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="tests/run_single_ai_wait_probe.py">
#!/usr/bin/env python3
"""
Single-AI wait_for_ready probe.

Launch or attach to a single AI controller, send a prompt, and rely on the
augmented wait_for_ready() instrumentation to gather detailed readiness logs.
"""

from __future__ import annotations

import argparse
import logging
import shlex
import sys
import time
from typing import Dict, Sequence

from src.controllers.tmux_controller import (
    SessionBackendError,
    SessionNotFoundError,
    TmuxController,
)
from src.utils.config_loader import get_config


AI_CHOICES = ("claude", "gemini", "codex")


def parse_args(argv: Sequence[str]) -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description=(
            "Probe a single AI session to collect wait_for_ready() diagnostics. "
            "Runs inside the active tmux worktree."
        )
    )
    parser.add_argument(
        "--ai",
        choices=AI_CHOICES,
        required=True,
        help="Which AI controller to exercise.",
    )
    parser.add_argument(
        "--prompt",
        default="Summarize the current status of the output end-marker investigation.",
        help="Prompt to send to the AI once the session is ready.",
    )
    parser.add_argument(
        "--session",
        help="Override tmux session name (defaults to config tmux.<ai>_session).",
    )
    parser.add_argument(
        "--working-dir",
        help="Working directory for the AI process (defaults to controller behaviour).",
    )
    parser.add_argument(
        "--auto-start",
        action="store_true",
        help="Launch the tmux session automatically if it is not already running.",
    )
    parser.add_argument(
        "--kill-existing",
        action="store_true",
        help="Kill any existing tmux session before starting a fresh instance.",
    )
    parser.add_argument(
        "--timeout",
        type=float,
        help=(
            "Override response timeout (seconds) used for wait_for_ready() "
            "(defaults to the value in config.yaml; Claude now uses 500s)."
        ),
    )
    parser.add_argument(
        "--check-interval",
        type=float,
        help="Override ready check interval (seconds).",
    )
    parser.add_argument(
        "--tail-lines",
        type=int,
        default=60,
        help="Number of trailing lines to print from the pane after completion.",
    )
    parser.add_argument(
        "--bootstrap",
        help="Shell command to run before launching the executable (safe worktree activation).",
    )
    parser.add_argument(
        "--enable-debug-wait",
        action="store_true",
        help="Force debug_wait_logging on for this run (overrides config setting).",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Only validate setup; do not send the prompt.",
    )
    return parser.parse_args(argv)


def build_controller(
    *,
    ai: str,
    session_name: str,
    working_dir: str | None,
    auto_start: bool,
    kill_existing: bool,
    bootstrap: str | None,
    enable_debug_wait: bool,
) -> TmuxController:
    config_loader = get_config()
    ai_section: Dict[str, object] = dict(config_loader.get_section(ai))
    if not ai_section:
        raise ValueError(f"No configuration section found for '{ai}'.")

    executable_value = ai_section.pop("executable", ai)
    exec_args_value = ai_section.pop("executable_args", [])
    if isinstance(exec_args_value, str):
        exec_args_value = shlex.split(exec_args_value)
    launch_executable = executable_value
    launch_args = list(exec_args_value)
    if enable_debug_wait:
        ai_section["debug_wait_logging"] = True

    if bootstrap:
        quoted_executable = shlex.quote(executable_value)
        quoted_args = " ".join(shlex.quote(arg) for arg in exec_args_value)
        command_tail = f"{quoted_executable} {quoted_args}".strip()
        shell_command = f"{bootstrap} && {command_tail}" if command_tail else f"{bootstrap} && {quoted_executable}"
        launch_executable = "bash"
        launch_args = ["-lc", shell_command]

    controller = TmuxController(
        session_name=session_name,
        executable=launch_executable,
        working_dir=working_dir,
        ai_config=ai_section,
        executable_args=launch_args,
    )
    controller.reset_output_cache()

    exists = controller.session_exists()
    if exists and kill_existing:
        if not controller.kill_session():
            raise SessionBackendError(f"Failed to kill existing session '{session_name}'.")
        exists = False

    if not exists:
        if not auto_start:
            raise SessionNotFoundError(
                f"Session '{session_name}' not found for {ai}. "
                "Start it manually or pass --auto-start."
            )
        controller.start()
        controller.reset_output_cache()
    else:
        controller.resume_automation(flush_pending=True)

    return controller


def main(argv: Sequence[str]) -> int:
    args = parse_args(argv)

    logging.basicConfig(level=logging.INFO, format="%(message)s")

    config_loader = get_config()
    tmux_section = config_loader.get_section("tmux")
    default_session = tmux_section.get(f"{args.ai}_session", args.ai)
    session_name = args.session or default_session

    try:
        controller = build_controller(
            ai=args.ai,
            session_name=session_name,
            working_dir=args.working_dir,
            auto_start=args.auto_start,
            kill_existing=args.kill_existing,
            bootstrap=args.bootstrap,
            enable_debug_wait=args.enable_debug_wait,
        )
    except (ValueError, SessionBackendError, SessionNotFoundError) as exc:
        print(f"[ERROR] {exc}", file=sys.stderr)
        return 1

    timeout = args.timeout or float(controller.config.get("response_timeout", 60.0))
    check_interval = args.check_interval or float(controller.config.get("ready_check_interval", 0.5))

    print(f"[INFO] Using wait_for_ready timeout: {timeout:.1f}s (interval {check_interval:.2f}s)")

    if args.dry_run:
        print(
            f"[DRY-RUN] Controller initialised for {args.ai} in session '{session_name}'. "
            "Skipping command dispatch."
        )
        return 0

    prompt = args.prompt.strip()
    if not prompt:
        print("[ERROR] Prompt is empty after stripping whitespace.", file=sys.stderr)
        return 1

    print(f"[INFO] Sending prompt to {args.ai} (session '{session_name}').")
    controller.reset_output_cache()
    start = time.time()
    try:
        controller.send_command(prompt, submit=True)
    except SessionBackendError as exc:
        print(f"[ERROR] Failed to send command: {exc}", file=sys.stderr)
        return 1

    ready = controller.wait_for_ready(timeout=timeout, check_interval=check_interval)
    elapsed = time.time() - start
    status = "ready" if ready else "timeout"
    print(f"[INFO] wait_for_ready result: {status} after {elapsed:.2f}s")

    try:
        pane_contents = controller.capture_output()
    except SessionBackendError as exc:
        print(f"[WARN] Unable to capture pane output: {exc}", file=sys.stderr)
        pane_contents = ""

    if pane_contents:
        lines = pane_contents.splitlines()
        tail = lines[-args.tail_lines :] if args.tail_lines else lines
        print("\n[INFO] Tail of pane output:")
        print("\n".join(tail))
    else:
        print("[INFO] No pane output captured.")

    return 0 if ready else 2


if __name__ == "__main__":
    sys.exit(main(sys.argv[1:]))
</file>

<file path="tests/test_auto_restart.py">
#!/usr/bin/env python3
"""
Test script for auto-restart functionality.
Tests the AutoRestarter and integration with tmux_controller.
"""
import sys
import time
from src.utils.auto_restart import AutoRestarter, RestartPolicy, RestartAttempt


# Test 1: Basic restart allowed
print("=" * 60)
print("Test 1: Basic restart allowed")
print("=" * 60)

restarter = AutoRestarter(policy=RestartPolicy.ON_FAILURE, max_restart_attempts=3)
should_restart = restarter.should_restart(reason="test")
print(f"Should restart: {should_restart}")
print(f"Can restart: {restarter.can_restart()}")

if should_restart and restarter.can_restart():
    print("✓ Restart allowed when policy permits\n")
else:
    print("✗ Restart should be allowed\n")
    sys.exit(1)


# Test 2: NEVER policy blocks restart
print("=" * 60)
print("Test 2: NEVER policy blocks restart")
print("=" * 60)

restarter_never = AutoRestarter(policy=RestartPolicy.NEVER)
should_restart = restarter_never.should_restart(reason="test")
print(f"Should restart: {should_restart}")

if not should_restart:
    print("✓ NEVER policy correctly blocks restart\n")
else:
    print("✗ NEVER policy should block restart\n")
    sys.exit(1)


# Test 3: Max attempts limit
print("=" * 60)
print("Test 3: Max attempts limit")
print("=" * 60)

restarter_limited = AutoRestarter(
    policy=RestartPolicy.ALWAYS,
    max_restart_attempts=3,
    restart_window=60.0,
    initial_backoff=0.1  # Fast for testing
)

restart_count = 0
def mock_restart_func():
    global restart_count
    restart_count += 1
    return True

# Perform 3 restarts
for i in range(3):
    result = restarter_limited.attempt_restart(mock_restart_func, reason=f"test_{i}", wait_before_restart=False)
    print(f"  Restart {i+1}: success={result}")

# Try 4th restart (should be blocked)
print("Attempting 4th restart (should be blocked)...")
result = restarter_limited.attempt_restart(mock_restart_func, reason="test_4", wait_before_restart=False)
print(f"  4th restart allowed: {result}")

stats = restarter_limited.get_stats()
print(f"Total restarts: {stats['total_restarts']}")
print(f"Attempts remaining: {stats['attempts_remaining']}")

if stats['total_restarts'] == 3 and stats['attempts_remaining'] == 0:
    print("✓ Max attempts limit enforced correctly\n")
else:
    print("✗ Max attempts limit not working\n")
    sys.exit(1)


# Test 4: Backoff calculation
print("=" * 60)
print("Test 4: Backoff calculation")
print("=" * 60)

restarter_backoff = AutoRestarter(
    policy=RestartPolicy.ON_FAILURE,
    initial_backoff=1.0,
    backoff_factor=2.0,
    max_backoff=10.0
)

# No attempts yet
backoff1 = restarter_backoff.calculate_backoff()
print(f"Initial backoff: {backoff1:.2f}s")

# Simulate failed attempts to test backoff growth
def mock_failing_restart():
    return False

restarter_backoff.attempt_restart(mock_failing_restart, reason="fail_1", wait_before_restart=False)
backoff2 = restarter_backoff.calculate_backoff()
print(f"After 1 failure: {backoff2:.2f}s (for 2nd attempt)")

restarter_backoff.attempt_restart(mock_failing_restart, reason="fail_2", wait_before_restart=False)
backoff3 = restarter_backoff.calculate_backoff()
print(f"After 2 failures: {backoff3:.2f}s (for 3rd attempt)")

# Backoff logic: initial_backoff * (backoff_factor ** (attempt_count - 1))
# With 0 attempts: 1.0 * (2.0 ** -1) = N/A, returns initial_backoff = 1.0
# With 1 attempt: 1.0 * (2.0 ** 0) = 1.0
# With 2 attempts: 1.0 * (2.0 ** 1) = 2.0
if backoff1 == 1.0 and backoff2 == 1.0 and backoff3 == 2.0:
    print("✓ Exponential backoff working correctly\n")
else:
    print(f"✗ Backoff not correct: expected 1.0, 1.0, 2.0 but got {backoff1}, {backoff2}, {backoff3}\n")
    sys.exit(1)


# Test 5: Success and failure tracking
print("=" * 60)
print("Test 5: Success and failure tracking")
print("=" * 60)

restarter_tracking = AutoRestarter(policy=RestartPolicy.ALWAYS, max_restart_attempts=10)

success_count = 0
fail_count = 0

def mock_mixed_restart():
    global success_count, fail_count
    # Succeed every other time
    if (success_count + fail_count) % 2 == 0:
        success_count += 1
        return True
    else:
        fail_count += 1
        return False

# Perform 6 restarts
for i in range(6):
    restarter_tracking.attempt_restart(mock_mixed_restart, reason=f"test_{i}", wait_before_restart=False)

stats = restarter_tracking.get_stats()
print(f"Successful restarts: {stats['successful_restarts']}")
print(f"Failed restarts: {stats['failed_restarts']}")
print(f"Success rate: {stats['success_rate']:.2%}")

if stats['successful_restarts'] == 3 and stats['failed_restarts'] == 3 and stats['success_rate'] == 0.5:
    print("✓ Success/failure tracking works correctly\n")
else:
    print("✗ Tracking not correct\n")
    sys.exit(1)


# Test 6: Restart window expiry
print("=" * 60)
print("Test 6: Restart window expiry")
print("=" * 60)

restarter_window = AutoRestarter(
    policy=RestartPolicy.ON_FAILURE,
    max_restart_attempts=2,
    restart_window=2.0,  # 2 second window
    initial_backoff=0.1
)

def mock_quick_restart():
    return True

# First restart
restarter_window.attempt_restart(mock_quick_restart, reason="test_1", wait_before_restart=False)
print(f"After 1st restart: attempts_remaining={restarter_window.get_stats()['attempts_remaining']}")

# Second restart
restarter_window.attempt_restart(mock_quick_restart, reason="test_2", wait_before_restart=False)
print(f"After 2nd restart: attempts_remaining={restarter_window.get_stats()['attempts_remaining']}")

# Wait for window to expire
print("Waiting for window to expire (2s)...")
time.sleep(2.1)

# Should be able to restart again
can_restart = restarter_window.can_restart()
print(f"After window expiry: can_restart={can_restart}")

if can_restart:
    print("✓ Restart window expiry works correctly\n")
else:
    print("✗ Should be able to restart after window expires\n")
    sys.exit(1)


# Test 7: History reset
print("=" * 60)
print("Test 7: History reset")
print("=" * 60)

restarter_reset = AutoRestarter(policy=RestartPolicy.ON_FAILURE)

# Perform some restarts
for i in range(3):
    restarter_reset.attempt_restart(mock_quick_restart, reason=f"test_{i}", wait_before_restart=False)

print(f"Before reset: total_restarts={restarter_reset.get_stats()['total_restarts']}")

# Reset history
restarter_reset.reset_history()

stats_after = restarter_reset.get_stats()
print(f"After reset: total_restarts={stats_after['total_restarts']}")
print(f"Recent attempts: {stats_after['recent_attempts_count']}")

if stats_after['total_restarts'] == 3 and stats_after['recent_attempts_count'] == 0:
    print("✓ History reset works correctly (keeps totals, clears recent)\n")
else:
    print("✗ History reset not working correctly\n")
    sys.exit(1)


# Test 8: Restart with actual delay
print("=" * 60)
print("Test 8: Restart with backoff delay")
print("=" * 60)

restarter_delay = AutoRestarter(
    policy=RestartPolicy.ON_FAILURE,
    initial_backoff=0.5,
    backoff_factor=2.0
)

start_time = time.time()
restarter_delay.attempt_restart(mock_quick_restart, reason="test_delay", wait_before_restart=True)
elapsed = time.time() - start_time

print(f"Restart with backoff took: {elapsed:.2f}s")

if elapsed >= 0.5 and elapsed < 1.0:
    print("✓ Backoff delay applied correctly\n")
else:
    print(f"✗ Delay incorrect (expected ~0.5s, got {elapsed:.2f}s)\n")
    sys.exit(1)


print("=" * 60)
print("All auto-restart tests passed! ✓")
print("=" * 60)
</file>

<file path="tests/test_automation_pause.py">
#!/usr/bin/env python3
"""
Smoke tests for the manual takeover lease/queue logic.
"""

from collections import deque
from typing import Sequence

from src.controllers.tmux_controller import TmuxController


class FakeResult:
    def __init__(self, returncode: int = 0, stdout: str = "", stderr: str = ""):
        self.returncode = returncode
        self.stdout = stdout
        self.stderr = stderr


class FakeTmuxController(TmuxController):
    """
    Minimal stand-in that skips real tmux interactions so we can exercise the
    automation gating logic deterministically.
    """

    def __init__(self):
        self._fake_clients: Sequence[str] = []
        self.sent_commands = deque()
        super().__init__(
            session_name="fake-session",
            executable="fake-cli",
            working_dir="/tmp"
        )

    # --- overrides ----------------------------------------------------- #

    def _verify_environment(self):
        """Skip environment verification for tests."""
        return

    def session_exists(self) -> bool:
        return True

    def _run_tmux_command(self, args):
        """
        Simulate tmux behavior for send-keys and capture commands.
        """
        if not args:
            return FakeResult(returncode=1, stderr="invalid command")

        cmd = args[0]
        if cmd == "send-keys":
            target = args[2] if len(args) > 2 else ""
            payload = args[3] if len(args) > 3 else ""
            if payload and payload != "Enter":
                self.sent_commands.append(payload)
            return FakeResult()
        if cmd == "capture-pane":
            return FakeResult(stdout="fake output")
        if cmd == "has-session":
            return FakeResult(returncode=0)
        if cmd == "list-clients":
            if self._fake_clients:
                return FakeResult(stdout="\n".join(self._fake_clients))
            return FakeResult(stdout="")
        if cmd == "kill-session":
            return FakeResult(returncode=0)

        return FakeResult()

    def list_clients(self) -> Sequence[str]:
        return list(self._fake_clients)

    # --- helpers ------------------------------------------------------- #

    def set_clients(self, clients):
        self._fake_clients = list(clients)


def main() -> int:
    print("=== Manual Takeover Lease Smoke Test ===")

    controller = FakeTmuxController()
    assert not controller.automation_paused
    assert controller.pending_command_count == 0

    print("1. Sending command with automation active...")
    assert controller.send_command("First command")
    assert list(controller.sent_commands) == ["First command"]

    print("2. Simulating manual client attachment...")
    controller.set_clients(["/dev/pts/1: user"])
    result = controller.send_command("Queued while manual")
    assert result is False, "Command should be queued, not executed"
    assert controller.pending_command_count == 1
    assert list(controller.sent_commands) == ["First command"]
    assert controller.automation_paused
    assert controller.automation_pause_reason == "manual-attach"

    print("3. Manual client detaches; new command should flush queue...")
    controller.set_clients([])
    assert controller.send_command("After manual detach")
    assert controller.pending_command_count == 0
    assert list(controller.sent_commands) == [
        "First command",
        "Queued while manual",
        "After manual detach",
    ]
    assert not controller.automation_paused

    print("=== All manual takeover lease checks passed ===")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
</file>

<file path="tests/test_backend_refactor.py">
#!/usr/bin/env python3
"""
Quick validation that TmuxController properly implements SessionBackend interface.
"""

from src.controllers.tmux_controller import TmuxController
from src.controllers.session_backend import SessionBackend, SessionSpec
import inspect

def test_interface_compliance():
    """Verify TmuxController implements all SessionBackend abstract methods."""

    print("=== SessionBackend Interface Compliance Test ===\n")

    # Check inheritance
    print("1. Checking inheritance...")
    assert issubclass(TmuxController, SessionBackend), "TmuxController must inherit from SessionBackend"
    print("   ✓ TmuxController inherits from SessionBackend\n")

    # Get all abstract methods from SessionBackend
    abstract_methods = {
        name for name, method in inspect.getmembers(SessionBackend, predicate=inspect.isfunction)
        if getattr(method, '__isabstractmethod__', False)
    }

    print("2. Checking abstract method implementation...")
    print(f"   Required methods: {sorted(abstract_methods)}\n")

    # Check each abstract method is implemented
    for method_name in abstract_methods:
        assert hasattr(TmuxController, method_name), f"Missing method: {method_name}"
        method = getattr(TmuxController, method_name)
        assert callable(method), f"{method_name} must be callable"
        print(f"   ✓ {method_name} implemented")

    print("\n3. Checking SessionSpec usage...")
    # Create a test instance
    controller = TmuxController(
        session_name="test-session",
        executable="echo",
        working_dir="/tmp"
    )

    # Verify spec attribute exists
    assert hasattr(controller, 'spec'), "Controller must have 'spec' attribute"
    assert isinstance(controller.spec, SessionSpec), "spec must be a SessionSpec instance"
    assert controller.spec.name == "test-session"
    assert controller.spec.executable == "echo"
    assert controller.spec.working_dir == "/tmp"
    print("   ✓ SessionSpec properly initialized\n")

    print("4. Checking backward compatibility...")
    assert hasattr(controller, 'session_name'), "Must maintain session_name attribute"
    assert hasattr(controller, 'executable'), "Must maintain executable attribute"
    assert hasattr(controller, 'working_dir'), "Must maintain working_dir attribute"
    assert controller.session_name == "test-session"
    assert controller.executable == "echo"
    assert controller.working_dir == "/tmp"
    print("   ✓ Backward compatible attributes preserved\n")

    print("5. Checking interface method signatures...")
    # Verify new interface methods exist
    interface_methods = [
        'start', 'send_text', 'send_enter', 'send_ctrl_c',
        'capture_output', 'capture_scrollback', 'list_clients',
        'attach', 'kill', 'session_exists', 'get_status'
    ]

    for method_name in interface_methods:
        assert hasattr(controller, method_name), f"Missing interface method: {method_name}"
        print(f"   ✓ {method_name} available")

    print("\n6. Checking legacy method compatibility...")
    legacy_methods = ['start_session', 'send_command', 'kill_session', 'attach_for_manual']
    for method_name in legacy_methods:
        assert hasattr(controller, method_name), f"Missing legacy method: {method_name}"
        print(f"   ✓ {method_name} available (backward compatibility)")

    print("\n" + "="*50)
    print("✅ ALL CHECKS PASSED - Interface refactoring successful!")
    print("="*50)

if __name__ == "__main__":
    try:
        test_interface_compliance()
    except AssertionError as e:
        print(f"\n❌ TEST FAILED: {e}")
        exit(1)
    except Exception as e:
        print(f"\n❌ UNEXPECTED ERROR: {e}")
        import traceback
        traceback.print_exc()
        exit(1)
</file>

<file path="tests/test_claude_refactored.py">
#!/usr/bin/env python3
"""
Test refactored ClaudeController to ensure Claude Code still works
"""

import sys
import time
from src.controllers.claude_controller import ClaudeController
from src.utils.path_helpers import get_tmux_worktree_path


def main():
    print("=== Testing Refactored Claude Controller ===\n")

    # Create controller using new ClaudeController class
    controller = ClaudeController(
        session_name="claude-refactor-test",
        working_dir=str(get_tmux_worktree_path())
    )

    print(f"1. Controller created")
    print(f"   Session: {controller.session_name}")
    print(f"   Executable: {controller.executable}")
    print(f"   Response marker: {controller.response_marker}\n")

    # Clean up any existing session
    if controller.session_exists():
        print("2. Cleaning up existing session...")
        controller.kill_session()
        time.sleep(1)

    # Start session
    print("3. Starting Claude Code session...")
    if controller.start_session():
        print("   ✓ Session started\n")
    else:
        print("   ✗ Failed to start session")
        return 1

    # Send command
    print("4. Sending command: 'What is 2 + 2?'")
    controller.send_command("What is 2 + 2?")
    print("   ✓ Command sent\n")

    # Wait for ready
    print("5. Waiting for response to complete...")
    if controller.wait_for_ready():
        print("   ✓ Response complete\n")
    else:
        print("   ⚠ Timeout waiting for response\n")

    # Capture output
    print("6. Capturing output:")
    output = controller.capture_output()
    print("   " + "\n   ".join(output.split("\n")[:20]))  # First 20 lines
    print()

    # Second command
    print("7. Sending second command: 'What is Python?'")
    controller.send_command("What is Python?")
    print("   ✓ Command sent\n")

    print("8. Waiting for response...")
    if controller.wait_for_ready():
        print("   ✓ Response complete\n")
    else:
        print("   ⚠ Timeout\n")

    # Final output
    print("9. Final output:")
    output = controller.capture_output()
    print("   " + "\n   ".join(output.split("\n")[:30]))  # First 30 lines
    print()

    # Cleanup
    print("10. Killing session...")
    if controller.kill_session():
        print("    ✓ Session killed\n")

    print("=== Test Complete ===")
    print("\n✅ Claude Code works with refactored controller!")
    return 0


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="tests/test_code_review_topic.py">
from pathlib import Path

import pytest

from examples.run_code_review_simulation import (
    InclusionStrategy,
    _format_display_path,
    build_topic,
    determine_inclusion_strategy,
)


def test_determine_strategy_small_file_embeds():
    strategy = determine_inclusion_strategy(
        line_count=10,
        size_bytes=200,
        embed_threshold=50,
        reference_threshold=100,
        size_threshold=5000,
    )
    assert strategy is InclusionStrategy.EMBED_FULL


def test_determine_strategy_medium_file_hybrid():
    strategy = determine_inclusion_strategy(
        line_count=75,
        size_bytes=3200,
        embed_threshold=50,
        reference_threshold=100,
        size_threshold=5000,
    )
    assert strategy is InclusionStrategy.HYBRID


def test_determine_strategy_large_file_reference_only():
    strategy = determine_inclusion_strategy(
        line_count=150,
        size_bytes=4100,
        embed_threshold=50,
        reference_threshold=100,
        size_threshold=5000,
    )
    assert strategy is InclusionStrategy.REFERENCE_ONLY


def test_determine_strategy_respects_size_threshold():
    strategy = determine_inclusion_strategy(
        line_count=40,
        size_bytes=6000,
        embed_threshold=50,
        reference_threshold=100,
        size_threshold=5000,
    )
    assert strategy is InclusionStrategy.REFERENCE_ONLY


@pytest.fixture()
def snippet_path(tmp_path: Path) -> Path:
    path = tmp_path / "example.py"
    path.write_text("print('hello')\nprint('world')\nprint('!')\n", encoding="utf-8")
    return path


def test_build_topic_embed_includes_code(snippet_path: Path):
    lines = ["print('hello')", "print('world')", "print('!')"]
    topic = build_topic(
        snippet_path,
        "TURN PLAN",
        lines,
        strategy=InclusionStrategy.EMBED_FULL,
        preview_lines=5,
    )
    display_path = _format_display_path(snippet_path)
    assert "```python" in topic
    assert "print('hello')" in topic
    assert f"@{display_path}" in topic


def test_build_topic_hybrid_shows_preview(snippet_path: Path):
    lines = [f"line_{idx}" for idx in range(10)]
    topic = build_topic(
        snippet_path,
        "TURN PLAN",
        lines,
        strategy=InclusionStrategy.HYBRID,
        preview_lines=3,
    )
    assert "Preview (first 3 of 10 lines shown)" in topic
    assert "(Preview truncated after 3 of 10 lines.)" in topic
    assert "```python" in topic


def test_build_topic_reference_only_has_no_code_block(snippet_path: Path):
    lines = [f"line_{idx}" for idx in range(5)]
    topic = build_topic(
        snippet_path,
        "TURN PLAN",
        lines,
        strategy=InclusionStrategy.REFERENCE_ONLY,
        preview_lines=3,
    )
    assert "```python" not in topic
    assert f"@{_format_display_path(snippet_path)}" in topic
</file>

<file path="tests/test_config.py">
#!/usr/bin/env python3
"""
Test configuration loader
"""

from src.utils.config_loader import ConfigLoader, get_config


def main():
    print("=== Configuration Loader Test ===\n")

    # Test loading config
    print("1. Loading configuration...")
    config = get_config()
    print(f"   ✓ Config loaded from: {config.config_path}\n")

    # Test getting values with dot notation
    print("2. Testing dot notation access:")
    test_cases = [
        ("claude.startup_timeout", "Startup timeout"),
        ("claude.response_timeout", "Response timeout"),
        ("tmux.capture_lines", "Capture lines"),
        ("tmux.session_prefix", "Session prefix"),
        ("logging.level", "Log level"),
        ("worktree.main_path", "Main worktree path"),
    ]

    for key_path, description in test_cases:
        value = config.get(key_path)
        print(f"   {description:20} ({key_path}): {value}")

    print()

    # Test getting sections
    print("3. Testing section access:")
    claude_config = config.get_section("claude")
    print(f"   Claude section keys: {list(claude_config.keys())}")

    tmux_config = config.get_section("tmux")
    print(f"   Tmux section keys: {list(tmux_config.keys())}\n")

    # Test default values
    print("4. Testing default values:")
    nonexistent = config.get("nonexistent.key", "DEFAULT_VALUE")
    print(f"   Nonexistent key with default: {nonexistent}\n")

    # Display test commands
    print("5. Available test commands:")
    simple_commands = config.get("test_commands.simple", [])
    for i, cmd in enumerate(simple_commands, 1):
        print(f"   {i}. {cmd}")

    print("\n=== Test Complete ===")


if __name__ == "__main__":
    main()
</file>

<file path="tests/test_controller_auto.py">
#!/usr/bin/env python3
"""
Automated test script for TmuxController (no user input required)
"""

import sys
import time
from src.controllers.tmux_controller import TmuxController
from src.utils.path_helpers import get_tmux_worktree_path


def main():
    # Use the worktree directory for testing
    worktree_dir = str(get_tmux_worktree_path())

    # Create controller
    controller = TmuxController(
        session_name="claude-test-auto",
        working_dir=worktree_dir
    )

    print("=== Automated Tmux Controller Test ===\n")

    # Clean up any existing session
    print("1. Cleaning up any existing session...")
    if controller.session_exists():
        controller.kill_session()
        time.sleep(1)
    print("   ✓ Clean state\n")

    # Start session
    print("2. Starting Claude Code session...")
    if controller.start_session(auto_confirm_trust=True):
        print("   ✓ Session started successfully\n")
    else:
        print("   ✗ Failed to start session")
        return 1

    # Check status
    print("3. Session status:")
    status = controller.get_status()
    for key, value in status.items():
        print(f"   {key}: {value}")
    print()

    # Test command sequence with proper timing
    print("4. Sending command: 'What is 2 + 2?'")
    controller.send_command("What is 2 + 2?")
    print("   ✓ Command sent\n")

    print("5. Waiting for response (5 seconds)...")
    time.sleep(5)

    print("6. Capturing output:")
    output = controller.capture_output()
    print("   " + "\n   ".join(output.split("\n")))
    print()

    # Second command with longer wait
    print("7. Sending command: 'What is Python?'")
    controller.send_command("What is Python?")
    print("   ✓ Command sent\n")

    print("8. Waiting for response (5 seconds)...")
    time.sleep(5)

    print("9. Capturing output:")
    output = controller.capture_output()
    print("   " + "\n   ".join(output.split("\n")))
    print()

    # Test Ctrl+C
    print("10. Testing Ctrl+C (cancel operation)...")
    controller.send_ctrl_c()
    time.sleep(1)
    print("    ✓ Ctrl+C sent\n")

    print("11. Capturing output after cancel:")
    output = controller.capture_output()
    print("   " + "\n   ".join(output.split("\n")))
    print()

    # Cleanup
    print("12. Killing session...")
    if controller.kill_session():
        print("    ✓ Session killed successfully\n")
    else:
        print("    ✗ Failed to kill session\n")

    print("=== Test Complete ===")
    return 0


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="tests/test_controller.py">
#!/usr/bin/env python3
"""
Simple test script for TmuxController

Tests basic functionality of the TmuxController class.
"""

import sys
import time
from src.controllers.tmux_controller import TmuxController
from src.utils.path_helpers import get_tmux_worktree_path


def main():
    # Use the worktree directory for testing
    worktree_dir = str(get_tmux_worktree_path())

    # Create controller
    controller = TmuxController(
        session_name="claude-test",
        working_dir=worktree_dir
    )

    print("=== Tmux Controller Test ===\n")

    # Test 1: Check if session already exists
    print("1. Checking for existing session...")
    if controller.session_exists():
        print("   ⚠️  Session already exists. Killing it first...")
        controller.kill_session()
        time.sleep(1)
    print("   ✓ No existing session\n")

    # Test 2: Start session
    print("2. Starting Claude Code session...")
    if controller.start_session(auto_confirm_trust=True):
        print("   ✓ Session started successfully\n")
    else:
        print("   ✗ Failed to start session")
        return 1

    # Test 3: Check status
    print("3. Checking session status...")
    status = controller.get_status()
    for key, value in status.items():
        print(f"   {key}: {value}")
    print()

    # Test 4: Send a simple command
    print("4. Sending test command: 'What is 2 + 2?'")
    if controller.send_command("What is 2 + 2?"):
        print("   ✓ Command sent successfully\n")
    else:
        print("   ✗ Failed to send command")
        return 1

    # Test 5: Wait and capture output
    print("5. Waiting for response (3 seconds)...")
    time.sleep(3)

    print("6. Capturing output...")
    output = controller.capture_output()
    print("   --- Output Start ---")
    print(output)
    print("   --- Output End ---\n")

    # Test 6: Send another command
    print("7. Sending second command: 'What is Python?'")
    if controller.send_command("What is Python?"):
        print("   ✓ Command sent successfully\n")
    else:
        print("   ✗ Failed to send command")
        return 1

    print("8. Waiting for response (3 seconds)...")
    time.sleep(3)

    print("9. Capturing output...")
    output = controller.capture_output()
    print("   --- Output Start ---")
    print(output)
    print("   --- Output End ---\n")

    # Test 7: Keep session alive or kill
    print("10. Session control options:")
    print("    - Press 'k' to kill the session")
    print("    - Press 'a' to attach to the session (read-only)")
    print("    - Press any other key to keep session alive and exit")

    choice = input("\n    Your choice: ").lower()

    if choice == 'k':
        print("\n    Killing session...")
        if controller.kill_session():
            print("    ✓ Session killed\n")
        else:
            print("    ✗ Failed to kill session\n")
    elif choice == 'a':
        print("\n    Attaching in read-only mode...")
        print("    (Press Ctrl+b, then d to detach)")
        controller.attach_for_manual(read_only=True)
        print("\n    Detached from session\n")
    else:
        print(f"\n    Session '{controller.session_name}' is still running")
        print(f"    To attach: tmux attach -t {controller.session_name}")
        print(f"    To kill: tmux kill-session -t {controller.session_name}\n")

    print("=== Test Complete ===")
    return 0


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="tests/test_dual_ai_observable.py">
#!/usr/bin/env python3
"""
Dual AI test with pauses for observation

Run this, then attach to both sessions to watch them work!
"""

import sys
import time
from src.controllers.claude_controller import ClaudeController
from src.controllers.gemini_controller import GeminiController
from src.utils.path_helpers import get_tmux_worktree_path, get_repo_root


def main():
    print("=" * 70)
    print("DUAL AI OBSERVABLE TEST - Claude Code + Gemini CLI")
    print("=" * 70)
    print()

    # Create both controllers
    claude = ClaudeController(
        session_name="claude-dual-test",
        working_dir=str(get_tmux_worktree_path())
    )

    gemini = GeminiController(
        session_name="gemini-dual-test",
        working_dir=str(get_repo_root())
    )

    print("1. Cleaning up any existing sessions...")
    for ai in [claude, gemini]:
        if ai.session_exists():
            ai.kill_session()
            time.sleep(1)
    print("   ✓ Clean\n")

    # Start both AIs
    print("2. Starting both AIs...")
    claude.start_session()
    gemini.start_session(auto_confirm_trust=False)
    print("   ✓ Both started\n")

    print("=" * 70)
    print("ATTACH NOW!")
    print("Terminal 1: tmux attach -t claude-dual-test -r")
    print("Terminal 2: tmux attach -t gemini-dual-test -r")
    print("=" * 70)
    print("\nWaiting 15 seconds for you to attach...")
    for i in range(15, 0, -1):
        print(f"  {i}...", end="\r")
        time.sleep(1)
    print("\n")

    # Test 1: Same question to both
    print("TEST 1: Asking both: 'What is 2 + 2?'")
    claude.send_command("What is 2 + 2?")
    gemini.send_command("What is 2 + 2?")
    print("  Commands sent. Waiting for responses...")
    claude.wait_for_ready()
    gemini.wait_for_ready()
    print("  ✓ Both responded\n")
    time.sleep(3)

    # Test 2: Different questions
    print("TEST 2: Different questions")
    print("  Claude: 'What is Python?'")
    claude.send_command("What is Python?")
    claude.wait_for_ready()
    print("  ✓ Claude responded\n")
    time.sleep(2)

    print("  Gemini: 'What is JavaScript?'")
    gemini.send_command("What is JavaScript?")
    gemini.wait_for_ready()
    print("  ✓ Gemini responded\n")
    time.sleep(3)

    # Test 3: Quick succession
    print("TEST 3: Quick succession on both")
    print("  Claude: 'List 3 colors'")
    claude.send_command("List 3 colors")
    time.sleep(1)

    print("  Gemini: 'List 3 animals'")
    gemini.send_command("List 3 animals")
    time.sleep(1)

    print("  Waiting for both...")
    claude.wait_for_ready()
    gemini.wait_for_ready()
    print("  ✓ Both completed\n")

    print("=" * 70)
    print("Tests complete! Sessions still running for your inspection.")
    print("=" * 70)
    print("\nTo kill sessions:")
    print("  tmux kill-session -t claude-dual-test")
    print("  tmux kill-session -t gemini-dual-test")
    print()

    return 0


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="tests/test_dual_ai.py">
#!/usr/bin/env python3
"""
Test both Claude and Gemini running simultaneously

This is the ultimate test - demonstrating multi-AI orchestration capability!
"""

import sys
import time
from src.controllers.claude_controller import ClaudeController
from src.controllers.gemini_controller import GeminiController
from src.utils.path_helpers import get_tmux_worktree_path, get_repo_root


def main():
    print("=" * 70)
    print("DUAL AI OPERATION TEST - Claude Code + Gemini CLI")
    print("=" * 70)
    print()

    # Create both controllers
    claude = ClaudeController(
        session_name="claude-dual-test",
        working_dir=str(get_tmux_worktree_path())
    )

    gemini = GeminiController(
        session_name="gemini-dual-test",
        working_dir=str(get_repo_root())
    )

    print("1. Controllers created:")
    print(f"   Claude: {claude.session_name} ({claude.response_marker})")
    print(f"   Gemini: {gemini.session_name} ({gemini.response_marker})\n")

    # Clean up
    for ai, name in [(claude, "Claude"), (gemini, "Gemini")]:
        if ai.session_exists():
            print(f"   Cleaning up existing {name} session...")
            ai.kill_session()
            time.sleep(1)

    # Start both AIs
    print("2. Starting both AIs simultaneously...")
    claude_started = claude.start_session()
    gemini_started = gemini.start_session(auto_confirm_trust=False)

    if claude_started and gemini_started:
        print("   ✅ Both AIs started successfully!\n")
    else:
        print("   ❌ Failed to start one or both AIs")
        return 1

    # Send same question to both
    question = "What is artificial intelligence?"
    print(f"3. Asking both AIs: '{question}'")
    claude.send_command(question)
    gemini.send_command(question)
    print("   ✓ Questions sent to both\n")

    # Wait for both to respond
    print("4. Waiting for Claude response...")
    if claude.wait_for_ready():
        print("   ✓ Claude ready\n")
    else:
        print("   ⚠ Claude timeout\n")

    print("5. Waiting for Gemini response...")
    if gemini.wait_for_ready():
        print("   ✓ Gemini ready\n")
    else:
        print("   ⚠ Gemini timeout\n")

    # Capture and display Claude's response
    print("6. Claude's response:")
    print("   " + "-" * 66)
    claude_output = claude.capture_output()
    # Extract just the response part
    for line in claude_output.split("\n"):
        if "●" in line or (line.strip() and not line.startswith(">")):
            if not any(skip in line for skip in ["▐▛███▜▌", "────", "? for shortcuts"]):
                print("   " + line)
    print("   " + "-" * 66)
    print()

    # Capture and display Gemini's response
    print("7. Gemini's response:")
    print("   " + "-" * 66)
    gemini_output = gemini.capture_output()
    # Extract just the response part
    for line in gemini_output.split("\n"):
        if "✦" in line or (line.strip() and ">" in line and "Type your message" not in line):
            if not any(skip in line for skip in ["███", "Tips for", "context left"]):
                print("   " + line)
    print("   " + "-" * 66)
    print()

    # Send different questions to each
    print("8. Sending different questions:")
    claude_q = "Name a programming language"
    gemini_q = "Name a color"

    print(f"   Claude: '{claude_q}'")
    claude.send_command(claude_q)
    claude.wait_for_ready()

    print(f"   Gemini: '{gemini_q}'")
    gemini.send_command(gemini_q)
    gemini.wait_for_ready()
    print("   ✓ Both responded\n")

    # Show sessions are independent
    print("9. Verifying independent sessions:")
    print(f"   Claude session exists: {claude.session_exists()}")
    print(f"   Gemini session exists: {gemini.session_exists()}\n")

    # Cleanup
    print("10. Cleaning up...")
    claude.kill_session()
    gemini.kill_session()
    print("    ✓ Both sessions terminated\n")

    print("=" * 70)
    print("🎉 SUCCESS! Claude Code and Gemini CLI operating simultaneously!")
    print("=" * 70)
    print("\nKey Achievements:")
    print("✅ Both AIs started in separate tmux sessions")
    print("✅ Both AIs responded to commands independently")
    print("✅ No interference between sessions")
    print("✅ Clean session management for both")
    print("\n🚀 Multi-AI orchestration foundation complete!")

    return 0


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="tests/test_gemini_controller.py">
#!/usr/bin/env python3
"""
Test GeminiController with refactored architecture
"""

import sys
import time
from src.controllers.gemini_controller import GeminiController
from src.utils.path_helpers import get_repo_root


def main():
    print("=== Testing Gemini Controller ===\n")

    # Create controller using new GeminiController class
    controller = GeminiController(
        session_name="gemini-controller-test",
        working_dir=str(get_repo_root())
    )

    print(f"1. Controller created")
    print(f"   Session: {controller.session_name}")
    print(f"   Executable: {controller.executable}")
    print(f"   Response marker: {controller.response_marker}")
    print(f"   Supports tools: {controller.supports_tools}\n")

    # Clean up any existing session
    if controller.session_exists():
        print("2. Cleaning up existing session...")
        controller.kill_session()
        time.sleep(1)

    # Start session
    print("3. Starting Gemini CLI session...")
    if controller.start_session(auto_confirm_trust=False):  # Gemini doesn't need trust confirmation
        print("   ✓ Session started\n")
    else:
        print("   ✗ Failed to start session")
        return 1

    # Send command
    print("4. Sending command: 'What is 2 + 2?'")
    controller.send_command("What is 2 + 2?")
    print("   ✓ Command sent\n")

    # Wait for ready
    print("5. Waiting for response to complete...")
    if controller.wait_for_ready():
        print("   ✓ Response complete\n")
    else:
        print("   ⚠ Timeout waiting for response\n")

    # Capture output
    print("6. Capturing output:")
    output = controller.capture_output()
    print("   " + "\n   ".join(output.split("\n")[:25]))  # First 25 lines
    print()

    # Second command
    print("7. Sending second command: 'List 3 colors'")
    controller.send_command("List 3 colors")
    print("   ✓ Command sent\n")

    print("8. Waiting for response...")
    if controller.wait_for_ready():
        print("   ✓ Response complete\n")
    else:
        print("   ⚠ Timeout\n")

    # Final output
    print("9. Final output:")
    output = controller.capture_output()
    print("   " + "\n   ".join(output.split("\n")[:35]))  # First 35 lines
    print()

    # Cleanup
    print("10. Killing session...")
    if controller.kill_session():
        print("    ✓ Session killed\n")

    print("=== Test Complete ===")
    print("\n✅ Gemini CLI works with new controller!")
    return 0


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="tests/test_gemini_input.py">
#!/usr/bin/env python3
"""
Focused Gemini CLI input probe.

Launches (or attaches to) the Gemini tmux session, injects a single prompt,
and prints pane snapshots so we can verify whether text and the submit key
are being delivered as expected.
"""

from __future__ import annotations

import argparse
import sys
import time
from pathlib import Path
from typing import Optional

from src.controllers.gemini_controller import GeminiController
from src.controllers.tmux_controller import (
    SessionBackendError,
    SessionNotFoundError,
)
from src.utils.config_loader import get_config


def capture_tail(controller: GeminiController, max_lines: int) -> str:
    """Return the last ``max_lines`` from the pane for quick inspection."""
    try:
        snapshot = controller.capture_output()
    except (SessionNotFoundError, SessionBackendError):
        return "<capture failed>"
    lines = snapshot.splitlines()
    tail = lines[-max_lines:] if max_lines else lines
    return "\n".join(tail)


def build_controller(session_name: str, working_dir: Optional[str]) -> GeminiController:
    """Create a GeminiController with config defaults."""
    controller = GeminiController(
        session_name=session_name,
        working_dir=working_dir,
    )
    controller.reset_output_cache()
    return controller


def parse_args(argv: list[str]) -> argparse.Namespace:
    cfg = get_config()
    tmux_cfg = cfg.get_section("tmux")
    default_session = tmux_cfg.get("gemini_session", "gemini")
    default_cwd = Path.cwd()

    parser = argparse.ArgumentParser(
        description="Send a single prompt to Gemini and inspect tmux behaviour."
    )
    parser.add_argument(
        "--session",
        default=default_session,
        help=f"Tmux session name for Gemini (default: {default_session}).",
    )
    parser.add_argument(
        "--working-dir",
        default=str(default_cwd),
        help="Working directory for the session (default: current directory).",
    )
    parser.add_argument(
        "--prompt",
        default=(
            "gemini, respond only with: 'Hello from gemini — message received.' "
            "Do not run tools or reference previous steps. Confirm you saw this message and stop."
        ),
        help="Prompt text to send to Gemini.",
    )
    parser.add_argument(
        "--auto-start",
        action="store_true",
        help="Launch the Gemini session automatically if it is not running.",
    )
    parser.add_argument(
        "--kill-existing",
        action="store_true",
        help="Kill any existing session with the chosen name before starting.",
    )
    parser.add_argument(
        "--startup-timeout",
        type=int,
        default=20,
        help="Seconds to wait for session startup readiness checks.",
    )
    parser.add_argument(
        "--response-timeout",
        type=int,
        default=60,
        help="Seconds to wait for Gemini to finish responding.",
    )
    parser.add_argument(
        "--wait-before-send",
        type=float,
        default=0.0,
        help="Seconds to sleep after ensuring the session is ready but before sending the prompt (attach window).",
    )
    parser.add_argument(
        "--tail-lines",
        type=int,
        default=40,
        help="Number of pane lines to show for snapshots (default: 40).",
    )
    parser.add_argument(
        "--preview-only",
        action="store_true",
        help="Do not send Enter after injecting text; useful for observing the buffer before submission.",
    )
    parser.add_argument(
        "--skip-wait",
        action="store_true",
        help="Do not call wait_for_ready() after sending the command.",
    )
    return parser.parse_args(argv)


def main(argv: list[str]) -> int:
    args = parse_args(argv)

    controller = build_controller(args.session, args.working_dir)
    controller.startup_timeout = args.startup_timeout
    controller.response_timeout = args.response_timeout

    if args.kill_existing and controller.session_exists():
        print(f"[info] Killing existing session '{args.session}'...")
        try:
            controller.kill()
        except SessionBackendError as exc:
            print(f"[error] Failed to kill existing session: {exc}", file=sys.stderr)
            return 1
        time.sleep(1)

    if not controller.session_exists():
        if not args.auto_start:
            print(
                f"[error] Session '{args.session}' not found. "
                "Start it manually or pass --auto-start.",
                file=sys.stderr,
            )
            return 1
        print(f"[info] Starting Gemini session '{args.session}'...")
        try:
            controller.start()
        except SessionBackendError as exc:
            print(f"[error] Failed to start session: {exc}", file=sys.stderr)
            return 1
        if not controller.wait_for_ready(timeout=args.startup_timeout):
            print("[warn] Startup ready check timed out; continuing anyway.")

    controller.resume_automation(flush_pending=True)

    if args.wait_before_send > 0:
        print(
            f"[info] Waiting {args.wait_before_send:.1f}s before sending prompt "
            "so you can attach with 'tmux attach -t {session} -r'."
        )
        time.sleep(args.wait_before_send)

    print("[snapshot] Pane tail BEFORE send:")
    print(capture_tail(controller, args.tail_lines))
    print("-" * 60)

    if args.preview_only:
        print("[action] Injecting text without Enter (preview-only mode).")
        controller.send_text(args.prompt)
        print("[snapshot] Pane tail AFTER text injection:")
        print(capture_tail(controller, args.tail_lines))
        print(
            "[note] Prompt inserted without submitting. Inspect the session and "
            "press Enter manually if desired."
        )
        return 0

    print(f"[action] Sending prompt (length {len(args.prompt)} chars)...")
    sent = controller.send_command(args.prompt)
    print(f"[action] controller.send_command returned {sent}")

    print("[snapshot] Pane tail AFTER send_command:")
    print(capture_tail(controller, args.tail_lines))
    print("-" * 60)

    if not args.skip_wait:
        print("[info] Waiting for Gemini to finish responding...")
        ready = controller.wait_for_ready(timeout=args.response_timeout)
        print(f"[info] wait_for_ready returned {ready}")
    else:
        ready = False

    output = controller.get_last_output(tail_lines=args.tail_lines)
    print("[delta] Output since send_command:")
    print(output or "<no new output captured>")

    return 0


if __name__ == "__main__":
    sys.exit(main(sys.argv[1:]))
</file>

<file path="tests/test_gemini_output_parser.py">
#!/usr/bin/env python3
"""
Test OutputParser with Gemini CLI output

Verify that OutputParser can handle Gemini's different response format
"""

import sys
import time
from src.utils.output_parser import OutputParser
from src.controllers.gemini_controller import GeminiController
from src.utils.path_helpers import get_repo_root

# Sample Gemini output from our tests
WORKDIR_DISPLAY = str(get_repo_root())

SAMPLE_GEMINI_OUTPUT = f"""
 ███            █████████  ██████████ ██████   ██████ █████ ██████   █████ █████
░░░███         ███░░░░░███░░███░░░░░█░░██████ ██████ ░░███ ░░██████ ░░███ ░░███
  ░░░███      ███     ░░░  ░███  █ ░  ░███░█████░███  ░███  ░███░███ ░███  ░███
    ░░░███   ░███          ░██████    ░███░░███ ░███  ░███  ░███░░███░███  ░███

Tips for getting started:
1. Ask questions, edit files, or run commands.

╭────────────────────╮
│  > What is 2 + 2?  │
╰────────────────────╯

✦ 4

╭─────────────────────╮
│  > What is Python?  │
╰─────────────────────╯

✦ Python is a high-level, interpreted programming language known for its readability and versatility. It is
  widely used for web development, data analysis, artificial intelligence, scientific computing, and
  automation.

╭──────────────────────────────────╮
│  > List 3 programming languages  │
╰──────────────────────────────────╯

✦ 1. Python
  2. JavaScript
  3. Java

Using: 2 GEMINI.md files
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ >   Type your message or @path/to/file                                                                   │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────╯
{WORKDIR_DISPLAY}            no sandbox (see     gemini-2.5-pro (99% context
(GeminiDev*)                                            /docs)             left)
"""


def main():
    print("=== Testing OutputParser with Gemini Output ===\n")

    parser = OutputParser()

    # Test 1: Clean output
    print("1. Testing output cleaning:")
    cleaned = parser.clean_output(SAMPLE_GEMINI_OUTPUT)
    print("   --- Cleaned Output ---")
    print(cleaned)
    print("   --- End ---\n")

    # Test 2: Extract Q&A pairs
    print("2. Testing Q&A extraction with Gemini's ✦ marker:")
    pairs = parser.extract_responses(SAMPLE_GEMINI_OUTPUT)
    print(f"   Found {len(pairs)} question/answer pairs (expected 3):\n")

    for i, pair in enumerate(pairs, 1):
        print(f"   Pair {i}:")
        print(f"     Q: {pair['question']}")
        print(f"     A: {pair['response'][:60]}..." if len(pair['response']) > 60 else f"     A: {pair['response']}")
        print()

    # Check for duplicates
    questions = [p['question'] for p in pairs]
    if len(questions) != len(set(questions)):
        print("   ⚠ WARNING: Duplicate questions detected!")

    # Test 3: Get last response
    print("3. Testing last response extraction:")
    last_response = parser.get_last_response(SAMPLE_GEMINI_OUTPUT)
    print(f"   Last response: {last_response}\n")

    # Test 4: Get last question
    print("4. Testing last question extraction:")
    last_question = parser.get_last_question(SAMPLE_GEMINI_OUTPUT)
    print(f"   Last question: {last_question}\n")

    # Test 5: Live test with actual Gemini session
    print("5. LIVE TEST: Testing with actual Gemini session...")
    print("   Starting Gemini...")

    controller = GeminiController(
        session_name="gemini-parser-test",
        working_dir=WORKDIR_DISPLAY
    )

    # Clean up existing
    if controller.session_exists():
        controller.kill_session()
        time.sleep(1)

    controller.start_session(auto_confirm_trust=False)
    print("   ✓ Gemini started")
    print("\n   ATTACH NOW: tmux attach -t gemini-parser-test -r")
    print("   Waiting 10 seconds for you to attach...")
    for i in range(10, 0, -1):
        print(f"   {i}...", end="\r")
        time.sleep(1)
    print("\n")

    # Send test command
    print("   Sending: 'What is the capital of France?'")
    controller.send_command("What is the capital of France?")
    print("   Waiting for response...")
    controller.wait_for_ready()
    print("   ✓ Response received")

    print("\n   Pausing 5 seconds so you can see the result...")
    time.sleep(5)

    # Capture and parse
    output = controller.capture_output()
    print(f"   Raw output length: {len(output)} characters")
    print(f"   Full output:")
    print("   " + "\n   ".join(output.split("\n")))
    print()

    pairs = parser.extract_responses(output)

    print(f"   Extracted {len(pairs)} pairs from live session:\n")
    if pairs:
        for pair in pairs:
            print(f"     Q: {pair['question']}")
            print(f"     A: {pair['response']}")
            print()

    # Cleanup
    controller.kill_session()
    print("   ✓ Session cleaned up\n")

    # Final verdict
    print("=" * 70)
    if len(pairs) > 0:
        print("✅ SUCCESS: OutputParser works with Gemini!")
        print("   - Handles ✦ marker correctly")
        print("   - Extracts Q&A pairs properly")
        print("   - Compatible with Gemini's box format")
        return 0
    else:
        print("❌ ISSUE: Parser may need updates for Gemini format")
        return 1


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="tests/test_health_check.py">
#!/usr/bin/env python3
"""
Test script for health check functionality.
Tests the HealthChecker and integration with tmux_controller.
"""
import sys
import time
from src.utils.health_check import HealthChecker, HealthCheckResult


# Test 1: Basic session exists check
print("=" * 60)
print("Test 1: Basic session exists check")
print("=" * 60)

checker = HealthChecker(check_interval=5.0, max_failed_checks=3)

# Simulate healthy session
def mock_session_exists_healthy():
    return True

result = checker.check_session_exists(mock_session_exists_healthy)
print(f"Check type: {result.check_type}")
print(f"Healthy: {result.healthy}")
print(f"Consecutive failures: {checker.consecutive_failures}")
print(f"Is healthy: {checker.is_healthy()}")

if result.healthy and checker.is_healthy():
    print("✓ Session exists check passed\n")
else:
    print("✗ Session exists check failed\n")
    sys.exit(1)


# Test 2: Failed session check
print("=" * 60)
print("Test 2: Failed session check")
print("=" * 60)

def mock_session_exists_dead():
    return False

result = checker.check_session_exists(mock_session_exists_dead)
print(f"Healthy: {result.healthy}")
print(f"Error: {result.error_message}")
print(f"Consecutive failures: {checker.consecutive_failures}")
print(f"Is healthy: {checker.is_healthy()}")

if not result.healthy and result.error_message == "Session does not exist":
    print("✓ Failed session detected correctly\n")
else:
    print("✗ Failed session not detected\n")
    sys.exit(1)


# Test 3: Consecutive failure threshold
print("=" * 60)
print("Test 3: Consecutive failure threshold")
print("=" * 60)

checker2 = HealthChecker(max_failed_checks=3)

print("Failing 3 consecutive checks...")
for i in range(3):
    result = checker2.check_session_exists(mock_session_exists_dead)
    print(f"  Check {i+1}: failures={checker2.consecutive_failures}, healthy={checker2.is_healthy()}")

if not checker2.is_healthy():
    print("✓ Unhealthy status after threshold exceeded\n")
else:
    print("✗ Should be unhealthy after 3 failures\n")
    sys.exit(1)


# Test 4: Recovery after failure
print("=" * 60)
print("Test 4: Recovery after failure")
print("=" * 60)

checker3 = HealthChecker(max_failed_checks=3)

# Fail twice
for i in range(2):
    checker3.check_session_exists(mock_session_exists_dead)
print(f"After 2 failures: consecutive={checker3.consecutive_failures}, healthy={checker3.is_healthy()}")

# Then succeed
result = checker3.check_session_exists(mock_session_exists_healthy)
print(f"After recovery: consecutive={checker3.consecutive_failures}, healthy={checker3.is_healthy()}")

if checker3.consecutive_failures == 0 and checker3.is_healthy():
    print("✓ Recovery from failures works correctly\n")
else:
    print("✗ Recovery failed\n")
    sys.exit(1)


# Test 5: Output responsive check
print("=" * 60)
print("Test 5: Output responsive check")
print("=" * 60)

checker4 = HealthChecker()

def mock_capture_good_output():
    return "This is sufficient output for the health check"

def mock_capture_insufficient_output():
    return "Short"

result = checker4.check_output_responsive(mock_capture_good_output, min_output_length=10)
print(f"Good output - Healthy: {result.healthy}, length: {result.details['output_length']}")

result = checker4.check_output_responsive(mock_capture_insufficient_output, min_output_length=10)
print(f"Insufficient output - Healthy: {result.healthy}, length: {result.details['output_length']}")
print(f"Error: {result.error_message}")

if result.error_message and "Insufficient output" in result.error_message:
    print("✓ Output responsive check works correctly\n")
else:
    print("✗ Output responsive check failed\n")
    sys.exit(1)


# Test 6: Command echo check
print("=" * 60)
print("Test 6: Command echo check")
print("=" * 60)

checker5 = HealthChecker(response_timeout=2.0)

def mock_send_command(cmd):
    return True

def mock_wait_ready(timeout):
    time.sleep(0.1)  # Simulate brief processing
    return True

def mock_capture_with_echo():
    return "Previous output\n# health_check\nMore output"

result = checker5.check_command_echo(
    send_command_func=mock_send_command,
    wait_func=mock_wait_ready,
    capture_func=mock_capture_with_echo,
    test_command="# health_check"
)

print(f"Healthy: {result.healthy}")
print(f"Command found: {result.details.get('command_found')}")
print(f"Elapsed: {result.details.get('elapsed_time'):.3f}s")

if result.healthy and result.details.get('command_found'):
    print("✓ Command echo check works correctly\n")
else:
    print("✗ Command echo check failed\n")
    sys.exit(1)


# Test 7: Health check statistics
print("=" * 60)
print("Test 7: Health check statistics")
print("=" * 60)

checker6 = HealthChecker()

# Perform mix of checks
checker6.check_session_exists(mock_session_exists_healthy)
checker6.check_session_exists(mock_session_exists_healthy)
checker6.check_session_exists(mock_session_exists_dead)
checker6.check_session_exists(mock_session_exists_healthy)

stats = checker6.get_stats()
print(f"Total checks: {stats['total_checks']}")
print(f"Total failures: {stats['total_failures']}")
print(f"Success rate: {stats['success_rate']:.2%}")
print(f"Consecutive failures: {stats['consecutive_failures']}")
print(f"Is healthy: {stats['is_healthy']}")

if stats['total_checks'] == 4 and stats['total_failures'] == 1 and stats['success_rate'] == 0.75:
    print("✓ Statistics tracking works correctly\n")
else:
    print("✗ Statistics tracking failed\n")
    sys.exit(1)


# Test 8: Should check interval
print("=" * 60)
print("Test 8: Should check interval")
print("=" * 60)

checker7 = HealthChecker(check_interval=1.0)

# First check should always run
should_check1 = checker7.should_check()
print(f"Before any check: should_check={should_check1}")

# Run a check
checker7.check_session_exists(mock_session_exists_healthy)

# Immediately after, should not check
should_check2 = checker7.should_check()
print(f"Immediately after check: should_check={should_check2}")

# Wait for interval
time.sleep(1.1)
should_check3 = checker7.should_check()
print(f"After interval: should_check={should_check3}")

if should_check1 and not should_check2 and should_check3:
    print("✓ Check interval logic works correctly\n")
else:
    print("✗ Check interval logic failed\n")
    sys.exit(1)


print("=" * 60)
print("All health check tests passed! ✓")
print("=" * 60)
</file>

<file path="tests/test_manual_together.py">
#!/usr/bin/env python3
"""
Manual interactive test - works together with user observation

This script will:
1. Start a Claude Code session
2. Pause so you can attach and observe
3. Send commands one at a time with pauses between
4. Keep session alive at the end for inspection
"""

import sys
import time
from src.controllers.tmux_controller import TmuxController
from src.utils.path_helpers import get_tmux_worktree_path


def main():
    worktree_dir = str(get_tmux_worktree_path())

    controller = TmuxController(
        session_name="claude-manual-test",
        working_dir=worktree_dir
    )

    print("=== Manual Interactive Test ===\n")

    # Clean up
    if controller.session_exists():
        print("Cleaning up existing session...")
        controller.kill_session()
        time.sleep(1)

    # Start session
    print("Starting Claude Code session...")
    if not controller.start_session(auto_confirm_trust=True):
        print("Failed to start session!")
        return 1

    print(f"✓ Session '{controller.session_name}' started!\n")
    print("=" * 60)
    print("ATTACH NOW to observe:")
    print(f"  tmux attach -t {controller.session_name} -r")
    print("=" * 60)
    print("\nWaiting 10 seconds for you to attach...")

    for i in range(10, 0, -1):
        print(f"  {i}...", end="\r")
        time.sleep(1)
    print("\n")

    # Test 1
    print("TEST 1: Sending 'What is 2 + 2?'")
    controller.send_command("What is 2 + 2?")
    print("  Waiting for response to complete...")
    if controller.wait_for_ready(timeout=30):
        print("  ✓ Response complete and ready for next command\n")
    else:
        print("  ⚠ Timeout waiting for ready state\n")

    # Test 2
    print("TEST 2: Sending 'What is Python?'")
    controller.send_command("What is Python?")
    print("  Waiting for response to complete...")
    if controller.wait_for_ready(timeout=30):
        print("  ✓ Response complete and ready for next command\n")
    else:
        print("  ⚠ Timeout waiting for ready state\n")

    # Test 3
    print("TEST 3: Sending 'List 3 programming languages'")
    controller.send_command("List 3 programming languages")
    print("  Waiting for response to complete...")
    if controller.wait_for_ready(timeout=30):
        print("  ✓ Response complete and ready for next command\n")
    else:
        print("  ⚠ Timeout waiting for ready state\n")

    # Capture final state
    print("Capturing final output:")
    print("-" * 60)
    output = controller.capture_scrollback()
    # Show last 30 lines
    lines = output.split("\n")
    for line in lines[-30:]:
        print(line)
    print("-" * 60)
    print()

    # Keep alive
    print("=" * 60)
    print(f"Session '{controller.session_name}' is still running!")
    print(f"  To attach: tmux attach -t {controller.session_name} -r")
    print(f"  To kill: tmux kill-session -t {controller.session_name}")
    print("=" * 60)
    print("\nTest complete. Session kept alive for your inspection.")

    return 0


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="tests/test_orchestrator_automation.py">
#!/usr/bin/env python3
"""
Smoke test for DevelopmentTeamOrchestrator automation awareness.
"""

from collections import deque
from typing import Deque, List, Tuple

from src.orchestrator.orchestrator import DevelopmentTeamOrchestrator


class FakeController:
    """
    Minimal controller stub that exposes the orchestrator-facing surface.
    """

    def __init__(self) -> None:
        self.sent: List[Tuple[str, bool]] = []
        self._paused: bool = False
        self._manual_clients: List[str] = []
        self._reason: str | None = None
        self._internal_queue: Deque[Tuple[str, bool]] = deque()
        self.pause_on_send: bool = False

    # --- Controller contract -------------------------------------------------

    def get_status(self):
        return {
            "automation": {
                "paused": self._paused,
                "reason": self._reason,
                "pending_commands": len(self._internal_queue),
                "manual_clients": list(self._manual_clients),
            }
        }

    def send_command(self, command: str, submit: bool = True) -> bool:
        if self.pause_on_send:
            # Simulate a pause being detected while sending
            self.pause_on_send = False
            self._paused = True
            self._reason = "manual-attach"
            self._manual_clients = ["tmux-client"]
            self._internal_queue.append((command, submit))
            return False

        if self._paused:
            # Mirror TmuxController behaviour: queue internally and return False
            self._internal_queue.append((command, submit))
            return False

        self.sent.append((command, submit))
        return True

    # --- Helpers -------------------------------------------------------------

    def set_manual_pause(self, paused: bool, reason: str | None = None, client: str | None = None) -> None:
        self._paused = paused
        self._reason = reason
        self._manual_clients = [client] if paused and client else []
        if not paused:
            self.flush_internal_queue()

    def flush_internal_queue(self) -> None:
        while self._internal_queue and not self._paused:
            command, submit = self._internal_queue.popleft()
            self.sent.append((command, submit))


def main() -> int:
    print("=== Orchestrator Automation Awareness Smoke Test ===")

    controller = FakeController()
    orchestrator = DevelopmentTeamOrchestrator({"claude": controller})

    # Command should dispatch immediately when automation is active
    result = orchestrator.dispatch_command("claude", "Initial command")
    assert result["dispatched"] and not result["queued"]
    assert controller.sent == [("Initial command", True)]
    assert orchestrator.get_pending_command_count("claude") == 0

    # When paused, commands should be queued by the orchestrator
    controller.set_manual_pause(True, reason="manual-attach", client="tmux-client")
    result = orchestrator.dispatch_command("claude", "Queued command 1")
    assert not result["dispatched"] and result["queued"]
    assert result["queue_source"] == "orchestrator"
    assert orchestrator.get_pending_command_count("claude") == 1

    orchestrator.dispatch_command("claude", "Queued command 2")
    assert orchestrator.get_pending_command_count("claude") == 2

    # Automation resumes; orchestrator should flush its queue
    controller.set_manual_pause(False)
    summary = orchestrator.process_pending("claude")
    assert summary["flushed"] == 2
    assert orchestrator.get_pending_command_count("claude") == 0
    assert controller.sent[-2:] == [("Queued command 1", True), ("Queued command 2", True)]

    # Pause occurs during dispatch (controller queues internally)
    controller.pause_on_send = True
    result = orchestrator.dispatch_command("claude", "Controller queued command")
    assert not result["dispatched"] and result["queued"]
    assert result["queue_source"] == "controller"
    assert len(controller.sent) == 3  # no new send recorded yet
    assert len(controller._internal_queue) == 1

    # Automation resumes; controller flushes internally
    controller.set_manual_pause(False)
    assert len(controller.sent) == 4
    assert controller.sent[-1] == ("Controller queued command", True)

    print("=== All orchestrator automation checks passed ===")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
</file>

<file path="tests/test_orchestrator_discussion_pause.py">
#!/usr/bin/env python3
"""
Integration-flavoured tests for orchestrator-driven conversations with pauses.
"""

from collections import deque
from typing import Deque, Dict, List, Tuple

from src.orchestrator.conversation_manager import ConversationManager
from src.orchestrator.context_manager import ContextManager
from src.orchestrator.message_router import MessageRouter
from src.orchestrator.orchestrator import DevelopmentTeamOrchestrator


class PauseAwareController:
    """
    Test double that mimics TmuxController automation behaviour.

    - Exposes automation pause metadata.
    - Returns False from send_command while paused (forcing orchestrator queueing).
    - Produces deterministic outputs in FIFO order when commands execute.
    """

    def __init__(self, responses: List[str]) -> None:
        self.sent: List[str] = []
        self._responses: Deque[str] = deque(responses)
        self._last_output: str | None = None
        self._paused: bool = False
        self._pause_reason: str | None = None
        self._manual_clients: List[str] = []

    def get_status(self) -> Dict[str, Dict[str, object]]:
        return {
            "automation": {
                "paused": self._paused,
                "reason": self._pause_reason,
                "pending_commands": 0,
                "manual_clients": list(self._manual_clients),
            }
        }

    def send_command(self, command: str, submit: bool = True) -> bool:
        if self._paused:
            return False
        self.sent.append(command)
        self._last_output = self._responses.popleft() if self._responses else ""
        return True

    def get_last_output(self) -> str | None:
        return self._last_output

    def set_paused(
        self,
        paused: bool,
        *,
        reason: str | None = None,
        manual_clients: List[str] | None = None,
    ) -> None:
        self._paused = paused
        self._pause_reason = reason
        self._manual_clients = manual_clients or []

    def wait_for_ready(self, timeout: float | None = None, check_interval: float | None = None) -> bool:
        return True


def test_discussion_pause_and_resume_flow() -> None:
    claude_controller = PauseAwareController(
        ["Claude initial proposal.", "Claude acknowledges Gemini."]
    )
    gemini_controller = PauseAwareController(
        ["Gemini flush response after resume.", "Gemini detailed follow-up."]
    )
    gemini_controller.set_paused(True, reason="manual-attach", manual_clients=["tmux-client"])

    orchestrator = DevelopmentTeamOrchestrator(
        {"claude": claude_controller, "gemini": gemini_controller}
    )
    context_manager = ContextManager(history_size=10)
    router = MessageRouter(["claude", "gemini"], context_manager=context_manager)
    manager = ConversationManager(
        orchestrator,
        ["claude", "gemini"],
        context_manager=context_manager,
        message_router=router,
    )

    # Phase 1: Gemini is paused, so her turn should be queued and conversation halts.
    phase_one = manager.facilitate_discussion("Coordinate rollout", max_turns=3)
    assert [turn["speaker"] for turn in phase_one] == ["claude", "gemini"]
    assert phase_one[-1]["metadata"]["queued"] is True
    assert orchestrator.get_pending_command_count("gemini") == 1

    # Resume automation and allow orchestrator to flush the queued command.
    gemini_controller.set_paused(False)
    flush_summary = orchestrator.process_pending("gemini")
    assert flush_summary["flushed"] == 1
    assert orchestrator.get_pending_command_count("gemini") == 0
    assert gemini_controller.get_last_output() == "Gemini flush response after resume."

    # Phase 2: Conversation resumes; Gemini speaks first, then Claude responds using routed context.
    phase_two = manager.facilitate_discussion("Coordinate rollout", max_turns=2)
    assert [turn["speaker"] for turn in phase_two] == ["gemini", "claude"]
    assert phase_two[0]["response"] == "Gemini detailed follow-up."

    # Router should have injected Gemini's follow-up into Claude's prompt.
    assert "Gemini detailed follow-up." in claude_controller.sent[-1]

    # Context manager tracks the full history.
    assert len(context_manager.history) == 4
    assert context_manager.history[-1]["speaker"] == "claude"
</file>

<file path="tests/test_output_parser.py">
#!/usr/bin/env python3
"""
Test OutputParser with real Claude Code output
"""

from src.utils.output_parser import OutputParser
from src.utils.path_helpers import get_tmux_worktree_path

# Sample output from our actual tests
WORKDIR_DISPLAY = str(get_tmux_worktree_path())

SAMPLE_OUTPUT = f"""
 ▐▛███▜▌   Claude Code v2.0.8
▝▜█████▛▘  Sonnet 4.5 · Claude Pro
  ▘▘ ▝▝    {WORKDIR_DISPLAY}

> What is 2 + 2?

● 4

> What is Python?

● Python is a high-level, interpreted programming language known for its simple syntax, readability, and
  versatility. It's widely used for web development, data science, automation, AI/ML, and scripting.

> List 3 programming languages

● 1. Python
  2. JavaScript
  3. Java

────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
>
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
  ? for shortcuts                                                                         Thinking off (tab to toggle)
"""


def main():
    print("=== Output Parser Test ===\n")

    parser = OutputParser()

    # Test 1: Strip ANSI codes
    print("1. Testing ANSI stripping (no ANSI in sample):")
    cleaned_ansi = parser.strip_ansi(SAMPLE_OUTPUT)
    print(f"   ✓ ANSI codes removed (length: {len(cleaned_ansi)})\n")

    # Test 2: Clean output
    print("2. Testing output cleaning:")
    cleaned = parser.clean_output(SAMPLE_OUTPUT)
    print("   --- Cleaned Output ---")
    print(cleaned)
    print("   --- End ---\n")

    # Test 3: Extract Q&A pairs
    print("3. Testing Q&A extraction:")
    pairs = parser.extract_responses(SAMPLE_OUTPUT)
    print(f"   Found {len(pairs)} question/answer pairs:\n")

    for i, pair in enumerate(pairs, 1):
        print(f"   Pair {i}:")
        print(f"     Q: {pair['question']}")
        print(f"     A: {pair['response'][:50]}..." if len(pair['response']) > 50 else f"     A: {pair['response']}")
        print()

    # Test 4: Get last response
    print("4. Testing last response extraction:")
    last_response = parser.get_last_response(SAMPLE_OUTPUT)
    print(f"   Last response: {last_response}\n")

    # Test 5: Get last question
    print("5. Testing last question extraction:")
    last_question = parser.get_last_question(SAMPLE_OUTPUT)
    print(f"   Last question: {last_question}\n")

    # Test 6: Format conversation
    print("6. Testing conversation formatting:")
    formatted = parser.format_conversation(SAMPLE_OUTPUT)
    print("   --- Formatted Conversation ---")
    print(formatted)
    print("   --- End ---\n")

    # Test 7: Error detection
    print("7. Testing error detection:")
    error_responses = [
        "Error: File not found",
        "Failed to connect",
        "This is a normal response",
    ]

    for response in error_responses:
        is_error = parser.is_error_response(response)
        status = "ERROR" if is_error else "OK"
        print(f"   '{response}' -> {status}")

    print("\n=== Test Complete ===")


if __name__ == "__main__":
    main()
</file>

<file path="tests/test_qwen_standalone.py">
#!/usr/bin/env python3
"""
Manual validation script for the Qwen controller.

Launches the Qwen CLI inside tmux, exercises a pair of commands, and verifies
that the `(esc to cancel` loading indicator clears before sending additional
input. Mirrors the existing Gemini/Codex smoke scripts so we can sanity check
the ready/wait flow before running larger orchestrations.
"""

from __future__ import annotations

import argparse
import sys
import time
from pathlib import Path
from typing import Optional, Sequence

from src.controllers.qwen_controller import QwenController
from src.utils.path_helpers import get_tmux_worktree_path

SESSION_NAME = "qwen-controller-test"
WORKING_DIR = str(get_tmux_worktree_path())


class TeeWriter:
    """Mirror stdout to an additional file handle when requested."""

    def __init__(self, *targets):
        self._targets = targets

    def write(self, data: str) -> None:
        for target in self._targets:
            target.write(data)

    def flush(self) -> None:
        for target in self._targets:
            target.flush()


def parse_args(argv: Optional[Sequence[str]] = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Manual Qwen controller validation probe.")
    parser.add_argument(
        "--log-file",
        help=(
            "Optional path to capture a copy of the console output. "
            "Specify a directory to create/use qwen_standalone.log inside it."
        ),
    )
    return parser.parse_args(argv)


def _prepare_log_handle(path_str: str) -> tuple[Path, object]:
    log_path = Path(path_str)
    if log_path.is_dir() or not log_path.suffix:
        log_path.mkdir(parents=True, exist_ok=True)
        log_path = log_path / "qwen_standalone.log"
    else:
        log_path.parent.mkdir(parents=True, exist_ok=True)
    handle = log_path.open("w", encoding="utf-8")
    return log_path, handle


def main(argv: Optional[Sequence[str]] = None) -> int:
    args = parse_args(argv)
    original_stdout = sys.stdout
    log_handle = None

    try:
        if args.log_file:
            log_path, log_handle = _prepare_log_handle(args.log_file)
            sys.stdout = TeeWriter(original_stdout, log_handle)
            print(f"[log] Mirroring output to {log_path}")

        print("=== Testing Qwen Controller ===\n")

        controller = QwenController(
            session_name=SESSION_NAME,
            working_dir=WORKING_DIR,
        )

        print("1. Controller created")
        print(f"   Session: {controller.session_name}")
        print(f"   Executable: {controller.executable}")
        print(f"   Ready indicators: {controller.ready_indicators}")
        print(f"   Loading indicators: {controller.loading_indicators}")
        print(f"   Ready stabilization delay: {controller.ready_stabilization_delay:.2f}s")
        print(f"   Text enter delay: {controller.text_enter_delay:.2f}s\n")

        if controller.session_exists():
            print("2. Cleaning up existing session…")
            controller.kill_session()
            time.sleep(1.0)

        print("3. Starting Qwen CLI session…")
        if controller.start_session(auto_confirm_trust=False):
            print("   ✓ Session started\n")
        else:
            print("   ✗ Failed to start session")
            return 1

        first_prompt = "Summarize the Fibonacci sequence in one sentence."
        print(f"4. Sending command: {first_prompt!r}")
        controller.send_command(first_prompt)
        print("   ✓ Command sent\n")

        print("5. Waiting for response to complete (monitoring '(esc to cancel')…")
        if controller.wait_for_ready(timeout=controller.response_timeout):
            print("   ✓ Response complete\n")
        else:
            print("   ⚠ Timeout waiting for Qwen response\n")

        output = controller.capture_output()
        tail_preview = "\n   ".join(output.splitlines()[-25:])
        print("6. Captured output tail:")
        print(f"   {tail_preview}\n")

        recent_lines = output.splitlines()[-15:]
        if any(
            indicator in line
            for indicator in controller.loading_indicators
            for line in recent_lines
        ):
            print("   ⚠ Loading indicator text still present; double-check wait timing.")
        else:
            print("   ✓ Loading indicator cleared before prompt returned.")

        second_prompt = "\n".join(
            [
                "qwen, we're collaborating on: Give a one sentence statement about quantum computing, then pass to the next.",
                "Provide your next contribution focusing on actionable steps.",
                "Recent context: claude: ● To begin exploring quantum computing, start by learning the mathematical foundations of linear algebra and quantum mechanics.",
                "Provide your next contribution focusing on actionable steps.",
            ]
        )
        print(f"\n7. Sending multiline prompt:\n{second_prompt!r}")
        controller.send_command(second_prompt)
        print("   ✓ Multiline prompt sent\n")

        print("8. Waiting for multiline response…")
        if controller.wait_for_ready(timeout=controller.response_timeout):
            print("   ✓ Multiline response complete\n")
        else:
            print("   ⚠ Timeout waiting for multiline Qwen response\n")

        final_output = controller.capture_output()
        final_tail = "\n   ".join(final_output.splitlines()[-35:])
        print("9. Final output tail:")
        print(f"   {final_tail}\n")

        print("10. Killing session…")
        if controller.kill_session():
            print("    ✓ Session killed\n")
        else:
            print("    ⚠ Session kill reported failure; verify manually.\n")

        print("=== Test Complete ===")
        return 0

    finally:
        if log_handle is not None:
            log_handle.flush()
            log_handle.close()
        sys.stdout = original_stdout


if __name__ == "__main__":
    sys.exit(main(sys.argv[1:]))
</file>

<file path="tests/test_retry.py">
#!/usr/bin/env python3
"""
Test script for retry functionality.
Tests the retry decorator and integration with tmux_controller.
"""
import sys
import time
from src.utils.retry import retry_with_backoff, RetryStrategy, QUICK_RETRY, STANDARD_RETRY
from src.utils.exceptions import CommandError, CommandTimeout, TmuxError


# Test 1: Basic retry decorator
print("=" * 60)
print("Test 1: Basic retry decorator")
print("=" * 60)

attempt_count = 0

@retry_with_backoff(max_attempts=3, initial_delay=0.5)
def flaky_function():
    global attempt_count
    attempt_count += 1
    print(f"  Attempt {attempt_count}")
    if attempt_count < 3:
        raise CommandError("Simulated transient failure")
    return "Success!"

try:
    attempt_count = 0
    result = flaky_function()
    print(f"✓ Result: {result}")
    print(f"✓ Took {attempt_count} attempts\n")
except Exception as e:
    print(f"✗ Failed: {e}\n")
    sys.exit(1)


# Test 2: Retry with max attempts exceeded
print("=" * 60)
print("Test 2: Max attempts exceeded (should fail)")
print("=" * 60)

attempt_count = 0

@retry_with_backoff(max_attempts=3, initial_delay=0.2)
def always_fails():
    global attempt_count
    attempt_count += 1
    print(f"  Attempt {attempt_count}")
    raise CommandTimeout("Always fails")

try:
    attempt_count = 0
    result = always_fails()
    print(f"✗ Should have failed but got: {result}\n")
    sys.exit(1)
except CommandTimeout as e:
    print(f"✓ Failed as expected after {attempt_count} attempts")
    print(f"✓ Error: {e}\n")


# Test 3: RetryStrategy class
print("=" * 60)
print("Test 3: RetryStrategy class")
print("=" * 60)

attempt_count = 0

def flaky_with_args(x, y):
    global attempt_count
    attempt_count += 1
    print(f"  Attempt {attempt_count} with args: x={x}, y={y}")
    if attempt_count < 2:
        raise TmuxError("Transient error", command=["test"])
    return x + y

try:
    attempt_count = 0
    # Create custom strategy that includes TmuxError
    strategy = RetryStrategy(max_attempts=2, initial_delay=0.5, exceptions=(TmuxError,))
    result = strategy.execute(flaky_with_args, 10, 20)
    print(f"✓ Result: {result}")
    print(f"✓ Took {attempt_count} attempts\n")
except Exception as e:
    print(f"✗ Failed: {e}\n")
    sys.exit(1)


# Test 4: Custom exception types
print("=" * 60)
print("Test 4: Custom exception filtering")
print("=" * 60)

@retry_with_backoff(max_attempts=2, initial_delay=0.1, exceptions=(CommandError,))
def specific_exception():
    print("  Raising TimeoutException (not in retry list)")
    raise CommandTimeout("Not in retry exception list")

try:
    result = specific_exception()
    print(f"✗ Should have failed immediately\n")
    sys.exit(1)
except CommandTimeout as e:
    print(f"✓ Failed immediately without retry (correct behavior)")
    print(f"✓ Error: {e}\n")


# Test 5: Exponential backoff timing
print("=" * 60)
print("Test 5: Exponential backoff timing")
print("=" * 60)

attempt_times = []

@retry_with_backoff(max_attempts=4, initial_delay=0.5, backoff_factor=2.0)
def timed_failures():
    attempt_times.append(time.time())
    print(f"  Attempt {len(attempt_times)}")
    if len(attempt_times) < 4:
        raise CommandError("Not yet")
    return "Done"

try:
    attempt_times = []
    start = time.time()
    result = timed_failures()
    total_time = time.time() - start

    print(f"✓ Result: {result}")
    print(f"✓ Total time: {total_time:.2f}s")

    # Check delays between attempts
    if len(attempt_times) >= 2:
        delays = [attempt_times[i] - attempt_times[i-1] for i in range(1, len(attempt_times))]
        print(f"✓ Delays between attempts: {[f'{d:.2f}s' for d in delays]}")

        # Verify exponential backoff (approximately)
        if delays[0] < delays[1]:  # Second delay should be longer than first
            print(f"✓ Exponential backoff working correctly\n")
        else:
            print(f"✗ Backoff not increasing as expected\n")
            sys.exit(1)
except Exception as e:
    print(f"✗ Failed: {e}\n")
    sys.exit(1)


print("=" * 60)
print("All retry tests passed! ✓")
print("=" * 60)
</file>

<file path="examples/run_controller_probe.py">
#!/usr/bin/env python3
"""
Manual controller probe utility.

Launches a tmux-backed AI controller (Claude, Gemini, or Codex), sends one or
more prompts, and prints both raw and cleaned responses. Intended for manual
testing to determine whether additional controller tweaks are needed (e.g.,
submit key, timing delays, ready indicators).
"""

from __future__ import annotations

import argparse
import sys
import time
from typing import Callable, Dict, List, Optional, Type

from src.controllers.claude_controller import ClaudeController
from src.controllers.codex_controller import CodexController
from src.controllers.gemini_controller import GeminiController
from src.utils.output_parser import OutputParser


ControllerFactory = Callable[..., object]


CONTROLLERS: Dict[str, Type] = {
    "claude": ClaudeController,
    "gemini": GeminiController,
    "codex": CodexController,
}


def parse_args(argv: List[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "prompts",
        nargs="*",
        default=["What is 2 + 2?", "Give a one-sentence project status update."],
        help="Prompts to send in order (defaults to two simple checks).",
    )
    parser.add_argument(
        "--controller",
        choices=CONTROLLERS.keys(),
        required=True,
        help="Controller to exercise.",
    )
    parser.add_argument(
        "--session-name",
        help="Override tmux session name (defaults to controller config).",
    )
    parser.add_argument(
        "--working-dir",
        help="Working directory for the CLI process.",
    )
    parser.add_argument(
        "--no-start",
        action="store_true",
        help="Assume the session is already running; do not call start_session().",
    )
    parser.add_argument(
        "--keep-session",
        action="store_true",
        help="Leave the tmux session running when finished.",
    )
    parser.add_argument(
        "--response-timeout",
        type=float,
        default=None,
        help="Override wait_for_ready timeout (seconds).",
    )
    parser.add_argument(
        "--sleep",
        type=float,
        default=1.0,
        help="Delay between prompts to allow buffer stabilization (seconds).",
    )
    parser.add_argument(
        "--tail-lines",
        type=int,
        default=120,
        help="Maximum lines to print from the delta capture.",
    )
    return parser.parse_args(argv)


def capture_scrollback_lines(controller: object) -> List[str]:
    capture = getattr(controller, "capture_scrollback", None)
    if callable(capture):
        try:
            return capture().splitlines()
        except Exception:  # noqa: BLE001
            return []
    return []


def compute_delta(previous: List[str], current: List[str], tail_limit: Optional[int]) -> List[str]:
    if previous and len(current) >= len(previous):
        limit = min(len(previous), len(current))
        prefix = 0
        while prefix < limit and previous[prefix] == current[prefix]:
            prefix += 1
        delta = current[prefix:]
    else:
        delta = current

    if tail_limit is not None and len(delta) > tail_limit:
        delta = delta[-tail_limit:]
    return delta


def main(argv: List[str] | None = None) -> int:
    args = parse_args(argv)
    controller_cls = CONTROLLERS[args.controller]

    controller = controller_cls(
        session_name=args.session_name,
        working_dir=args.working_dir,
    )

    print(f"[info] Controller: {args.controller}")
    print(f"[info] tmux session: {controller.session_name}")
    print(f"[info] executable: {controller.executable}")
    print("")

    if not args.no_start:
        if controller.session_exists():
            print("[info] Session already running; reusing existing instance.")
        else:
            print("[info] Starting session...")
            controller.start_session()
            time.sleep(1.0)

    controller.reset_output_cache()
    parser = OutputParser()

    for idx, prompt in enumerate(args.prompts, start=1):
        print(f"[turn {idx}] prompt: {prompt}")
        before_lines = capture_scrollback_lines(controller)
        controller.send_command(prompt)
        if controller.wait_for_ready(timeout=args.response_timeout):
            print("  [status] response complete")
        else:
            print("  [status] timeout waiting for response")

        after_lines = capture_scrollback_lines(controller)
        delta_lines = compute_delta(before_lines, after_lines, args.tail_lines)
        if delta_lines:
            raw_delta = "\n".join(delta_lines)
        else:
            getter = getattr(controller, "get_last_output", None)
            raw_delta = getter(tail_lines=args.tail_lines) if callable(getter) else ""
        cleaned = parser.clean_output(raw_delta, strip_trailing_prompts=True)
        print("  [raw delta]")
        print("    " + "\n    ".join(raw_delta.splitlines() or ["<empty>"]))
        print("  [clean]")
        print("    " + "\n    ".join(cleaned.splitlines() or ["<empty>"]))
        print("")

        if idx < len(args.prompts) and args.sleep:
            time.sleep(args.sleep)

    if not args.keep_session:
        print("[info] Killing session (use --keep-session to leave running).")
        try:
            controller.kill_session()
        except Exception as exc:  # noqa: BLE001
            print(f"[warn] Failed to kill session cleanly: {exc}")

    print("[done]")
    return 0


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="src/controllers/session_backend.py">
"""
Session backend abstraction for interactive AI CLI tools.

This interface allows the orchestration layer to target different process
transport mechanisms (tmux, expect, PTY, etc.) while presenting the same
surface area to higher-level controllers.
"""

from __future__ import annotations

from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import Mapping, Optional, Sequence


@dataclass(frozen=True)
class SessionSpec:
    """
    Declarative session configuration passed to backends when creating a new
    interactive CLI instance.

    Attributes:
        name: Logical identifier for the session.
        executable: CLI executable to launch (e.g., "claude", "gemini").
        working_dir: Filesystem path to use as the process working directory.
        env: Optional environment overrides to apply when spawning the process.
        args: Optional extra arguments to append after the executable.
    """

    name: str
    executable: str
    working_dir: str
    env: Optional[Mapping[str, str]] = None
    args: Sequence[str] = field(default_factory=tuple)


class SessionBackendError(RuntimeError):
    """Base exception for backend failures."""


class SessionNotFoundError(SessionBackendError):
    """Raised when an operation targets a session that does not exist."""


class SessionBackend(ABC):
    """
    Transport interface for automating interactive AI CLI tools.

    Concrete implementations (e.g., tmux, expect, PTY) encapsulate the process
    management mechanics while higher-level controllers focus on orchestration
    logic such as readiness heuristics, command scheduling, and health checks.
    """

    def __init__(self, spec: SessionSpec) -> None:
        self.spec = spec

    # --- Lifecycle ----------------------------------------------------- #

    @abstractmethod
    def start(self) -> None:
        """
        Launch the CLI process according to the stored session specification.

        Raises:
            SessionBackendError: If the session fails to start.
        """

    @abstractmethod
    def session_exists(self) -> bool:
        """
        Return True if the session currently exists and is reachable.
        """

    @abstractmethod
    def kill(self) -> None:
        """
        Terminate the underlying session.

        Raises:
            SessionNotFoundError: If no session exists to terminate.
        """

    # --- Input --------------------------------------------------------- #

    @abstractmethod
    def send_text(self, text: str) -> None:
        """
        Inject literal text into the session input buffer without submitting.

        Raises:
            SessionNotFoundError: If the session does not exist.
            SessionBackendError: If the backend cannot deliver the text.
        """

    @abstractmethod
    def send_enter(self) -> None:
        """
        Submit the current line (typically by sending the Enter key).

        Raises:
            SessionNotFoundError: If the session does not exist.
            SessionBackendError: If the backend cannot deliver the keystroke.
        """

    @abstractmethod
    def send_ctrl_c(self) -> None:
        """
        Interrupt the current operation (Ctrl+C equivalent).

        Raises:
            SessionNotFoundError: If the session does not exist.
            SessionBackendError: If the backend cannot deliver the signal.
        """

    # --- Output -------------------------------------------------------- #

    @abstractmethod
    def capture_output(
        self,
        *,
        start_line: Optional[int] = None,
        lines: Optional[int] = None,
    ) -> str:
        """
        Capture text from the session's visible buffer.

        Args:
            start_line: Starting line offset. Backend-specific semantics:
                - Tmux: 0 = top of buffer, negative = relative to top
                - Other backends may define differently
                If omitted, captures the visible pane.
            lines: Number of lines to include. If omitted, implementations
                should default to the backend's standard capture window.

        Returns:
            Captured output as a single string.

        Raises:
            SessionNotFoundError: If the session does not exist.
            SessionBackendError: If the backend cannot capture output.
        """

    @abstractmethod
    def capture_scrollback(self) -> str:
        """
        Capture the full scrollback buffer for post-mortem analysis.

        Returns:
            The complete scrollback as a single string.

        Raises:
            SessionNotFoundError: If the session does not exist.
            SessionBackendError: If the backend cannot capture output.
        """

    # --- Observability ------------------------------------------------- #

    @abstractmethod
    def list_clients(self) -> Sequence[str]:
        """
        Enumerate active client connections (for manual takeover detection).

        Returns:
            A sequence of client identifiers.

        Raises:
            SessionNotFoundError: If the session does not exist.
            SessionBackendError: If the backend cannot list clients.
        """

    @abstractmethod
    def attach(self, read_only: bool = False) -> None:
        """
        Attach the current terminal to the session for manual observation.

        Args:
            read_only: If True, attach in read-only mode when supported.

        Raises:
            SessionNotFoundError: If the session does not exist.
            SessionBackendError: If attachment fails.
        """

    # --- Diagnostics --------------------------------------------------- #

    def get_status(self) -> Mapping[str, object]:
        """
        Return backend-specific status information for debugging.

        Implementations may override to add richer fields.
        """
        return {
            "session": self.spec.name,
            "exists": self.session_exists(),
        }
</file>

<file path="src/utils/config_loader.py">
"""
Configuration Loader

Loads and provides access to configuration values from config.yaml
"""

import os
import yaml
from typing import Any, Dict, Optional, Sequence


class ConfigLoader:
    """Loads and provides access to configuration settings."""

    def __init__(self, config_path: Optional[str] = None):
        """
        Initialize ConfigLoader.

        Args:
            config_path: Path to config.yaml file. If None, searches for it
                        in standard locations.
        """
        self.config_path = config_path or self._find_config()
        self.config = self._load_config()

    def _find_config(self) -> str:
        """
        Find config.yaml in standard locations.

        Returns:
            Path to config.yaml

        Raises:
            FileNotFoundError: If config.yaml not found
        """
        # Search paths (in order of priority)
        search_paths = [
            "config.yaml",                                    # Current directory
            os.path.join(os.getcwd(), "config.yaml"),        # Explicit current
            os.path.join(os.path.dirname(__file__), "..", "..", "config.yaml"),  # Project root
        ]

        for path in search_paths:
            if os.path.exists(path):
                return os.path.abspath(path)

        raise FileNotFoundError(
            f"config.yaml not found in standard locations: {search_paths}"
        )

    def _load_config(self) -> Dict[str, Any]:
        """
        Load configuration from YAML file.

        Returns:
            Configuration dictionary

        Raises:
            FileNotFoundError: If config file not found
            yaml.YAMLError: If config file is invalid
        """
        if not os.path.exists(self.config_path):
            raise FileNotFoundError(f"Config file not found: {self.config_path}")

        with open(self.config_path, 'r') as f:
            config = yaml.safe_load(f)

        if not isinstance(config, dict):
            raise ValueError(f"Invalid config file format: {self.config_path}")

        return config

    def get(self, key_path: str, default: Any = None) -> Any:
        """
        Get configuration value using dot notation.

        Args:
            key_path: Dot-separated path to config value (e.g., "claude.startup_timeout")
            default: Default value if key not found

        Returns:
            Configuration value or default

        Examples:
            config.get("claude.startup_timeout")  # Returns 10
            config.get("tmux.capture_lines")      # Returns 100
            config.get("nonexistent.key", 42)     # Returns 42
        """
        keys = key_path.split('.')
        value = self.config

        for key in keys:
            if isinstance(value, dict) and key in value:
                value = value[key]
            else:
                return default

        return value

    def get_section(self, section: str) -> Dict[str, Any]:
        """
        Get entire configuration section.

        Args:
            section: Section name (e.g., "claude", "tmux")

        Returns:
            Section dictionary or empty dict if not found
        """
        return self.config.get(section, {})

    def get_executable_parts(self, agent: str) -> Sequence[str]:
        """
        Return the executable and argument list for a given agent.

        Args:
            agent: Agent key in the config (e.g., "claude", "gemini").

        Returns:
            Sequence containing the executable and any configured arguments.

        Raises:
            KeyError: If the executable is not defined for the agent.
        """
        section = self.get_section(agent)
        executable = section.get("executable")
        if not executable:
            raise KeyError(f"No executable configured for '{agent}'.")

        raw_args = section.get("executable_args", [])
        if isinstance(raw_args, str):
            raw_args = [raw_args]

        if not isinstance(raw_args, (list, tuple)):
            raise TypeError(
                f"Invalid executable_args for '{agent}': expected list/tuple, got {type(raw_args)!r}"
            )

        return (executable, *map(str, raw_args))

    def get_executable_command(self, agent: str) -> str:
        """
        Build a shell-ready command string for the given agent.

        Args:
            agent: Agent key in the config (e.g., "claude", "gemini").

        Returns:
            Command string (executable + args) joined by spaces.
        """
        parts = self.get_executable_parts(agent)
        return " ".join(parts)

    def reload(self) -> None:
        """Reload configuration from file."""
        self.config = self._load_config()

    def __repr__(self) -> str:
        return f"ConfigLoader('{self.config_path}')"


# Global config instance (lazy loaded)
_config_instance: Optional[ConfigLoader] = None


def get_config() -> ConfigLoader:
    """
    Get global configuration instance (singleton pattern).

    Returns:
        ConfigLoader instance
    """
    global _config_instance
    if _config_instance is None:
        _config_instance = ConfigLoader()
    return _config_instance


def reload_config() -> None:
    """Reload global configuration from file."""
    global _config_instance
    if _config_instance is not None:
        _config_instance.reload()
</file>

<file path="src/utils/exceptions.py">
"""
Custom Exceptions for AI Controller Operations

Defines exception hierarchy for clear error handling and recovery strategies.
"""


class AIControllerError(Exception):
    """Base exception for all AI controller errors."""
    pass


# Session-level errors
class SessionError(AIControllerError):
    """Base class for session-related errors."""
    pass


class SessionAlreadyExists(SessionError):
    """Raised when trying to create a session that already exists."""
    pass


class SessionDead(SessionError):
    """Raised when session no longer exists or has died unexpectedly."""
    pass


class SessionUnresponsive(SessionError):
    """Raised when session exists but is not responding to commands."""
    pass


class SessionStartupTimeout(SessionError):
    """Raised when AI session fails to start within expected time."""
    pass


# Command execution errors
class CommandError(AIControllerError):
    """Base class for command execution errors."""
    pass


class CommandTimeout(CommandError):
    """Raised when command execution exceeds timeout."""
    def __init__(self, message, partial_output=None):
        super().__init__(message)
        self.partial_output = partial_output


class CommandMalformed(CommandError):
    """Raised when command contains invalid characters or format."""
    pass


class AutomationPaused(CommandError):
    """Raised when automation is paused (manual takeover, explicit pause, etc.)."""
    pass


# Environment/setup errors
class EnvironmentError(AIControllerError):
    """Base class for environment setup errors."""
    pass


class ExecutableNotFound(EnvironmentError):
    """Raised when AI executable (claude/gemini) is not found in PATH."""
    def __init__(self, executable_name):
        self.executable_name = executable_name
        super().__init__(f"Executable '{executable_name}' not found in PATH")


class TmuxNotFound(EnvironmentError):
    """Raised when tmux is not installed or not in PATH."""
    pass


class TmuxError(EnvironmentError):
    """Raised when tmux command fails."""
    def __init__(self, message, command=None, return_code=None):
        super().__init__(message)
        self.command = command
        self.return_code = return_code


# Output/parsing errors
class OutputError(AIControllerError):
    """Base class for output capture/parsing errors."""
    pass


class OutputEmpty(OutputError):
    """Raised when output capture returns empty result unexpectedly."""
    pass


class OutputMalformed(OutputError):
    """Raised when output cannot be parsed correctly."""
    pass
</file>

<file path="src/utils/logger.py">
"""
Logging helpers for the orchestration project.

Reads defaults from config.yaml when available and wires up console/file output.
"""

import logging
import sys
from logging.handlers import RotatingFileHandler
from pathlib import Path
from typing import Optional, Tuple

try:
    from .config_loader import get_config  # type: ignore circular import false positive
except Exception:  # pragma: no cover - config access optional during bootstrap
    get_config = None  # type: ignore[assignment]


DEFAULT_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
DEFAULT_DATEFMT = "%Y-%m-%d %H:%M:%S"

_LOGGING_DEFAULTS: Optional[Tuple[int, str, bool, int, int]] = None
_LOGGING_FORMAT: str = DEFAULT_FORMAT


def _load_logging_defaults() -> Tuple[int, Optional[str], bool, Optional[int], Optional[int], str]:
    """
    Resolve logging defaults from config.yaml (if available).
    """
    global _LOGGING_DEFAULTS, _LOGGING_FORMAT
    if _LOGGING_DEFAULTS is not None:
        level, log_file, console, max_bytes, backup_count = _LOGGING_DEFAULTS
        return (
            level,
            log_file or None,
            console,
            max_bytes or None,
            backup_count or None,
            _LOGGING_FORMAT,
        )

    level = logging.INFO
    log_file: Optional[str] = None
    console = True
    max_bytes: Optional[int] = None
    backup_count: Optional[int] = None
    fmt = DEFAULT_FORMAT

    if get_config is not None:
        try:
            config = get_config().get_section("logging") or {}
        except Exception:  # pragma: no cover - config access may fail at import time
            config = {}
        level_str = str(config.get("level", "INFO")).upper()
        level = getattr(logging, level_str, logging.INFO)
        log_file = config.get("file") or None
        console = bool(config.get("console", True))
        max_bytes_val = config.get("max_bytes")
        backup_count_val = config.get("backup_count")
        fmt = config.get("format", DEFAULT_FORMAT)
        if isinstance(max_bytes_val, int) and max_bytes_val > 0:
            max_bytes = max_bytes_val
        if isinstance(backup_count_val, int) and backup_count_val >= 0:
            backup_count = backup_count_val

    _LOGGING_DEFAULTS = (level, log_file or "", console, max_bytes or 0, backup_count or 0)
    _LOGGING_FORMAT = fmt
    return level, log_file, console, max_bytes, backup_count, fmt


def setup_logger(
    name: str,
    log_file: Optional[str] = None,
    level: int = logging.INFO,
    console: bool = True,
    *,
    fmt: Optional[str] = None,
    max_bytes: Optional[int] = None,
    backup_count: Optional[int] = None,
) -> logging.Logger:
    """
    Set up a logger with file and/or console handlers.

    Args:
        name: Logger name (typically __name__)
        log_file: Path to log file (optional)
        level: Logging level (default: INFO)
        console: Whether to also log to console (default: True)
        fmt: Optional log format string
        max_bytes: Enable rotating file handler if provided (>0)
        backup_count: Number of backup files for rotating handler

    Returns:
        Configured logger instance
    """
    logger = logging.getLogger(name)
    logger.setLevel(level)

    # Prevent duplicate handlers
    if logger.handlers:
        return logger

    pattern = fmt or DEFAULT_FORMAT
    formatter = logging.Formatter(pattern, datefmt=DEFAULT_DATEFMT)

    if log_file:
        log_path = Path(log_file)
        log_path.parent.mkdir(parents=True, exist_ok=True)
        if max_bytes and max_bytes > 0:
            handler = RotatingFileHandler(
                log_file,
                maxBytes=max_bytes,
                backupCount=backup_count or 0,
            )
        else:
            handler = logging.FileHandler(log_file)
        handler.setLevel(level)
        handler.setFormatter(formatter)
        logger.addHandler(handler)

    if console:
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(level)
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)

    return logger


def get_logger(name: str) -> logging.Logger:
    """
    Get an existing logger or create one honouring config defaults.

    Args:
        name: Logger name

    Returns:
        Logger instance
    """
    logger = logging.getLogger(name)

    if not logger.handlers:
        level, log_file, console, max_bytes, backup_count, fmt = _load_logging_defaults()
        return setup_logger(
            name,
            log_file=log_file,
            level=level,
            console=console,
            fmt=fmt,
            max_bytes=max_bytes,
            backup_count=backup_count,
        )

    return logger
</file>

<file path="tests/test_advanced_suite.py">
#!/usr/bin/env python3
"""
Phase 2.4: Advanced Test Suite
Integration tests with real Claude Code and Gemini CLI sessions.

Tests multi-turn conversations, file operations, rapid commands, and error recovery.
"""
import sys
import os
import time
import yaml
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent))

from src.controllers.tmux_controller import TmuxController
from src.utils.output_parser import OutputParser
from src.utils.path_helpers import (
    ensure_directory,
    get_tmux_worktree_path,
)


TMUX_WORKTREE = get_tmux_worktree_path()
TMUX_WORKTREE_STR = str(TMUX_WORKTREE)


def load_config():
    """Load configuration from config.yaml"""
    with open('config.yaml', 'r') as f:
        return yaml.safe_load(f)


def _extract_executable_parts(config: dict, agent: str) -> tuple[str, tuple[str, ...]]:
    section = config.get(agent, {})
    executable = section.get("executable")
    if not executable:
        raise KeyError(f"No executable configured for '{agent}'")
    args = section.get("executable_args", [])
    if isinstance(args, str):
        args = [args]
    if not isinstance(args, (list, tuple)):
        raise TypeError(f"Invalid executable_args for '{agent}': {type(args)!r}")
    return executable, tuple(str(arg) for arg in args)


def pause_for_observation(test_name: str, session_name: str, delay: int = 5):
    """Pause to allow manual tmux observation"""
    print(f"\n{'='*60}")
    print(f"OBSERVATION POINT: {test_name}")
    print(f"Session name: {session_name}")
    print(f"To observe: tmux attach -t {session_name} -r")
    print(f"Waiting {delay} seconds for observation...")
    print(f"{'='*60}")
    time.sleep(delay)


def test_multi_turn_claude():
    """Test 1: Multi-turn conversation with context preservation (Claude)"""
    print("\n" + "="*60)
    print("TEST 1: Multi-turn Conversation - Claude Code")
    print("="*60)

    config = load_config()
    parser = OutputParser()

    # Create controller for Claude
    claude_exec, claude_args = _extract_executable_parts(config, "claude")

    controller = TmuxController(
        session_name="claude-test",
        executable=claude_exec,
        working_dir=TMUX_WORKTREE_STR,
        ai_config=config['claude'],
        executable_args=claude_args,
    )

    try:
        # Start session
        print("Starting Claude Code session...")
        controller.start_session(auto_confirm_trust=True)

        pause_for_observation("Claude session started", "claude-test")

        # Turn 1: Ask about a topic
        print("\nTurn 1: Asking Claude to remember a number...")
        controller.send_command("I'm going to tell you a number. Remember it: 42. Just acknowledge you'll remember it.")
        controller.wait_for_ready(timeout=30)

        output1 = controller.capture_output(lines=50)
        print(f"Response received ({len(output1)} chars)")

        pause_for_observation("After Turn 1", "claude-test")

        # Turn 2: Reference previous context
        print("\nTurn 2: Testing context preservation...")
        controller.send_command("What number did I just tell you to remember?")
        controller.wait_for_ready(timeout=30)

        output2 = controller.capture_output(lines=50)
        print(f"Response received ({len(output2)} chars)")

        # Check if Claude remembers
        if "42" in output2:
            print("✓ Context preserved - Claude remembered the number!")
        else:
            print("✗ Context lost - Claude didn't remember")

        pause_for_observation("After Turn 2 (context test)", "claude-test")

        # Turn 3: Follow-up question
        print("\nTurn 3: Follow-up question...")
        controller.send_command("What's that number multiplied by 2?")
        controller.wait_for_ready(timeout=30)

        output3 = controller.capture_output(lines=50)

        if "84" in output3:
            print("✓ Claude correctly calculated 42 * 2 = 84")
        else:
            print("✗ Calculation incorrect or context lost")

        pause_for_observation("After Turn 3 (calculation)", "claude-test")

        print("\n✓ Multi-turn conversation test complete")
        return True

    except Exception as e:
        print(f"\n✗ Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        print("\nPausing before cleanup (10 seconds)...")
        time.sleep(10)
        if controller.session_exists():
            controller.kill_session()
            print("Session cleaned up")


def test_multi_turn_gemini():
    """Test 2: Multi-turn conversation with context preservation (Gemini)"""
    print("\n" + "="*60)
    print("TEST 2: Multi-turn Conversation - Gemini CLI")
    print("="*60)

    config = load_config()
    parser = OutputParser()

    # Create controller for Gemini
    gemini_exec, gemini_args = _extract_executable_parts(config, "gemini")

    controller = TmuxController(
        session_name="gemini-test",
        executable=gemini_exec,
        working_dir=TMUX_WORKTREE_STR,
        ai_config=config['gemini'],
        executable_args=gemini_args,
    )

    try:
        # Start session
        print("Starting Gemini CLI session...")
        controller.start_session(auto_confirm_trust=False)  # Gemini doesn't need trust confirmation

        pause_for_observation("Gemini session started", "gemini-test")

        # Turn 1: Ask about a topic (avoid triggering file edits)
        print("\nTurn 1: Asking Gemini to remember a number...")
        controller.send_command("Please remember this number: 777. Just say OK.")
        controller.wait_for_ready(timeout=30)

        output1 = controller.capture_output(lines=50)
        print(f"Response received ({len(output1)} chars)")

        pause_for_observation("After Turn 1", "gemini-test")

        # Turn 2: Reference previous context
        print("\nTurn 2: Testing context preservation...")
        controller.send_command("What number did I ask you to remember?")
        controller.wait_for_ready(timeout=30)

        output2 = controller.capture_output(lines=50)
        print(f"Response received ({len(output2)} chars)")

        # Check if Gemini remembers
        if "777" in output2:
            print("✓ Context preserved - Gemini remembered the number!")
        else:
            print("✗ Context lost - Gemini didn't remember")

        pause_for_observation("After Turn 2 (context test)", "gemini-test")

        # Turn 3: Math follow-up
        print("\nTurn 3: Math follow-up...")
        controller.send_command("What is that number divided by 7?")
        controller.wait_for_ready(timeout=30)

        output3 = controller.capture_output(lines=50)
        print(f"Response received ({len(output3)} chars)")

        pause_for_observation("After Turn 3 (creative response)", "gemini-test")

        print("\n✓ Multi-turn conversation test complete")
        return True

    except Exception as e:
        print(f"\n✗ Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        print("\nPausing before cleanup (10 seconds)...")
        time.sleep(10)
        if controller.session_exists():
            controller.kill_session()
            print("Session cleaned up")


def test_file_operations_claude():
    """Test 3: File operation commands (Claude)"""
    print("\n" + "="*60)
    print("TEST 3: File Operations - Claude Code")
    print("="*60)

    config = load_config()

    claude_exec, claude_args = _extract_executable_parts(config, "claude")

    controller = TmuxController(
        session_name="claude-test",
        executable=claude_exec,
        working_dir=TMUX_WORKTREE_STR,
        ai_config=config['claude'],
        executable_args=claude_args,
    )

    try:
        print("Starting Claude Code session...")
        controller.start_session(auto_confirm_trust=True)

        pause_for_observation("Claude session started", "claude-test")

        # Test 1: Create a test file
        print("\nAsking Claude to create a test file...")
        controller.send_command("Create a file called test_output.txt with the content 'Hello from Claude Code' in it.")
        controller.wait_for_ready(timeout=45)

        output1 = controller.capture_output(lines=100)
        print(f"Response received ({len(output1)} chars)")

        pause_for_observation("After file creation request", "claude-test")

        # Verify file was created
        test_file = ensure_directory(TMUX_WORKTREE) / "test_output.txt"
        if test_file.exists():
            content = test_file.read_text()
            print(f"✓ File created with content: {content.strip()}")
        else:
            print("✗ File was not created")

        # Test 2: Read the file back
        print("\nAsking Claude to read the file...")
        controller.send_command("What are the contents of test_output.txt?")
        controller.wait_for_ready(timeout=30)

        output2 = controller.capture_output(lines=100)

        if "Hello from Claude Code" in output2:
            print("✓ Claude correctly read the file contents")
        else:
            print("✗ Claude couldn't read the file or content missing")

        pause_for_observation("After file read request", "claude-test")

        print("\n✓ File operations test complete")
        return True

    except Exception as e:
        print(f"\n✗ Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        print("\nPausing before cleanup (10 seconds)...")
        time.sleep(10)

        # Clean up test file
        test_file = ensure_directory(TMUX_WORKTREE) / "test_output.txt"
        if test_file.exists():
            test_file.unlink()
            print("Test file removed")

        if controller.session_exists():
            controller.kill_session()
            print("Session cleaned up")


def main():
    """Run all advanced tests"""
    print("="*60)
    print("PHASE 2.4: ADVANCED TEST SUITE")
    print("="*60)
    print("\nThis suite will test:")
    print("1. Multi-turn conversations (context preservation)")
    print("2. File operation commands")
    print("3. Rapid sequential commands")
    print("4. Error scenarios with recovery")
    print("\nYou can attach to tmux sessions for observation:")
    print("  tmux attach -t claude-test -r")
    print("  tmux attach -t gemini-test -r")
    print("\nStarting tests in 5 seconds...")
    time.sleep(5)

    results = {}

    # Test 1: Multi-turn Claude
    results['multi_turn_claude'] = test_multi_turn_claude()

    # Test 2: Multi-turn Gemini
    results['multi_turn_gemini'] = test_multi_turn_gemini()

    # Test 3: File operations Claude
    results['file_ops_claude'] = test_file_operations_claude()

    # Summary
    print("\n" + "="*60)
    print("TEST SUITE SUMMARY")
    print("="*60)
    for test_name, passed in results.items():
        status = "✓ PASS" if passed else "✗ FAIL"
        print(f"{status} - {test_name}")

    total = len(results)
    passed = sum(1 for v in results.values() if v)
    print(f"\nTotal: {passed}/{total} tests passed")


if __name__ == "__main__":
    main()
</file>

<file path="tests/test_codex_startup.py">
#!/usr/bin/env python3
"""
Manual validation script to confirm Codex startup detection works.

Launches the Codex controller, waits for the configured ready indicators,
prints diagnostic output, and cleans up the tmux session. Mirrors the
existing Claude/Gemini startup smoke tests so we can quickly sanity check
Codex when tweaking config.yaml.
"""

import sys
import time
import yaml

from src.controllers.tmux_controller import TmuxController
from src.utils.path_helpers import get_tmux_worktree_path

CONFIG_PATH = "config.yaml"
SESSION_NAME = "codex-startup-test"
WORKING_DIR = str(get_tmux_worktree_path())
CODEX_KEY = "codex"


def load_config() -> dict:
    with open(CONFIG_PATH, "r", encoding="utf-8") as handle:
        return yaml.safe_load(handle)


def main() -> int:
    config = load_config()
    codex_cfg = config.get(CODEX_KEY)
    if not codex_cfg:
        print(f"[error] '{CODEX_KEY}' configuration missing in {CONFIG_PATH}")
        return 1

    executable = codex_cfg.get("executable")
    if not executable:
        print(f"[error] No executable configured for '{CODEX_KEY}' in {CONFIG_PATH}")
        return 1

    raw_args = codex_cfg.get("executable_args", [])
    if isinstance(raw_args, str):
        raw_args = [raw_args]
    if not isinstance(raw_args, (list, tuple)):
        print(f"[error] Invalid executable_args for '{CODEX_KEY}': {type(raw_args)!r}")
        return 1

    controller = TmuxController(
        session_name=SESSION_NAME,
        executable=executable,
        working_dir=WORKING_DIR,
        ai_config=codex_cfg,
        executable_args=tuple(str(arg) for arg in raw_args),
    )

    if controller.session_exists():
        print("[info] Existing session detected; killing before retry…")
        controller.kill_session()
        time.sleep(1.0)

    print("[info] Starting Codex session for startup detection probe…")
    try:
        controller.start_session()
    except Exception as exc:  # noqa: BLE001
        print(f"[error] Startup failed: {exc}")
        if controller.session_exists():
            controller.kill_session()
        return 1

    print("[ok] Codex reported ready.")

    output = controller.capture_output()
    print(f"[debug] Captured {len(output)} characters from pane.")

    markers = codex_cfg.get("ready_indicators", [])
    if markers:
        print("[debug] Ready indicators configured:")
        for marker in markers:
            found = marker in output
            status = "✓" if found else "✗"
            print(f"   {status} {marker}")
    else:
        print("[warn] No ready indicators configured for Codex.")

    controller.kill_session()
    print("[info] Session cleaned up.")
    return 0


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="tests/test_output_parser_cleanup.py">
import pytest

from src.utils.output_parser import OutputParser


RAW_SNIPPET = """
⎿  total 96
    … +12 lines (ctrl+o to expand)
⎿  Read 1014 lines (ctrl+o to expand)
· Assessing current implementation status… (esc to interrupt · ctrl+t to show todos)
⏵⏵ bypass permissions on (shift+tab to cycle)
╭────────────────────╮
│  > What is 2 + 2?  │
╰────────────────────╯
│  > Type your message or @path/to/file  │
╰────────────────────╯
> [Pasted text #1 +56 lines]
Using: 2 GEMINI.md files
YOLO mode (ctrl + y to toggle)
/mnt/path (session*) no sandbox (see /docs)  gemini-2.5-pro (99% context left)
● Answer begins
  This is the payload line.
"""

CODEX_SNIPPET = """
› In two sentences, explain the testing plan.

• Capture raw transcripts for ground truth integrity.
  Compare the cleaned parser output to ensure we only transformed UI chrome.

› Summarize recent commits
  100% context left · ? for shortcuts
"""

CODE_BLOCK_SNIPPET = """
> Provide a tiny Python helper.

● Here's a quick function:
  def add(a, b):
      return a + b
"""


@pytest.fixture
def parser():
    return OutputParser()


def test_clean_output_removes_known_ui_noise(parser):
    cleaned = parser.clean_output(RAW_SNIPPET)

    assert 'Assessing current implementation status' not in cleaned
    assert 'bypass permissions' not in cleaned
    assert 'YOLO mode' not in cleaned
    assert 'no sandbox' not in cleaned
    assert 'Type your message' not in cleaned
    assert '[Pasted text' not in cleaned
    assert '… +12 lines' not in cleaned
    assert '⎿' not in cleaned


def test_clean_output_preserves_payload_lines(parser):
    cleaned = parser.clean_output(RAW_SNIPPET)

    assert 'total 96' in cleaned
    assert 'Read 1014 lines' in cleaned
    assert '> What is 2 + 2?' in cleaned
    assert 'Answer begins' in cleaned
    assert 'This is the payload line.' in cleaned


def test_clean_output_can_strip_trailing_prompts(parser):
    default_cleaned = parser.clean_output(CODEX_SNIPPET)
    trimmed_cleaned = parser.clean_output(CODEX_SNIPPET, strip_trailing_prompts=True)

    assert '› Summarize recent commits' in default_cleaned
    assert '› Summarize recent commits' not in trimmed_cleaned
    assert '› In two sentences, explain the testing plan.' in trimmed_cleaned


def test_extract_responses_handles_codex_prompt_and_bullet(parser):
    pairs = parser.extract_responses(CODEX_SNIPPET)

    assert len(pairs) == 1
    assert pairs[0]['question'] == 'In two sentences, explain the testing plan.'
    assert 'Capture raw transcripts' in pairs[0]['response']


def test_clean_output_preserves_indentation(parser):
    cleaned = parser.clean_output(CODE_BLOCK_SNIPPET)

    assert '  def add(a, b):' in cleaned
    assert '      return a + b' in cleaned
</file>

<file path="tests/test_startup_detection.py">
#!/usr/bin/env python3
"""
Quick test to verify wait_for_startup() works correctly.
"""
import sys
import yaml
from src.controllers.tmux_controller import TmuxController
from src.utils.path_helpers import get_tmux_worktree_path

def load_config():
    with open('config.yaml', 'r') as f:
        return yaml.safe_load(f)


def _extract_executable_parts(config: dict, agent: str) -> tuple[str, tuple[str, ...]]:
    section = config.get(agent, {})
    executable = section.get("executable")
    if not executable:
        raise KeyError(f"No executable configured for '{agent}'")
    args = section.get("executable_args", [])
    if isinstance(args, str):
        args = [args]
    if not isinstance(args, (list, tuple)):
        raise TypeError(f"Invalid executable_args for '{agent}': {type(args)!r}")
    return executable, tuple(str(arg) for arg in args)

print("="*60)
print("Testing Startup Detection")
print("="*60)

config = load_config()
tmux_worktree = str(get_tmux_worktree_path())
claude_exec, claude_args = _extract_executable_parts(config, "claude")
gemini_exec, gemini_args = _extract_executable_parts(config, "gemini")

# Test Claude
print("\n1. Testing Claude startup detection...")
claude = TmuxController(
    session_name="claude-startup-test",
    executable=claude_exec,
    working_dir=tmux_worktree,
    ai_config=config['claude'],
    executable_args=claude_args,
)

if claude.session_exists():
    claude.kill_session()

print("   Starting Claude session...")
try:
    claude.start_session(auto_confirm_trust=True)
    print("   ✓ Claude started and ready!")

    # Show what output was detected
    output = claude.capture_output()
    print(f"   Output length: {len(output)} chars")
    if "? for shortcuts" in output:
        print("   ✓ Found 'for shortcuts' indicator")

    claude.kill_session()
except Exception as e:
    print(f"   ✗ Failed: {e}")
    if claude.session_exists():
        claude.kill_session()
    sys.exit(1)

# Test Gemini
print("\n2. Testing Gemini startup detection...")
gemini = TmuxController(
    session_name="gemini-startup-test",
    executable=gemini_exec,
    working_dir=tmux_worktree,
    ai_config=config['gemini'],
    executable_args=gemini_args,
)

if gemini.session_exists():
    gemini.kill_session()

print("   Starting Gemini session...")
try:
    gemini.start_session(auto_confirm_trust=False)
    print("   ✓ Gemini started and ready!")

    # Show what output was detected
    output = gemini.capture_output()
    print(f"   Output length: {len(output)} chars")
    if "Type your message" in output:
        print("   ✓ Found 'Type your message' indicator")

    gemini.kill_session()
except Exception as e:
    print(f"   ✗ Failed: {e}")
    if gemini.session_exists():
        gemini.kill_session()
    sys.exit(1)

print("\n" + "="*60)
print("✓ Startup detection working correctly!")
print("="*60)
</file>

<file path="tests/test_tmux_controller_ready.py">
import time
import shutil
from typing import List

import pytest

from src.controllers.tmux_controller import TmuxController
from src.utils.config_loader import get_config


def _make_controller(monkeypatch, outputs: List[str]) -> TmuxController:
    monkeypatch.setattr(shutil, "which", lambda _: "/usr/bin/fake")
    monkeypatch.setattr(time, "sleep", lambda _: None)

    config = {
        "response_timeout": 1,
        "ready_check_interval": 0.0,
        "ready_stable_checks": 2,
        "ready_indicators": ["context left"],
        "loading_indicators": ["◦"],
        "response_complete_markers": ["› "],
    }

    exe_parts = get_config().get_executable_parts("claude")

    controller = TmuxController(
        session_name="test",
        executable=exe_parts[0],
        ai_config=config,
        executable_args=tuple(exe_parts[1:]),
    )

    controller.session_exists = lambda: True

    sequence = iter(outputs)
    last_value = {"value": ""}

    def fake_capture() -> str:
        try:
            last_value["value"] = next(sequence)
        except StopIteration:
            pass
        return last_value["value"]

    controller.capture_output = fake_capture  # type: ignore[assignment]
    return controller


def test_wait_for_ready_reacts_to_completion(monkeypatch):
    controller = _make_controller(
        monkeypatch,
        [
            "◦ Working for 10s\n",
            "◦ Working for 10s\n",
            "› Write tests for @filename\n98% context left · ? for shortcuts\n",
            "› Write tests for @filename\n98% context left · ? for shortcuts\n",
        ],
    )

    assert controller.wait_for_ready(timeout=0.2, check_interval=0.0)


def test_wait_for_ready_times_out_when_loading_persists(monkeypatch):
    controller = _make_controller(
        monkeypatch,
        [
            "◦ Working for 10s\n",
        ],
    )

    # Ensure the capture continues returning the loading indicator.
    assert controller.wait_for_ready(timeout=0.05, check_interval=0.0) is False


def test_wait_for_ready_ignores_old_marker(monkeypatch):
    controller = _make_controller(
        monkeypatch,
        [
            "› Write tests for @filename\n98% context left · ? for shortcuts\n",
            "◦ Working for 3s\n",
            "◦ Working for 3s\n",
        ],
    )

    assert controller.wait_for_ready(timeout=0.1, check_interval=0.0) is False
</file>

<file path="examples/run_code_review_simulation.py">
#!/usr/bin/env python3
"""Run the Option 1 CLAUDE↔Gemini code review simulation."""

from __future__ import annotations

import argparse
import textwrap
from enum import Enum
from pathlib import Path
from typing import Dict

from examples.run_orchestrated_discussion import build_controller, run_discussion
from src.orchestrator.context_manager import ContextManager
from src.utils.config_loader import get_config
from src.utils.logger import get_logger


LOGGER = get_logger("examples.code_review_simulation")


DEFAULT_TURN_PLAN = textwrap.dedent(
    """
    Conversation structure:
    1. Claude: Identify the most critical bug or omission you spot in the function. Mention why it matters.
    2. Gemini: Add a new finding that Claude did not cover. Highlight the impact if left unresolved.
    3. Claude: Propose a fix or guard for one of Gemini's observations.
    4. Gemini: Validate Claude's proposal, add one more improvement opportunity, and note any test you would run.
    5. Claude: Summarize the defects found and list concrete next steps (fixes, tests).
    6. Gemini: Provide the final sign-off gate: can this ship as-is? If not, state blocking reasons succinctly.
    Keep each turn focused, reference specific lines, and avoid repeating prior points.
    """
).strip()


class InclusionStrategy(str, Enum):
    EMBED_FULL = "embed_full"
    HYBRID = "hybrid"
    REFERENCE_ONLY = "reference_only"


def _format_display_path(snippet_path: Path) -> str:
    """Return project-relative path when possible for prompt readability."""

    try:
        return snippet_path.relative_to(Path.cwd()).as_posix()
    except ValueError:
        return snippet_path.as_posix()


def _render_code_block(lines: list[str]) -> str:
    """Render lines as a Python code block with consistent indentation."""

    if lines:
        formatted = textwrap.indent("\n".join(lines), "    ")
    else:
        formatted = textwrap.indent("# (file is empty)", "    ")
    return f"```python\n{formatted}\n```"


def _render_preview_block(lines: list[str], preview_lines: int) -> tuple[str, bool]:
    """Return a preview code block and whether it was truncated."""

    preview_limit = max(preview_lines, 1)
    preview = lines[:preview_limit]
    truncated = len(lines) > preview_limit
    return _render_code_block(preview), truncated


def determine_inclusion_strategy(
    *,
    line_count: int,
    size_bytes: int,
    embed_threshold: int,
    reference_threshold: int,
    size_threshold: int,
) -> InclusionStrategy:
    """Select how to include the target file in prompts."""

    if size_bytes > size_threshold or line_count > reference_threshold:
        return InclusionStrategy.REFERENCE_ONLY
    if line_count > embed_threshold:
        return InclusionStrategy.HYBRID
    return InclusionStrategy.EMBED_FULL


class ReviewContextManager(ContextManager):
    """Context manager that keeps the review scenario front-and-centre."""

    def __init__(self, scenario: str, *, history_size: int = 20) -> None:
        super().__init__(history_size=history_size)
        self._scenario = scenario

    def build_prompt(self, ai_name: str, task: str, *, include_history: bool = True) -> str:  # type: ignore[override]
        lines = [
            f"{ai_name.title()}, you're co-reviewing the Python helper below.",
        ]
        if not self.history:
            lines.append(self._scenario)
        else:
            lines.append(
                "Revisit the original snippet and review plan above; add insights we haven't covered yet."
            )

        if include_history:
            recent = self._format_recent_history()
            if recent:
                lines.append(f"Recent discussion: {recent}")

        return "\n\n".join(lines)


def build_topic(
    snippet_path: Path,
    turn_plan: str,
    snippet_lines: list[str],
    *,
    strategy: InclusionStrategy,
    preview_lines: int,
) -> str:
    """Compose the orchestrator topic for the code review scenario."""

    display_path = _format_display_path(snippet_path)
    reference_token = f"@{display_path}"
    total_lines = len(snippet_lines)

    sections: list[str] = [
        textwrap.dedent(
            """
            You are participating in an asynchronous code review of a Python helper. Review the
            function exactly as written (do not assume missing context) and follow the
            turn-by-turn plan. Focus on correctness, defensive coding, and actionable guidance.
            """
        ).strip()
    ]

    if strategy is InclusionStrategy.EMBED_FULL:
        sections.append(
            textwrap.dedent(
                f"""
                Target file `{display_path}` (you may also open `{reference_token}` directly in your CLI):
                {_render_code_block(snippet_lines)}
                """
            ).strip()
        )
    elif strategy is InclusionStrategy.HYBRID:
        preview_block, truncated = _render_preview_block(snippet_lines, preview_lines)
        preview_header = (
            f"Preview (first {min(total_lines, max(preview_lines, 1))} of {total_lines} lines shown)."
            if total_lines
            else "Preview (file is empty)."
        )
        section = textwrap.dedent(
            f"""
            Target file `{display_path}`. Open `{reference_token}` to inspect the full code.
            {preview_header}
            {preview_block}
            """
        ).strip()
        if truncated:
            section += f"\n(Preview truncated after {max(preview_lines, 1)} of {total_lines} lines.)"
        sections.append(section)
    else:
        sections.append(
            textwrap.dedent(
                f"""
                Target file `{display_path}`. Open `{reference_token}` to review the complete implementation.
                """
            ).strip()
        )

    sections.append(turn_plan.strip())
    sections.append(
        textwrap.dedent(
            """
            Expectations:
            - Each turn must add a new insight or decision, avoiding duplication.
            - Reference concrete behaviours (e.g., empty ranges, index bounds) when raising issues.
            - Prefer concise bullet points when listing defects or next steps.
            - Keep outputs under 220 words per turn.
            """
        ).strip()
    )

    return "\n\n".join(sections).strip()


def parse_args(argv: list[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Launch the CLAUDE↔Gemini code review simulation scenario."
    )
    config = get_config()

    def default_command(agent: str) -> str:
        try:
            return config.get_executable_command(agent)
        except (KeyError, TypeError) as exc:
            parser.error(
                f"Executable for '{agent}' is not configured correctly in config.yaml: {exc}"
            )

    claude_default = default_command("claude")
    gemini_default = default_command("gemini")
    parser.add_argument(
        "--snippet",
        type=Path,
        default=Path(__file__).with_name("buggy_review_target.py"),
        help="Path to the Python file the AIs should review (default: buggy_review_target.py).",
    )
    parser.add_argument(
        "--max-turns",
        type=int,
        default=6,
        help="Maximum number of turns to run (default: 6).",
    )
    parser.add_argument(
        "--auto-start",
        action="store_true",
        help="Launch tmux sessions automatically if they are not already running.",
    )
    parser.add_argument(
        "--claude-session",
        default="claude",
        help="Tmux session name for Claude (default: claude).",
    )
    parser.add_argument(
        "--gemini-session",
        default="gemini",
        help="Tmux session name for Gemini (default: gemini).",
    )
    parser.add_argument(
        "--claude-executable",
        default=claude_default,
        help=f"Command used to launch Claude Code CLI (default: '{claude_default}').",
    )
    parser.add_argument(
        "--gemini-executable",
        default=gemini_default,
        help=f"Command used to launch Gemini CLI (default: '{gemini_default}').",
    )
    parser.add_argument(
        "--claude-working-dir",
        default=None,
        help="Working directory for Claude CLI session (default: None).",
    )
    parser.add_argument(
        "--gemini-working-dir",
        default=None,
        help="Working directory for Gemini CLI session (default: None).",
    )
    parser.add_argument(
        "--claude-startup-timeout",
        type=int,
        default=30,
        help="Startup timeout for Claude CLI (default: 30 seconds).",
    )
    parser.add_argument(
        "--gemini-startup-timeout",
        type=int,
        default=30,
        help="Startup timeout for Gemini CLI (default: 30 seconds).",
    )
    parser.add_argument(
        "--claude-init-wait",
        type=float,
        default=None,
        help="Optional extra wait after launching Claude CLI (seconds).",
    )
    parser.add_argument(
        "--gemini-init-wait",
        type=float,
        default=None,
        help="Optional extra wait after launching Gemini CLI (seconds).",
    )
    parser.add_argument(
        "--claude-bootstrap",
        default=None,
        help="Shell snippet to run before starting Claude CLI (e.g., activate venv).",
    )
    parser.add_argument(
        "--gemini-bootstrap",
        default=None,
        help="Shell snippet to run before starting Gemini CLI.",
    )
    parser.add_argument(
        "--kill-existing",
        action="store_true",
        help="Stop existing tmux sessions before launching new ones.",
    )
    parser.add_argument(
        "--history-size",
        type=int,
        default=20,
        help="Shared context window turn count (default: 20).",
    )
    parser.add_argument(
        "--debug-prompts",
        action="store_true",
        help="Log prompt previews for debugging.",
    )
    parser.add_argument(
        "--prompt-preview-chars",
        type=int,
        default=220,
        help="Character preview length when --debug-prompts is set (default: 220).",
    )
    parser.set_defaults(include_history=True)
    parser.add_argument(
        "--no-history",
        action="store_false",
        dest="include_history",
        help="Skip conversation history when building prompts (smoke-test style).",
    )
    parser.add_argument(
        "--turn-plan-file",
        type=Path,
        default=None,
        help="Optional path to a text file containing a custom turn plan.",
    )
    parser.add_argument(
        "--embed-threshold",
        type=int,
        default=50,
        help="Maximum line count to embed the full code (default: 50).",
    )
    parser.add_argument(
        "--reference-threshold",
        type=int,
        default=100,
        help="Line count above which only the @-reference is provided (default: 100).",
    )
    parser.add_argument(
        "--size-threshold",
        type=int,
        default=5000,
        help="File size in bytes above which only the @-reference is provided (default: 5000).",
    )
    parser.add_argument(
        "--preview-lines",
        type=int,
        default=30,
        help="Number of lines to show in the hybrid preview (default: 30).",
    )
    parser.add_argument(
        "--log-file",
        type=Path,
        default=Path("logs/code_review_simulation.log"),
        help="File path to store the conversation transcript (default: logs/code_review_simulation.log).",
    )
    return parser.parse_args(argv)


def load_turn_plan(args: argparse.Namespace) -> str:
    if args.turn_plan_file:
        LOGGER.info("Loading turn plan from %s", args.turn_plan_file)
        return args.turn_plan_file.read_text(encoding="utf-8").strip()
    return DEFAULT_TURN_PLAN


def main(argv: list[str] | None = None) -> int:
    args = parse_args(argv)

    if not args.snippet.exists():
        raise SystemExit(f"Snippet file not found: {args.snippet}")

    turn_plan = load_turn_plan(args)
    snippet_text = args.snippet.read_text(encoding="utf-8").rstrip()
    snippet_lines = snippet_text.splitlines()
    size_bytes = args.snippet.stat().st_size
    preview_lines = max(args.preview_lines, 1)
    size_threshold = max(args.size_threshold, 1)

    reference_threshold = args.reference_threshold
    if reference_threshold <= args.embed_threshold:
        reference_threshold = args.embed_threshold + 1
        LOGGER.warning(
            "reference_threshold (%d) must exceed embed_threshold (%d); adjusted to %d.",
            args.reference_threshold,
            args.embed_threshold,
            reference_threshold,
        )

    strategy = determine_inclusion_strategy(
        line_count=len(snippet_lines),
        size_bytes=size_bytes,
        embed_threshold=args.embed_threshold,
        reference_threshold=reference_threshold,
        size_threshold=size_threshold,
    )
    LOGGER.info(
        "Using %s strategy for %s (lines=%d, bytes=%d)",
        strategy.value,
        _format_display_path(args.snippet),
        len(snippet_lines),
        size_bytes,
    )

    claude = build_controller(
        name="claude",
        session_name=args.claude_session,
        executable=args.claude_executable,
        working_dir=args.claude_working_dir,
        auto_start=args.auto_start,
        startup_timeout=args.claude_startup_timeout,
        init_wait=args.claude_init_wait,
        bootstrap=args.claude_bootstrap,
        kill_existing=args.kill_existing,
    )

    gemini = build_controller(
        name="gemini",
        session_name=args.gemini_session,
        executable=args.gemini_executable,
        working_dir=args.gemini_working_dir,
        auto_start=args.auto_start,
        startup_timeout=args.gemini_startup_timeout,
        init_wait=args.gemini_init_wait,
        bootstrap=args.gemini_bootstrap,
        kill_existing=args.kill_existing,
    )

    topic = build_topic(
        args.snippet,
        turn_plan,
        snippet_lines,
        strategy=strategy,
        preview_lines=preview_lines,
    )
    review_context = ReviewContextManager(topic, history_size=args.history_size)

    if args.debug_prompts:
        LOGGER.info("Prompt preview enabled (first %d characters)", args.prompt_preview_chars)

    outcome: Dict[str, object] = run_discussion(
        claude=claude,
        gemini=gemini,
        topic=topic,
        max_turns=args.max_turns,
        history_size=args.history_size,
        start_with="claude",
        debug_prompts=args.debug_prompts,
        debug_prompt_chars=args.prompt_preview_chars,
        include_history=args.include_history,
        context_manager=review_context,
    )

    conversation = outcome["conversation"]
    log_path = args.log_file

    if log_path:
        log_path.parent.mkdir(parents=True, exist_ok=True)
        with log_path.open("w", encoding="utf-8") as handle:
            handle.write("=== CODE REVIEW SUMMARY ===\n")
            for turn in conversation:
                speaker = turn.get("speaker", "unknown")
                handle.write(f"\n[{turn.get('turn', '?')}] {speaker.title()} says:\n")
                handle.write(textwrap.indent((turn.get("response") or "(no response)").strip(), "    "))
                handle.write("\n")

    print("\n=== CODE REVIEW SUMMARY ===")
    for turn in conversation:
        speaker = turn.get("speaker", "unknown")
        print(f"\n[{turn.get('turn', '?')}] {speaker.title()} says:")
        print(textwrap.indent((turn.get("response") or "(no response)").strip(), "    "))

    if log_path:
        print(f"\nRun complete. Transcript saved to {log_path}.")
    else:
        print("\nRun complete. Inspect logs/ or tmux panes for raw transcripts if needed.")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
</file>

<file path="examples/run_counting_conversation.py">
#!/usr/bin/env python3
"""
Let Claude, Gemini, and Codex count upward together using the orchestrator.

The first AI starts at 1, the next replies with 2, and so on until the target count.
The script records the transcript and verifies that every number appears in order.
"""

from __future__ import annotations

import argparse
import re
import time
import sys
from pathlib import Path
from typing import Dict, List, Optional

from src.controllers.tmux_controller import SessionBackendError, SessionNotFoundError, TmuxController
from src.orchestrator import ContextManager, DevelopmentTeamOrchestrator, MessageRouter
from src.orchestrator.conversation_manager import ConversationManager
from src.utils.config_loader import get_config
from src.utils.output_parser import OutputParser


def build_controller(
    *,
    name: str,
    session_name: str,
    executable: str,
    working_dir: Optional[str],
    auto_start: bool,
    startup_timeout: int,
    init_wait: Optional[float],
    kill_existing: bool,
) -> TmuxController:
    cfg = get_config()
    base = dict(cfg.get_section(name.lower()) or {})
    base["startup_timeout"] = startup_timeout
    if init_wait is not None:
        base["init_wait"] = init_wait

    parts = executable.split()
    controller = TmuxController(
        session_name=session_name,
        executable=parts[0],
        working_dir=working_dir,
        ai_config=base,
        executable_args=tuple(parts[1:]),
    )
    controller.reset_output_cache()

    if kill_existing and controller.session_exists():
        controller.kill()

    if controller.session_exists():
        controller.resume_automation(flush_pending=True)
        return controller

    if not auto_start:
        raise SessionNotFoundError(
            f"Session '{session_name}' not found for {name}. Start manually or use --auto-start."
        )

    controller.start()
    controller.wait_for_ready()
    return controller


def parse_args(argv: list[str]) -> argparse.Namespace:
    cfg = get_config()
    tmux_cfg = cfg.get_section("tmux")

    parser = argparse.ArgumentParser(description="Have Claude, Gemini, and Codex count together.")

    def default_command(agent: str) -> str:
        try:
            return cfg.get_executable_command(agent)
        except (KeyError, TypeError) as exc:
            parser.error(
                f"Executable for '{agent}' is not configured correctly in config.yaml: {exc}"
            )

    claude_default = default_command("claude")
    gemini_default = default_command("gemini")
    codex_default = default_command("codex")
    parser.add_argument("--count-to", type=int, default=20, help="Highest number to reach (default 20).")
    parser.add_argument("--auto-start", action="store_true", help="Launch sessions automatically if needed.")
    parser.add_argument("--kill-existing", action="store_true", help="Kill sessions before starting.")
    parser.add_argument("--claude-session", default=tmux_cfg.get("claude_session", "claude"))
    parser.add_argument("--gemini-session", default=tmux_cfg.get("gemini_session", "gemini"))
    parser.add_argument(
        "--claude-executable",
        default=claude_default,
        help=f"Command to launch Claude (default: '{claude_default}').",
    )
    parser.add_argument(
        "--gemini-executable",
        default=gemini_default,
        help=f"Command to launch Gemini (default: '{gemini_default}').",
    )
    parser.add_argument("--claude-startup-timeout", type=int, default=20)
    parser.add_argument("--gemini-startup-timeout", type=int, default=60)
    parser.add_argument("--claude-init-wait", type=float, default=None)
    parser.add_argument("--gemini-init-wait", type=float, default=None)
    parser.add_argument("--claude-cwd", default=None)
    parser.add_argument("--gemini-cwd", default=None)
    parser.add_argument("--codex-session", default=tmux_cfg.get("codex_session", "codex"))
    parser.add_argument(
        "--codex-executable",
        default=codex_default,
        help=f"Command to launch Codex (default: '{codex_default}').",
    )
    parser.add_argument("--codex-startup-timeout", type=int, default=20)
    parser.add_argument("--codex-init-wait", type=float, default=None)
    parser.add_argument("--codex-cwd", default=None)
    parser.add_argument("--log-file", default=None, help="Optional path to write the transcript.")
    parser.add_argument(
        "--history-size",
        type=int,
        default=10,
        help="How many turns to keep in context (default 10).",
    )
    parser.add_argument(
        "--turn-delay",
        type=float,
        default=1.0,
        help="Seconds to pause before dispatching each prompt (default 1.0).",
    )
    parser.add_argument(
        "--initial-delay",
        type=float,
        default=2.0,
        help="Seconds to wait after startup before starting the count (default 2.0).",
    )
    parser.add_argument(
        "--response-timeout",
        type=float,
        default=30.0,
        help="Seconds to wait for each AI response before giving up (default 30s).",
    )
    return parser.parse_args(argv)


def capture_scrollback_lines(controller: TmuxController) -> List[str]:
    try:
        snapshot = controller.capture_scrollback()
    except (SessionBackendError, SessionNotFoundError):
        return []
    return snapshot.splitlines()


def compute_delta(previous: List[str], current: List[str], tail_limit: int) -> List[str]:
    if previous and len(current) >= len(previous):
        limit = min(len(previous), len(current))
        prefix = 0
        while prefix < limit and previous[prefix] == current[prefix]:
            prefix += 1
        delta = current[prefix:]
    else:
        delta = current

    if tail_limit and len(delta) > tail_limit:
        delta = delta[-tail_limit:]
    return delta


def build_prompt(number: int, speaker: str, next_speaker: str) -> str:
    return (
        f"You are counting upward with {next_speaker}. Respond with ONLY the number {number}."
        f" Then instruct {next_speaker} to add 1 and reply with the next number."
        " Do not add extra commentary."
    )


def main(argv: list[str]) -> int:
    args = parse_args(argv)
    transcript_path = Path(args.log_file) if args.log_file else None
    parser = OutputParser()

    try:
        claude = build_controller(
            name="Claude",
            session_name=args.claude_session,
            executable=args.claude_executable,
            working_dir=args.claude_cwd,
            auto_start=args.auto_start,
            startup_timeout=args.claude_startup_timeout,
            init_wait=args.claude_init_wait,
            kill_existing=args.kill_existing,
        )
        gemini = build_controller(
            name="Gemini",
            session_name=args.gemini_session,
            executable=args.gemini_executable,
            working_dir=args.gemini_cwd,
            auto_start=args.auto_start,
            startup_timeout=args.gemini_startup_timeout,
            init_wait=args.gemini_init_wait,
            kill_existing=args.kill_existing,
        )
        codex = build_controller(
            name="Codex",
            session_name=args.codex_session,
            executable=args.codex_executable,
            working_dir=args.codex_cwd,
            auto_start=args.auto_start,
            startup_timeout=args.codex_startup_timeout,
            init_wait=args.codex_init_wait,
            kill_existing=args.kill_existing,
        )
    except (SessionBackendError, SessionNotFoundError) as exc:
        print(f"[error] {exc}", file=sys.stderr)
        return 1

    controllers: Dict[str, TmuxController] = {"claude": claude, "gemini": gemini, "codex": codex}
    orchestrator = DevelopmentTeamOrchestrator(controllers)
    context_manager = ContextManager(history_size=args.history_size)
    router = MessageRouter(["claude", "gemini", "codex"], context_manager=context_manager)
    manager = ConversationManager(
        orchestrator,
        ["claude", "gemini", "codex"],
        context_manager=context_manager,
        message_router=router,
        max_history=args.history_size,
    )

    conversation = []
    if args.initial_delay > 0:
        print(f"[info] Waiting {args.initial_delay:.1f}s before starting the count...")
        time.sleep(args.initial_delay)

    turn_delay = max(0.0, args.turn_delay)
    next_number = 1
    current_speaker_index = 0  # 0 -> claude, 1 -> gemini
    transcript_lines: list[str] = []

    while next_number <= args.count_to:
        speaker = manager.participants[current_speaker_index]
        next_speaker = manager.participants[(current_speaker_index + 1) % len(manager.participants)]
        next_target = next_number + 1
        prompt_lines = [
            f"Current number: {next_number}",
            f"Reply using exactly two lines:",
            f"Line 1: {next_number}",
            f"Line 2: Next speaker ({next_speaker}) should reply with {next_target}.",
            "Do not open files, run commands, or use tools. No additional commentary or formatting.",
        ]
        prompt = "\n".join(prompt_lines)

        if turn_delay:
            time.sleep(turn_delay)

        controller = controllers[speaker]
        before_lines = capture_scrollback_lines(controller)
        dispatch = orchestrator.dispatch_command(speaker, prompt)
        controller.wait_for_ready(timeout=max(int(args.response_timeout), 1))
        after_lines = capture_scrollback_lines(controller)
        delta_lines = compute_delta(before_lines, after_lines, tail_limit=300)
        if delta_lines:
            raw_output = "\n".join(delta_lines)
        else:
            fallback = controller.get_last_output(tail_lines=300)
            raw_output = fallback or ""

        cleaned_output = parser.clean_output(raw_output, strip_trailing_prompts=True)
        pairs = parser.extract_responses(raw_output) or parser.extract_responses(cleaned_output)
        response = pairs[-1]["response"].strip() if pairs else cleaned_output.strip() or raw_output.strip()
        reported_number: Optional[int] = None
        if response:
            numbers = re.findall(r"\d+", response)
            if numbers:
                reported_number = int(numbers[0])

        turn_record = {
            "turn": len(conversation),
            "speaker": speaker,
            "prompt": prompt,
            "response": response,
            "metadata": dispatch,
        }
        conversation.append(turn_record)
        transcript_lines.append(f"{next_number}: {speaker}: {response}")

        print(f"[debug] Raw output from {speaker}:\n{raw_output}\n---")
        if cleaned_output:
            print(f"[debug] Cleaned output from {speaker}:\n{cleaned_output}\n---")
        if pairs:
            print(f"[debug] Parsed response from {speaker}: {pairs[-1]['response']}\n---")

        if not response:
            print(f"[warn] No response captured for turn {len(conversation)-1} ({speaker}).")
            break

        # Update number by parsing the response's first integer.
        if reported_number is None:
            print(f"[warn] Could not parse number from {speaker}'s response: {response!r}")
            break

        if reported_number != next_number:
            print(f"[warn] Expected {next_number} but {speaker} replied with {reported_number}.")
            break

        next_number += 1
        current_speaker_index = (current_speaker_index + 1) % len(manager.participants)

    if transcript_path:
        transcript_path.write_text("\n".join(transcript_lines), encoding="utf-8")
        print(f"\nTranscript written to {transcript_path}")

    print("=== Transcript Preview ===")
    for line in transcript_lines[-10:]:
        print(line)

    return 0


if __name__ == "__main__":
    sys.exit(main(sys.argv[1:]))
</file>

<file path="examples/run_three_agent_discussion.py">
#!/usr/bin/env python3
"""
Demonstrate a three-participant discussion (Claude, Gemini, Codex agent).

The script defaults to a stubbed simulation so it can run without access to the
Claude, Gemini, or Codex CLIs. Pass ``--mode tmux`` to attempt a real tmux-backed
run using the configured controllers (requires tmux plus the CLI executables).

Flag switches mirror ``run_orchestrated_discussion.py`` so long-running tests can
be controlled consistently across the demo scripts.
"""

from __future__ import annotations

import argparse
import logging
import shlex
import sys
import textwrap
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Sequence

from src.controllers.tmux_controller import (
    SessionBackendError,
    SessionNotFoundError,
    TmuxController,
)
from src.orchestrator.context_manager import ContextManager
from src.orchestrator.conversation_manager import ConversationManager
from src.orchestrator.message_router import MessageRouter
from src.orchestrator.orchestrator import DevelopmentTeamOrchestrator
from src.utils.config_loader import get_config
from src.utils.output_parser import OutputParser


# --------------------------------------------------------------------------- #
# Stub controllers for the default simulation mode
# --------------------------------------------------------------------------- #

@dataclass
class StubResponsePlan:
    lines: List[str] = field(default_factory=list)
    cursor: int = 0

    def next(self) -> str:
        if not self.lines:
            return ""
        response = self.lines[self.cursor]
        self.cursor = min(self.cursor + 1, len(self.lines) - 1)
        return response


class StubController:
    """
    Simple conversational stub that satisfies the controller interface used by
    the orchestrator/conversation manager tests.
    """

    def __init__(self, responses: Iterable[str], *, role: Optional[str] = None) -> None:
        self._plan = StubResponsePlan(list(responses))
        self._last_output: str = ""
        self._paused: bool = False
        self._role = role

    # --- Controller surface -------------------------------------------------

    def get_status(self) -> Dict[str, Dict[str, object]]:
        return {
            "automation": {
                "paused": self._paused,
                "reason": None,
                "pending_commands": 0,
                "manual_clients": [],
            }
        }

    def send_command(self, command: str, submit: bool = True) -> bool:  # noqa: ARG002 - submit unused
        self._last_output = self._plan.next()
        return True

    # --- Helpers ------------------------------------------------------------

    def wait_for_ready(self, timeout: float | None = None, check_interval: float | None = None) -> bool:  # noqa: ARG002
        return True

    def get_last_output(self, *, tail_lines: int = 50) -> str:  # noqa: ARG002
        return self._last_output


# --------------------------------------------------------------------------- #
# Controller factories
# --------------------------------------------------------------------------- #

ParticipantMetadata = Dict[str, Dict[str, object]]
DEFAULT_PARTICIPANTS: Sequence[str] = ("claude", "gemini", "codex")


def build_stub_controllers() -> tuple[Dict[str, StubController], ParticipantMetadata]:
    controllers = {
        "claude": StubController(
            [
                "Initial roadmap outline with priorities.",
                "Agreeing on implementation plan.",
                "Ready to ship the increment.",
            ],
            role="lead reviewer",
        ),
        "gemini": StubController(
            [
                "Architecture impact assessment plus risks.",
                "Identified integration touchpoints.",
                "Confirmed monitoring hooks.",
            ],
            role="architect",
        ),
        "codex": StubController(
            [
                "Implementation checklist with code owners.",
                "Outlined tests and tooling updates.",
                "Deployment playbook ready.",
            ],
            role="implementation",
        ),
    }

    metadata: ParticipantMetadata = {
        "claude": {"type": "cli", "role": "lead reviewer"},
        "gemini": {"type": "cli", "role": "architect"},
        "codex": {"type": "cli", "role": "implementation"},
    }
    return controllers, metadata


def build_controller(
    *,
    name: str,
    session_name: str,
    executable: str,
    working_dir: Optional[str],
    auto_start: bool,
    startup_timeout: int,
    init_wait: Optional[float],
    bootstrap: Optional[str],
    kill_existing: bool,
) -> TmuxController:
    base_config = dict(get_config().get_section(name.lower()) or {})
    ai_config: Dict[str, object] = base_config
    ai_config["startup_timeout"] = startup_timeout
    ai_config["pause_on_manual_clients"] = False
    if init_wait is not None:
        ai_config["init_wait"] = init_wait

    if name.lower() == "gemini":
        ai_config["submit_key"] = "C-m"
        ai_config["text_enter_delay"] = 0.5
        ai_config["post_text_delay"] = 0.5

    exe_parts = shlex.split(executable)
    if not exe_parts:
        raise ValueError(f"No executable provided for {name}")

    launch_executable = exe_parts[0]
    launch_args = exe_parts[1:]

    if bootstrap:
        shell_command = f"{bootstrap} && {executable}"
        launch_executable = "bash"
        launch_args = ["-lc", shell_command]

    controller = TmuxController(
        session_name=session_name,
        executable=launch_executable,
        working_dir=working_dir,
        ai_config=ai_config,
        executable_args=launch_args,
    )

    controller.reset_output_cache()

    if kill_existing and controller.session_exists():
        if not controller.kill_session():
            raise SessionBackendError(
                f"Failed to kill existing tmux session '{session_name}' for {name}."
            )

    if controller.session_exists():
        controller.resume_automation(flush_pending=True)
        return controller

    if not auto_start:
        raise SessionNotFoundError(
            f"Tmux session '{session_name}' not found for {name}. "
            "Start the CLI manually or pass --auto-start."
        )

    controller.start()
    controller.wait_for_ready()
    return controller


def build_tmux_controllers(args) -> tuple[Dict[str, TmuxController], ParticipantMetadata]:
    controllers: Dict[str, TmuxController] = {}
    metadata: ParticipantMetadata = {
        "claude": {"type": "cli", "role": "lead reviewer"},
        "gemini": {"type": "cli", "role": "architect"},
        "codex": {"type": "cli", "role": "implementation"},
    }

    controllers["claude"] = build_controller(
        name="Claude",
        session_name=args.claude_session,
        executable=args.claude_executable,
        working_dir=args.claude_cwd,
        auto_start=args.auto_start,
        startup_timeout=args.claude_startup_timeout,
        init_wait=args.claude_init_wait,
        bootstrap=args.claude_bootstrap,
        kill_existing=args.kill_existing,
    )
    controllers["gemini"] = build_controller(
        name="Gemini",
        session_name=args.gemini_session,
        executable=args.gemini_executable,
        working_dir=args.gemini_cwd,
        auto_start=args.auto_start,
        startup_timeout=args.gemini_startup_timeout,
        init_wait=args.gemini_init_wait,
        bootstrap=args.gemini_bootstrap,
        kill_existing=args.kill_existing,
    )
    controllers["codex"] = build_controller(
        name="Codex",
        session_name=args.codex_session,
        executable=args.codex_executable,
        working_dir=args.codex_cwd,
        auto_start=args.auto_start,
        startup_timeout=args.codex_startup_timeout,
        init_wait=args.codex_init_wait,
        bootstrap=args.codex_bootstrap,
        kill_existing=args.kill_existing,
    )

    return controllers, metadata


# --------------------------------------------------------------------------- #
# Discussion runner
# --------------------------------------------------------------------------- #

def run_discussion(
    controllers: Dict[str, object],
    metadata: ParticipantMetadata,
    *,
    topic: str,
    participants: Sequence[str],
    max_turns: int,
    history_size: int,
    include_history: bool,
    debug_prompts: bool,
    debug_prompt_chars: int,
) -> Dict[str, object]:
    orchestrator = DevelopmentTeamOrchestrator(controllers, metadata=metadata)
    if debug_prompts:
        orchestrator.set_prompt_debug(True, preview_chars=debug_prompt_chars)

    context_manager = ContextManager(
        history_size=history_size,
        participant_metadata=metadata,
    )
    router = MessageRouter(participants, context_manager=context_manager)
    manager = ConversationManager(
        orchestrator,
        participants,
        context_manager=context_manager,
        message_router=router,
        participant_metadata=metadata,
        max_history=history_size,
        include_history=include_history,
    )

    conversation = manager.facilitate_discussion(topic, max_turns=max_turns)
    return {
        "conversation": conversation,
        "context_manager": context_manager,
        "message_router": router,
    }


def format_turn(turn: Dict[str, object]) -> str:
    parser = OutputParser()
    response = parser.clean_output(turn.get("response") or "", strip_trailing_prompts=True)
    dispatch = turn.get("dispatch") or {}
    queued = " (queued)" if dispatch.get("queued") else ""
    metadata = turn.get("metadata") or {}
    status_bits: List[str] = []
    if metadata.get("consensus"):
        status_bits.append("consensus")
    if metadata.get("conflict"):
        status_bits.append("conflict")
    if metadata.get("queued"):
        status_bits.append("queued")
    status_suffix = f" [{' '.join(status_bits)}]" if status_bits else ""
    prompt = (turn.get("prompt") or "").strip()
    formatted_prompt = textwrap.indent(prompt or "<no prompt>", "    ")
    formatted_response = textwrap.indent(response or "<no output>", "    ")

    return "\n".join(
        [
            f"Turn {turn.get('turn')} • {turn.get('speaker')}{queued}{status_suffix}",
            "  Prompt:",
            formatted_prompt,
            "  Response:",
            formatted_response,
        ]
    )


def cleanup_controller(controller: Optional[TmuxController], label: str) -> None:
    if controller is None:
        return

    try:
        if controller.session_exists():
            if controller.kill_session():
                print(f"[cleanup] Killed {label} session '{controller.session_name}'.")
            else:
                print(
                    f"[cleanup] Unable to kill {label} session '{controller.session_name}'.",
                    file=sys.stderr,
                )
    except (SessionNotFoundError, SessionBackendError) as exc:
        print(f"[cleanup] Error while killing {label} session: {exc}", file=sys.stderr)


def resolve_participants(
    available: Iterable[str],
    start_with: str,
) -> List[str]:
    available_list = list(available)
    normalized = [name for name in DEFAULT_PARTICIPANTS if name in available_list]
    if not normalized:
        normalized = available_list.copy()

    start = start_with.lower()
    if start not in normalized:
        return list(normalized)

    idx = normalized.index(start)
    return list(normalized[idx:] + normalized[:idx])


def parse_args(argv: Optional[Sequence[str]]) -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description=__doc__,
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    cfg = get_config()

    def default_command(agent: str) -> str:
        try:
            return cfg.get_executable_command(agent)
        except (KeyError, TypeError) as exc:
            parser.error(
                f"Executable for '{agent}' is not configured correctly in config.yaml: {exc}"
            )

    claude_default = default_command("claude")
    gemini_default = default_command("gemini")
    codex_default = default_command("codex")
    parser.add_argument(
        "topic",
        nargs="?",
        default="Align on the next sprint backlog",
        help="Discussion topic.",
    )
    parser.add_argument(
        "--topic",
        dest="topic_override",
        help="Discussion topic (overrides the positional argument).",
    )
    parser.add_argument(
        "--mode",
        choices=["stub", "tmux"],
        default="stub",
        help="Controller backend to use.",
    )
    parser.add_argument(
        "--max-turns",
        "--turns",
        type=int,
        dest="max_turns",
        default=6,
        help="Maximum number of turns to run.",
    )
    parser.add_argument(
        "--history-size",
        type=int,
        default=20,
        help="Number of turns to retain in the shared context.",
    )
    parser.add_argument(
        "--simple-prompts",
        action="store_true",
        help="Skip conversation history when building prompts.",
    )
    parser.add_argument(
        "--no-history",
        action="store_true",
        dest="simple_prompts",
        help=argparse.SUPPRESS,
    )
    parser.add_argument(
        "--start-with",
        choices=["claude", "gemini", "codex"],
        default="gemini",
        help="Which participant should speak first.",
    )
    parser.add_argument(
        "--auto-start",
        action="store_true",
        help="Launch tmux sessions automatically if they are not running.",
    )
    parser.add_argument(
        "--kill-existing",
        action="store_true",
        help="Kill existing tmux sessions before starting.",
    )
    parser.add_argument(
        "--cleanup-after",
        action="store_true",
        help="Kill tmux sessions after the discussion completes.",
    )
    parser.add_argument(
        "--startup-timeout",
        type=int,
        default=None,
        help="Convenience override for per-agent startup timeouts.",
    )
    parser.add_argument(
        "--debug-prompts",
        action="store_true",
        help="Log prompt diagnostics before dispatch.",
    )
    parser.add_argument(
        "--debug-prompt-chars",
        type=int,
        default=200,
        help="How many characters to include when debugging prompts.",
    )
    parser.add_argument(
        "--log-file",
        default=None,
        help="Optional path to write the conversation transcript and summary.",
    )

    # Claude options
    parser.add_argument(
        "--claude-session",
        default="claude",
        help="Tmux session name for Claude.",
    )
    parser.add_argument(
        "--claude-executable",
        default=claude_default,
        help=f"Executable used to start Claude (default: '{claude_default}').",
    )
    parser.add_argument(
        "--claude-startup-timeout",
        type=int,
        default=10,
        help="Seconds to wait for Claude session readiness when auto-starting.",
    )
    parser.add_argument(
        "--claude-init-wait",
        type=float,
        default=None,
        help="Seconds to pause after spawning Claude before sending the first input.",
    )
    parser.add_argument(
        "--claude-bootstrap",
        default=None,
        help="Command to run before launching the Claude executable.",
    )
    parser.add_argument(
        "--claude-cwd",
        default=None,
        help="Working directory for the Claude session.",
    )

    # Gemini options
    parser.add_argument(
        "--gemini-session",
        default="gemini",
        help="Tmux session name for Gemini.",
    )
    parser.add_argument(
        "--gemini-executable",
        default=gemini_default,
        help=f"Executable used to start Gemini (default: '{gemini_default}').",
    )
    parser.add_argument(
        "--gemini-startup-timeout",
        type=int,
        default=20,
        help="Seconds to wait for Gemini session readiness when auto-starting.",
    )
    parser.add_argument(
        "--gemini-init-wait",
        type=float,
        default=None,
        help="Seconds to pause after spawning Gemini before sending the first input.",
    )
    parser.add_argument(
        "--gemini-bootstrap",
        default=None,
        help="Command to run before launching the Gemini executable.",
    )
    parser.add_argument(
        "--gemini-cwd",
        default=None,
        help="Working directory for the Gemini session.",
    )

    # Codex options
    parser.add_argument(
        "--codex-session",
        default="codex",
        help="Tmux session name for Codex.",
    )
    parser.add_argument(
        "--codex-executable",
        default=codex_default,
        help=f"Executable used to start Codex (default: '{codex_default}').",
    )
    parser.add_argument(
        "--codex-startup-timeout",
        type=int,
        default=20,
        help="Seconds to wait for Codex session readiness when auto-starting.",
    )
    parser.add_argument(
        "--codex-init-wait",
        type=float,
        default=None,
        help="Seconds to pause after spawning Codex before sending the first input.",
    )
    parser.add_argument(
        "--codex-bootstrap",
        default=None,
        help="Command to run before launching the Codex executable.",
    )
    parser.add_argument(
        "--codex-cwd",
        default=None,
        help="Working directory for the Codex session.",
    )

    args = parser.parse_args(argv)

    if args.topic_override:
        args.topic = args.topic_override
    delattr(args, "topic_override")

    override = args.startup_timeout
    if override is not None:
        if args.claude_startup_timeout == parser.get_default("claude_startup_timeout"):
            args.claude_startup_timeout = override
        if args.gemini_startup_timeout == parser.get_default("gemini_startup_timeout"):
            args.gemini_startup_timeout = override
        if args.codex_startup_timeout == parser.get_default("codex_startup_timeout"):
            args.codex_startup_timeout = override

    return args


def main(argv: Optional[Sequence[str]] = None) -> int:
    args = parse_args(argv)

    if args.debug_prompts:
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        )

    include_history = not args.simple_prompts
    effective_history_size = max(1, args.history_size if include_history else 1)

    if args.mode == "stub":
        controllers, metadata = build_stub_controllers()
    else:
        try:
            controllers, metadata = build_tmux_controllers(args)
        except (SessionNotFoundError, SessionBackendError, ValueError) as exc:
            print(f"[error] {exc}", file=sys.stderr)
            return 1

    participants = resolve_participants(controllers.keys(), args.start_with)

    result = run_discussion(
        controllers,
        metadata,
        topic=args.topic,
        participants=participants,
        max_turns=max(1, args.max_turns),
        history_size=effective_history_size,
        include_history=include_history,
        debug_prompts=args.debug_prompts,
        debug_prompt_chars=args.debug_prompt_chars,
    )

    conversation = result["conversation"]
    context_manager: ContextManager = result["context_manager"]

    print(f"Three-agent discussion on: {args.topic}")
    print("=" * 80)
    for turn in conversation:
        print(format_turn(turn))
        print("-" * 80)

    summary = context_manager.summarize_conversation(context_manager.history)
    print("\nSummary:")
    print(summary or "(no summary available)")

    if args.log_file:
        log_path = Path(args.log_file)
        if log_path.suffix:
            log_path.parent.mkdir(parents=True, exist_ok=True)
        else:
            log_path.mkdir(parents=True, exist_ok=True)
            log_path = log_path / "discussion.log"

        log_lines = ["=== Conversation Transcript ==="]
        for turn in conversation:
            log_lines.append(format_turn(turn))
            log_lines.append("-" * 80)
        log_lines.append("\n=== Shared Context Summary ===")
        log_lines.append(summary or "(no summary available)")
        log_path.write_text("\n".join(log_lines), encoding="utf-8")
        print(f"\n[log] Conversation written to {log_path}")

    if args.cleanup_after and args.mode == "tmux":
        for name, controller in controllers.items():
            cleanup_controller(controller, name.capitalize())

    return 0


if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))
</file>

<file path="src/controllers/__init__.py">
"""
AI Controllers

Provides controllers for interacting with AI CLI tools via tmux.
"""

from .tmux_controller import TmuxController
from .claude_controller import ClaudeController
from .gemini_controller import GeminiController
from .codex_controller import CodexController
from .qwen_controller import QwenController

__all__ = [
    'TmuxController',
    'ClaudeController',
    'GeminiController',
    'CodexController',
    'QwenController',
]
</file>

<file path="src/controllers/claude_controller.py">
"""
Claude Code Controller

Wrapper around TmuxController configured specifically for Claude Code.
"""

from typing import Optional
from .tmux_controller import TmuxController
from ..utils.config_loader import get_config


class ClaudeController(TmuxController):
    """Controller specifically configured for Claude Code."""

    def __init__(
        self,
        session_name: Optional[str] = None,
        working_dir: Optional[str] = None
    ):
        """
        Initialize ClaudeController with Claude-specific configuration.

        Args:
            session_name: Name of tmux session (uses config default if not specified)
            working_dir: Working directory (defaults to current dir)
        """
        # Load Claude configuration
        config = get_config()
        claude_config = config.get_section('claude')
        tmux_config = config.get_section('tmux')

        # Use configured session name if not specified
        if session_name is None:
            session_name = tmux_config.get('claude_session', 'claude')

        # Get executable from config
        executable = claude_config.get('executable', 'claude')

        # Initialize parent with Claude configuration
        executable_args = claude_config.get('executable_args', [])

        super().__init__(
            session_name=session_name,
            executable=executable,
            working_dir=working_dir,
            ai_config=claude_config,
            executable_args=executable_args
        )

        # Store Claude-specific markers
        self.response_marker = claude_config.get('response_marker', '●')
</file>

<file path="src/controllers/gemini_controller.py">
"""
Gemini CLI Controller

Wrapper around TmuxController configured specifically for Gemini CLI.
"""

from typing import Optional
from .tmux_controller import TmuxController
from ..utils.config_loader import get_config


class GeminiController(TmuxController):
    """Controller specifically configured for Gemini CLI."""

    def __init__(
        self,
        session_name: Optional[str] = None,
        working_dir: Optional[str] = None
    ):
        """
        Initialize GeminiController with Gemini-specific configuration.

        Args:
            session_name: Name of tmux session (uses config default if not specified)
            working_dir: Working directory (defaults to current dir)
        """
        # Load Gemini configuration
        config = get_config()
        gemini_config = dict(config.get_section('gemini') or {})
        tmux_config = config.get_section('tmux')

        # Override for tmux reliability: Use C-m for consistent command submission
        # This enables the double-submit pattern (C-m + fallback Enter) which is
        # essential for complex/normalized multiline commands in orchestrated scenarios
        gemini_config["submit_key"] = "C-m"
        gemini_config["text_enter_delay"] = 0.5
        gemini_config["post_text_delay"] = 0.5

        # Use configured session name if not specified
        if session_name is None:
            session_name = tmux_config.get('gemini_session', 'gemini')

        # Get executable from config
        executable = gemini_config.get('executable', 'gemini')

        # Initialize parent with Gemini configuration
        executable_args = gemini_config.get('executable_args', [])

        super().__init__(
            session_name=session_name,
            executable=executable,
            working_dir=working_dir,
            ai_config=gemini_config,
            executable_args=executable_args
        )

        # Store Gemini-specific markers
        self.response_marker = gemini_config.get('response_marker', '✦')
        self.supports_tools = gemini_config.get('supports_tools', True)
        self.tool_marker = gemini_config.get('tool_marker', '✓')
</file>

<file path="src/orchestrator/__init__.py">
"""
Orchestration package wiring the multi-AI collaboration stack.
"""

from .conversation_manager import ConversationManager
from .context_manager import ContextManager
from .message_router import MessageRouter
from .orchestrator import DevelopmentTeamOrchestrator

__all__ = [
    "DevelopmentTeamOrchestrator",
    "ConversationManager",
    "ContextManager",
    "MessageRouter",
]
</file>

<file path="src/orchestrator/context_manager.py">
"""
Lightweight context manager for orchestrated AI collaborations.

The context manager maintains recent conversation history, decisions, and
observations so higher-level orchestration layers can construct prompts and
summaries without re-implementing bookkeeping logic in every workflow.
"""

from __future__ import annotations

from collections import deque
from typing import Any, Deque, Dict, List, Optional, Sequence

from ..utils.logger import get_logger


class ContextManager:
    """
    Track conversation context, decisions, and conflict signals.

    The manager keeps a bounded turn history to minimize memory pressure while
    still offering recent context for prompt construction. Consumers can record
    decisions and query consolidated project state snapshots.
    """

    def __init__(
        self,
        *,
        history_size: int = 200,
        participant_metadata: Optional[Dict[str, Dict[str, Any]]] = None,
    ) -> None:
        if history_size < 1:
            raise ValueError("history_size must be positive")

        self.logger = get_logger("orchestrator.context")
        self._history: Deque[Dict[str, Any]] = deque(maxlen=history_size)
        self._decisions: List[Dict[str, Any]] = []
        self._conflicts: List[Dict[str, Any]] = []
        self._consensus_events: List[Dict[str, Any]] = []
        self._project_state: Dict[str, Any] = {}
        self._participants: Dict[str, Dict[str, Any]] = {}

        if participant_metadata:
            for name, metadata in participant_metadata.items():
                self.register_participant(name, metadata)

    # ------------------------------------------------------------------ #
    # Turn and decision management
    # ------------------------------------------------------------------ #

    def record_turn(self, turn: Dict[str, Any]) -> None:
        """Store a sanitized copy of the latest conversation turn."""
        self._history.append(self._sanitize_turn(turn))

    # Backwards-compatible aliases for other naming conventions
    append_turn = record_turn
    save_turn = record_turn

    def record_conflict(self, turn: Dict[str, Any], reason: str) -> None:
        """Track conflicts for later review or escalation."""
        payload = self._sanitize_turn(turn)
        payload["reason"] = reason
        self._conflicts.append(payload)

    def record_consensus(self, turn: Dict[str, Any]) -> None:
        """Track consensus outcomes so we can summarize decisions later."""
        self._consensus_events.append(self._sanitize_turn(turn))

    def save_decision(self, decision: Dict[str, Any]) -> None:
        """Persist key decisions reached by the team."""
        if not isinstance(decision, dict):
            self.logger.warning("Ignoring non-dict decision payload: %r", decision)
            return

        self._decisions.append(decision.copy())

    # ------------------------------------------------------------------ #
    # Context inspection helpers
    # ------------------------------------------------------------------ #

    @property
    def history(self) -> List[Dict[str, Any]]:
        """Return a snapshot of the stored conversation history."""
        return list(self._history)

    @property
    def decisions(self) -> List[Dict[str, Any]]:
        """Return recorded decisions."""
        return list(self._decisions)

    @property
    def conflicts(self) -> List[Dict[str, Any]]:
        """Return historical conflict events."""
        return list(self._conflicts)

    @property
    def consensus_events(self) -> List[Dict[str, Any]]:
        """Return turns where consensus was detected."""
        return list(self._consensus_events)

    def get_project_context(self) -> Dict[str, Any]:
        """
        Consolidated view of recent history and decisions.

        Returns:
            Dict with keys:
                - history: list of turn dicts
                - decisions: list of decisions
                - conflicts: recorded conflict events
                - consensus: recorded consensus events
                - state: current project state payload
                - participants: participant metadata (if registered)
        """
        return {
            "history": self.history,
            "decisions": self.decisions,
            "conflicts": self.conflicts,
            "consensus": self.consensus_events,
            "state": self._project_state.copy(),
            "participants": self.participants,
        }

    def update_project_state(self, **state: Any) -> None:
        """Merge keyword updates into the project state payload."""
        self._project_state.update(state)

    # ------------------------------------------------------------------ #
    # Prompt and summary helpers
    # ------------------------------------------------------------------ #

    def build_prompt(self, ai_name: str, task: str, *, include_history: bool = True) -> str:
        """
        Construct a prompt for the requested AI participant.

        Args:
            ai_name: Controller identifier (e.g., "claude").
            task: The current topic or objective.
            include_history: Whether to embed a short context summary.
        """
        metadata = self._participants.get(ai_name, {})
        participant_type = metadata.get("type", "cli")
        role = metadata.get("role") or metadata.get("persona")
        host = metadata.get("host")
        guidance = metadata.get("guidance")

        if not include_history:
            return (
                f"{ai_name}, respond only with: 'Hello from {ai_name} — message received.'\n"
                "Do not run tools or reference previous steps. Confirm you saw this message and stop."
            )

        if participant_type == "agent":
            host_blurb = f" hosted via {host}" if host else ""
            performer = role or "implementation"
            lines = [
                f"{ai_name}, you're operating as the {performer} agent{host_blurb}.",
                f"Address the topic: {task}. Focus on concrete actions, code, or fixes.",
            ]
        else:
            qualifier = f" ({role})" if role else ""
            lines = [
                f"{ai_name}{qualifier}, we're collaborating on: {task}.",
                "Provide your next contribution focusing on actionable steps.",
            ]

        if guidance:
            lines.append(str(guidance))

        if include_history:
            blurb = self._format_recent_history()
            if blurb:
                lines.append(f"Recent context: {blurb}")

        return "\n".join(lines)

    def summarize_conversation(
        self,
        messages: Sequence[Dict[str, Any]],
        *,
        max_length: int = 400,
    ) -> str:
        """
        Return a truncated summary of the supplied messages.

        The summary favours responses when available, falling back to prompts.
        """
        fragments: List[str] = []
        for turn in messages:
            speaker = turn.get("speaker", "unknown")
            body = turn.get("response") or turn.get("prompt") or ""
            snippet = f"{speaker}: {body}".strip()
            if snippet:
                fragments.append(snippet)

        summary = " | ".join(fragments)
        if len(summary) > max_length:
            return summary[: max_length - 3] + "..."
        return summary

    # ------------------------------------------------------------------ #
    # Internal helpers
    # ------------------------------------------------------------------ #

    def _format_recent_history(self, max_turns: int = 3) -> str:
        """Return a compact description of the most recent turns."""
        if not self._history:
            return ""

        recent = list(self._history)[-max_turns:]
        fragments = []
        for turn in recent:
            speaker = turn.get("speaker", "unknown")
            response = turn.get("response")
            if response:
                fragments.append(f"{speaker}: {response}")
            else:
                fragments.append(f"{speaker} queued a prompt")
        return "; ".join(fragments)

    @staticmethod
    def _sanitize_turn(turn: Dict[str, Any]) -> Dict[str, Any]:
        """
        Create a shallow copy of the supplied turn.

        The function avoids mutating caller-owned dictionaries and ensures
        metadata dictionaries are shallow-copied as well.
        """
        sanitized = turn.copy()
        metadata = sanitized.get("metadata")
        if isinstance(metadata, dict):
            sanitized["metadata"] = metadata.copy()
        return sanitized


    # ------------------------------------------------------------------ #
    # Participant metadata helpers
    # ------------------------------------------------------------------ #

    def register_participant(self, name: str, metadata: Optional[Dict[str, Any]] = None) -> None:
        """Register or update metadata for a participant."""
        if not isinstance(name, str) or not name:
            return

        merged: Dict[str, Any] = {"name": name}
        if isinstance(metadata, dict):
            merged.update(metadata)
        merged.setdefault("type", "cli")
        self._participants[name] = merged

    def get_participant_metadata(self, name: str) -> Dict[str, Any]:
        """Return stored metadata for ``name``."""
        payload = self._participants.get(name, {})
        return payload.copy() if isinstance(payload, dict) else {}

    @property
    def participants(self) -> Dict[str, Dict[str, Any]]:
        """Return a copy of registered participant metadata."""
        return {name: meta.copy() for name, meta in self._participants.items()}
        return sanitized


__all__ = ["ContextManager"]
</file>

<file path="tests/test_conversation_manager.py">
#!/usr/bin/env python3
"""
Tests for the conversation manager scaffold.
"""

from collections import deque
from typing import Any, Deque, Dict, List, Tuple

from src.orchestrator.conversation_manager import ConversationManager
from src.orchestrator.message_router import MessageRouter
from src.orchestrator.context_manager import ContextManager
from src.orchestrator.orchestrator import DevelopmentTeamOrchestrator


class FakeConversationalController:
    """
    Minimal controller surface for conversation tests.

    The controller never pauses automation and exposes ``get_last_output`` so the
    conversation manager can capture responses.
    """

    def __init__(self, outputs: List[str]) -> None:
        self.sent: List[str] = []
        self._outputs: Deque[str] = deque(outputs)
        self._last_output: str | None = None
        self._paused: bool = False
        self._pause_reason: str | None = None
        self._manual_clients: List[str] = []
        self._internal_queue: Deque[Tuple[str, bool]] = deque()

    # --- Controller contract -------------------------------------------------

    def get_status(self) -> Dict[str, Dict[str, object]]:
        return {
            "automation": {
                "paused": self._paused,
                "reason": self._pause_reason,
                "pending_commands": len(self._internal_queue),
                "manual_clients": list(self._manual_clients),
            }
        }

    def send_command(self, command: str, submit: bool = True) -> bool:
        if self._paused:
            self._internal_queue.append((command, submit))
            return False

        self.sent.append(command)
        self._last_output = self._outputs.popleft() if self._outputs else ""
        return True

    # --- Helpers -------------------------------------------------------------

    def get_last_output(self) -> str | None:
        return self._last_output

    def wait_for_ready(self, timeout: float | None = None, check_interval: float | None = None) -> bool:
        return True

    def set_paused(self, paused: bool, *, reason: str | None = None, manual_clients: List[str] | None = None) -> None:
        self._paused = paused
        self._pause_reason = reason
        self._manual_clients = manual_clients or []
        if not paused:
            self._flush_internal_queue()

    def _flush_internal_queue(self) -> None:
        while self._internal_queue:
            command, submit = self._internal_queue.popleft()
            # Emulate normal send behaviour on resume
            self.send_command(command, submit=submit)


def test_conversation_manager_round_robin_dispatch() -> None:
    claude_controller = FakeConversationalController(
        ["Here's an approach.", "Consensus: adopt plan A."]
    )
    gemini_controller = FakeConversationalController(
        ["Let's explore plan B to cover edge cases."]
    )

    orchestrator = DevelopmentTeamOrchestrator(
        {"claude": claude_controller, "gemini": gemini_controller}
    )
    manager = ConversationManager(orchestrator, ["claude", "gemini"])

    conversation = manager.facilitate_discussion("Design the API", max_turns=4)

    # Expect alternating turns until consensus is declared.
    assert [turn["speaker"] for turn in conversation] == ["claude", "gemini", "claude"]
    assert manager.detect_consensus(conversation) is True
    assert conversation[-1]["metadata"]["consensus"] is True

    # Confirm prompts made it to the controllers.
    assert len(claude_controller.sent) == 2
    assert len(gemini_controller.sent) == 1


def test_detect_conflict_on_disagreement_keyword() -> None:
    orchestrator = DevelopmentTeamOrchestrator({})
    manager = ConversationManager(orchestrator, ["claude"])

    conversation = [
        {"speaker": "claude", "response": "Proposal A looks solid."},
        {"speaker": "gemini", "response": "I disagree with that direction."},
    ]
    conflict, reason = manager.detect_conflict(conversation)

    assert conflict is True
    assert "disagree" in reason


def test_detect_conflict_ignores_code_block_keywords() -> None:
    orchestrator = DevelopmentTeamOrchestrator({})
    manager = ConversationManager(orchestrator, ["claude"])

    conversation = [
        {"speaker": "claude", "response": "Initial analysis."},
        {
            "speaker": "gemini",
            "response": "```python\nraise ValueError('Input cannot be empty')\n```",
        },
    ]

    conflict, reason = manager.detect_conflict(conversation)

    assert conflict is False
    assert reason == ""


def test_conversation_manager_records_history_in_context_manager() -> None:
    claude_controller = FakeConversationalController(
        ["Initial thoughts.", "Consensus reached on plan A."]
    )
    gemini_controller = FakeConversationalController(
        ["Building on that idea."]
    )

    orchestrator = DevelopmentTeamOrchestrator(
        {"claude": claude_controller, "gemini": gemini_controller}
    )
    context_manager = ContextManager(history_size=5)
    manager = ConversationManager(
        orchestrator,
        ["claude", "gemini"],
        context_manager=context_manager,
    )

    conversation = manager.facilitate_discussion("Choose the rollout strategy", max_turns=5)

    assert len(conversation) == 3
    assert len(context_manager.history) == 3
    assert context_manager.consensus_events, "Consensus event should be recorded"

    prompt = context_manager.build_prompt("gemini", "Provide final summary", include_history=True)
    assert "Recent context" in prompt


def test_conflict_notification_updates_context_manager() -> None:
    claude_controller = FakeConversationalController(
        ["Let's proceed with plan A."]
    )
    gemini_controller = FakeConversationalController(
        ["I disagree; plan A introduces risks."]
    )

    orchestrator = DevelopmentTeamOrchestrator(
        {"claude": claude_controller, "gemini": gemini_controller}
    )
    context_manager = ContextManager(history_size=5)
    manager = ConversationManager(
        orchestrator,
        ["claude", "gemini"],
        context_manager=context_manager,
    )

    conversation = manager.facilitate_discussion("Decide between plans", max_turns=4)

    assert len(conversation) == 2
    assert conversation[-1]["metadata"]["conflict"] is True
    assert context_manager.conflicts, "Conflict should be tracked"
    assert "disagree" in context_manager.conflicts[0]["reason"]


def test_detect_conflict_matches_stronger_phrases() -> None:
    orchestrator = DevelopmentTeamOrchestrator({})
    manager = ConversationManager(orchestrator, ["claude"])

    conversation = [
        {"speaker": "claude", "response": "Proposal summary."},
        {"speaker": "gemini", "response": "I cannot agree with this direction."},
    ]

    conflict, reason = manager.detect_conflict(conversation)

    assert conflict is True
    assert "cannot agree" in reason


def test_participant_metadata_registered_with_context_manager() -> None:
    class RecordingContext(ContextManager):
        def __init__(self) -> None:
            super().__init__()
            self.registered: Dict[str, Dict[str, Any]] = {}

        def register_participant(self, name: str, metadata: Dict[str, Any] | None = None) -> None:  # type: ignore[override]
            self.registered[name] = metadata or {}
            super().register_participant(name, metadata)

    orchestrator = DevelopmentTeamOrchestrator({})
    context = RecordingContext()
    metadata = {"codex": {"type": "cli", "role": "implementation"}}

    ConversationManager(
        orchestrator,
        ["codex"],
        context_manager=context,
        participant_metadata=metadata,
    )

    assert "codex" in context.registered
    assert context.registered["codex"]["type"] == "cli"
    stored = context.get_participant_metadata("codex")
    assert stored["role"] == "implementation"

def test_context_manager_prompt_includes_role_details() -> None:
    context = ContextManager(
        participant_metadata={"codex": {"type": "cli", "role": "implementation"}}
    )
    prompt = context.build_prompt("codex", "Implement the new endpoint", include_history=True)
    assert "implementation" in prompt.lower()


def test_orchestrator_start_discussion_with_codex_participant() -> None:
    claude_controller = FakeConversationalController(
        ["Initial assessment.", "Alignment reached."]
    )
    gemini_controller = FakeConversationalController(
        ["Architecture notes.", "No blockers identified."]
    )
    codex_controller = FakeConversationalController(
        ["Implementation plan ready.", "Pushing final changes."]
    )

    controllers = {
        "claude": claude_controller,
        "gemini": gemini_controller,
        "codex": codex_controller,
    }
    metadata = {
        "claude": {"type": "cli", "role": "review"},
        "gemini": {"type": "cli", "role": "architecture"},
        "codex": {"type": "cli", "role": "implementation"},
    }

    orchestrator = DevelopmentTeamOrchestrator(controllers, metadata=metadata)
    result = orchestrator.start_discussion("Coordinate handoff", max_turns=3)

    conversation = result["conversation"]
    assert len(conversation) == 3
    assert [turn["speaker"] for turn in conversation] == ["claude", "gemini", "codex"]

    context = result["context_manager"]
    agent_prompt = context.build_prompt("codex", "Follow-up validation", include_history=True)
    assert "implementation" in agent_prompt.lower()


def test_message_router_adds_partner_updates_to_prompt() -> None:
    claude_controller = FakeConversationalController(
        ["Initial proposal.", "Consensus reached."]
    )
    gemini_controller = FakeConversationalController(
        ["Follow-up analysis."]
    )

    orchestrator = DevelopmentTeamOrchestrator(
        {"claude": claude_controller, "gemini": gemini_controller}
    )
    router = MessageRouter(["claude", "gemini"])
    manager = ConversationManager(
        orchestrator,
        ["claude", "gemini"],
        message_router=router,
    )

    conversation = manager.facilitate_discussion("Evaluate design trade-offs", max_turns=4)

    assert len(conversation) == 3
    assert "Initial proposal." in gemini_controller.sent[0]
    assert "Follow-up analysis." in claude_controller.sent[-1]


def test_message_router_skips_delivery_when_turn_is_queued() -> None:
    claude_controller = FakeConversationalController(
        ["Draft solution."]
    )
    gemini_controller = FakeConversationalController(
        ["Queued response that should not route."]
    )
    # Gemini starts paused to force orchestrator queueing.
    gemini_controller.set_paused(True, reason="manual-attach", manual_clients=["tmux-client"])

    orchestrator = DevelopmentTeamOrchestrator(
        {"claude": claude_controller, "gemini": gemini_controller}
    )
    router = MessageRouter(["claude", "gemini"])
    manager = ConversationManager(
        orchestrator,
        ["claude", "gemini"],
        message_router=router,
    )

    conversation = manager.facilitate_discussion("Queued delivery check", max_turns=3)

    assert len(conversation) == 2
    assert conversation[1]["dispatch"]["queued"] is True
    base_prompt = "[Base]"
    prompt_for_claude = router.prepare_prompt(
        recipient="claude",
        topic="Queued delivery check",
        base_prompt=base_prompt,
    )
    assert prompt_for_claude == base_prompt, "No routed message should reach Claude"


def test_determine_next_speaker_retry_after_queue() -> None:
    claude_controller = FakeConversationalController(["Initial idea."])
    gemini_controller = FakeConversationalController(["Queued response."])
    gemini_controller.set_paused(True, reason="manual-attach")

    orchestrator = DevelopmentTeamOrchestrator(
        {"claude": claude_controller, "gemini": gemini_controller}
    )
    router = MessageRouter(["claude", "gemini"])
    manager = ConversationManager(
        orchestrator,
        ["claude", "gemini"],
        message_router=router,
    )

    conversation = manager.facilitate_discussion("Retry speaker", max_turns=2)

    assert conversation[-1]["metadata"]["queued"] is True
    next_speaker = manager.determine_next_speaker(conversation)
    assert next_speaker == "gemini"


def test_orchestrator_start_discussion_with_router() -> None:
    claude_controller = FakeConversationalController(
        ["Draft outline.", "Consensus achieved."]
    )
    gemini_controller = FakeConversationalController(
        ["Refined analysis."]
    )

    orchestrator = DevelopmentTeamOrchestrator(
        {"claude": claude_controller, "gemini": gemini_controller}
    )

    result = orchestrator.start_discussion(
        "Plan implementation",
        max_turns=4,
    )

    conversation = result["conversation"]
    context_manager = result["context_manager"]
    message_router = result["message_router"]

    assert len(conversation) == 3
    assert conversation[-1]["metadata"]["consensus"] is True
    assert len(context_manager.history) == 3
    prompt = message_router.prepare_prompt(
        recipient="gemini",
        topic="Plan implementation",
        base_prompt="[Reminder]",
    )
    assert "[Reminder]" in prompt
</file>

<file path="tests/test_counting_smoke.py">
#!/usr/bin/env python3
"""
Simple alternating counting smoke test for Claude and Gemini.

Each turn instructs the active AI to respond with the next integer in the
sequence. Keeping the transcript minimal makes it easy to spot desynchronisation.
"""

from __future__ import annotations

import argparse
import sys
import time
from pathlib import Path
from typing import Dict, List, Optional

from src.controllers.tmux_controller import (
    TmuxController,
    SessionBackendError,
    SessionNotFoundError,
)
from src.utils.config_loader import get_config
from src.utils.output_parser import OutputParser


def build_controller(
    *,
    name: str,
    session_name: str,
    executable: str,
    working_dir: Optional[str],
    auto_start: bool,
    startup_timeout: int,
    init_wait: Optional[float],
    kill_existing: bool,
) -> TmuxController:
    config = dict(get_config().get_section(name.lower()) or {})
    config["startup_timeout"] = startup_timeout
    if init_wait is not None:
        config["init_wait"] = init_wait

    parts = executable.split()
    controller = TmuxController(
        session_name=session_name,
        executable=parts[0],
        working_dir=working_dir,
        ai_config=config,
        executable_args=tuple(parts[1:]),
    )

    controller.reset_output_cache()

    if kill_existing and controller.session_exists():
        controller.kill()
        time.sleep(1)

    if controller.session_exists():
        controller.resume_automation(flush_pending=True)
        return controller

    if not auto_start:
        raise SessionNotFoundError(
            f"Session '{session_name}' not found for {name}. Start manually or pass --auto-start."
        )

    controller.start()
    controller.wait_for_ready(timeout=startup_timeout)
    return controller


def parse_args(argv: list[str]) -> argparse.Namespace:
    cfg = get_config()
    tmux_cfg = cfg.get_section("tmux")

    parser = argparse.ArgumentParser(
        description="Minimal alternating counting smoke test for Claude and Gemini."
    )
    def default_command(agent: str) -> str:
        try:
            return cfg.get_executable_command(agent)
        except (KeyError, TypeError) as exc:
            parser.error(
                f"Executable for '{agent}' is not configured correctly in config.yaml: {exc}"
            )

    claude_default = default_command("claude")
    gemini_default = default_command("gemini")
    parser.add_argument("--count-to", type=int, default=20)
    parser.add_argument("--auto-start", action="store_true")
    parser.add_argument("--kill-existing", action="store_true")
    parser.add_argument("--claude-session", default=tmux_cfg.get("claude_session", "claude"))
    parser.add_argument("--gemini-session", default=tmux_cfg.get("gemini_session", "gemini"))
    parser.add_argument(
        "--claude-executable",
        default=claude_default,
    )
    parser.add_argument(
        "--gemini-executable",
        default=gemini_default,
    )
    parser.add_argument("--claude-startup-timeout", type=int, default=20)
    parser.add_argument("--gemini-startup-timeout", type=int, default=60)
    parser.add_argument("--claude-init-wait", type=float, default=None)
    parser.add_argument("--gemini-init-wait", type=float, default=None)
    parser.add_argument("--claude-cwd", default=None)
    parser.add_argument("--gemini-cwd", default=None)
    parser.add_argument("--log-file", default=None)
    parser.add_argument(
        "--initial-delay",
        type=float,
        default=2.0,
        help="Seconds to wait before the first prompt (default: 2.0).",
    )
    parser.add_argument(
        "--turn-delay",
        type=float,
        default=1.0,
        help="Seconds to wait before each subsequent prompt (default: 1.0).",
    )
    return parser.parse_args(argv)


def capture_scrollback_lines(controller: TmuxController) -> List[str]:
    try:
        snapshot = controller.capture_scrollback()
    except (SessionBackendError, SessionNotFoundError):
        return []
    return snapshot.splitlines()


def compute_delta(previous: List[str], current: List[str], tail_limit: int) -> List[str]:
    if previous and len(current) >= len(previous):
        limit = min(len(previous), len(current))
        prefix = 0
        while prefix < limit and previous[prefix] == current[prefix]:
            prefix += 1
        delta = current[prefix:]
    else:
        delta = current

    if tail_limit and len(delta) > tail_limit:
        delta = delta[-tail_limit:]
    return delta


def send_number(controller: TmuxController, number: int, turn_delay: float) -> str:
    prompt = f"Respond ONLY with the number {number}."
    if turn_delay > 0:
        time.sleep(turn_delay)
    before_lines = capture_scrollback_lines(controller)
    controller.send_command(prompt, submit=True)
    controller.wait_for_ready()
    after_lines = capture_scrollback_lines(controller)
    delta_lines = compute_delta(before_lines, after_lines, tail_limit=120)
    if delta_lines:
        raw_output = "\n".join(delta_lines)
    else:
        raw_output = controller.get_last_output(tail_lines=120) or ""
    parser = OutputParser()
    cleaned = parser.clean_output(raw_output, strip_trailing_prompts=True)
    return cleaned or raw_output


def main(argv: list[str]) -> int:
    args = parse_args(argv)
    transcript_path = Path(args.log_file) if args.log_file else None
    transcript_lines: list[str] = []

    try:
        claude = build_controller(
            name="Claude",
            session_name=args.claude_session,
            executable=args.claude_executable,
            working_dir=args.claude_cwd,
            auto_start=args.auto_start,
            startup_timeout=args.claude_startup_timeout,
            init_wait=args.claude_init_wait,
            kill_existing=args.kill_existing,
        )
        gemini = build_controller(
            name="Gemini",
            session_name=args.gemini_session,
            executable=args.gemini_executable,
            working_dir=args.gemini_cwd,
            auto_start=args.auto_start,
            startup_timeout=args.gemini_startup_timeout,
            init_wait=args.gemini_init_wait,
            kill_existing=args.kill_existing,
        )
    except (SessionBackendError, SessionNotFoundError) as exc:
        print(f"[error] {exc}", file=sys.stderr)
        return 1

    controllers: Dict[str, TmuxController] = {"gemini": gemini, "claude": claude}
    order = ["gemini", "claude"]

    if args.initial_delay > 0:
        print(f"[info] Waiting {args.initial_delay:.1f}s before starting the count...")
        time.sleep(args.initial_delay)

    print("=== Counting Smoke Test ===")
    for number in range(1, args.count_to + 1):
        speaker = order[(number - 1) % len(order)]
        controller = controllers[speaker]
        print(f"[turn {number}] {speaker} → {number}")
        output = send_number(controller, number, args.turn_delay).strip()
        print(f"    output: {output or '(no output)'}")
        transcript_lines.append(f"{number}: {speaker}: {output}")

    if transcript_path:
        transcript_path.write_text("\n".join(transcript_lines), encoding="utf-8")
        print(f"\nTranscript written to {transcript_path}")

    print("=== Done ===")
    return 0


if __name__ == "__main__":
    sys.exit(main(sys.argv[1:]))
</file>

<file path="tests/test_gemini_manual.py">
#!/usr/bin/env python3
"""
Manual Gemini test - similar to Claude manual test

Allows user to attach and observe Gemini CLI interaction
"""

import subprocess
import time
import sys

from src.utils.config_loader import get_config
from src.utils.path_helpers import get_repo_root


def run_tmux(args):
    """Run tmux command"""
    cmd = ["tmux"] + args
    return subprocess.run(cmd, capture_output=True, text=True)


def main():
    session_name = "gemini-manual-test"
    working_dir = str(get_repo_root())

    print("=== Gemini Manual Interactive Test ===\n")

    # Clean up existing session
    print("Cleaning up any existing session...")
    run_tmux(["kill-session", "-t", session_name])
    time.sleep(1)

    # Start Gemini session
    gemini_parts = list(get_config().get_executable_parts("gemini"))

    print(f"Starting Gemini CLI session '{session_name}'...")
    result = run_tmux([
        "new-session", "-d",
        "-s", session_name,
        "-c", working_dir,
        *gemini_parts,
    ])

    if result.returncode != 0:
        print(f"Failed to start session: {result.stderr}")
        return 1

    print(f"✓ Session '{session_name}' started!\n")
    print("=" * 60)
    print("ATTACH NOW to observe:")
    print(f"  tmux attach -t {session_name} -r")
    print("=" * 60)
    print("\nWaiting 10 seconds for you to attach...")

    for i in range(10, 0, -1):
        print(f"  {i}...", end="\r")
        time.sleep(1)
    print("\n")

    # Test 1
    print("TEST 1: Sending 'What is 2 + 2?'")
    run_tmux(["send-keys", "-t", session_name, "What is 2 + 2?"])
    time.sleep(0.2)
    run_tmux(["send-keys", "-t", session_name, "Enter"])
    print("  Waiting 5 seconds for response...")
    time.sleep(5)
    print("  ✓ Done\n")

    # Test 2
    print("TEST 2: Sending 'What is Python?'")
    run_tmux(["send-keys", "-t", session_name, "What is Python?"])
    time.sleep(0.2)
    run_tmux(["send-keys", "-t", session_name, "Enter"])
    print("  Waiting 5 seconds for response...")
    time.sleep(5)
    print("  ✓ Done\n")

    # Test 3
    print("TEST 3: Sending 'List 3 programming languages'")
    run_tmux(["send-keys", "-t", session_name, "List 3 programming languages"])
    time.sleep(0.2)
    run_tmux(["send-keys", "-t", session_name, "Enter"])
    print("  Waiting 5 seconds for response...")
    time.sleep(5)
    print("  ✓ Done\n")

    # Capture final output
    print("Capturing final output:")
    print("-" * 60)
    result = run_tmux(["capture-pane", "-t", session_name, "-p", "-S", "-30"])
    print(result.stdout)
    print("-" * 60)
    print()

    # Keep alive
    print("=" * 60)
    print(f"Session '{session_name}' is still running!")
    print(f"  To attach: tmux attach -t {session_name} -r")
    print(f"  To kill: tmux kill-session -t {session_name}")
    print("=" * 60)
    print("\nTest complete. Session kept alive for your inspection.")

    return 0


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="src/orchestrator/orchestrator.py">
"""
Development team orchestrator that coordinates multiple AI controllers.

The orchestrator monitors each controller's automation state, defers command
dispatch while a human is attached, and flushes queued work once automation
resumes. This module intentionally keeps the orchestration surface minimal so
additional subsystems (conversation manager, task planner, etc.) can build on
top of a stable contract.
"""

from __future__ import annotations

from collections import deque
from typing import Any, Deque, Dict, Iterable, List, Optional, Sequence, Tuple

from ..utils.logger import get_logger


ControllerType = Any  # Protocol-like duck typing (send_command, get_status)


class DevelopmentTeamOrchestrator:
    """
    Coordinates collaborative workflows across multiple AI controllers.

    The class tracks automation pauses reported by controllers (e.g., when a
    human attaches to a tmux session) and ensures commands are only dispatched
    once the session is safe for automation again.
    """

    def __init__(
        self,
        controllers: Optional[Dict[str, ControllerType]] = None,
        *,
        metadata: Optional[Dict[str, Dict[str, Any]]] = None,
    ) -> None:
        """
        Args:
            controllers: Optional mapping of controller name -> controller object.
            metadata: Optional mapping of controller name -> participant metadata.
        """
        self.logger = get_logger("orchestrator.development_team")
        self.controllers: Dict[str, ControllerType] = {}
        self._pending: Dict[str, Deque[Tuple[str, bool]]] = {}
        self._debug_prompts: bool = False
        self._debug_prompt_chars: int = 200
        self.controller_metadata: Dict[str, Dict[str, Any]] = {}

        if controllers:
            for name, controller in controllers.items():
                meta = metadata.get(name) if isinstance(metadata, dict) else None
                self.register_controller(name, controller, metadata=meta)

    # ------------------------------------------------------------------ #
    # Controller registration & status helpers
    # ------------------------------------------------------------------ #

    def register_controller(
        self,
        name: str,
        controller: ControllerType,
        *,
        metadata: Optional[Dict[str, Any]] = None,
    ) -> None:
        """Register (or replace) a controller instance."""
        self.controllers[name] = controller
        self._pending.setdefault(name, deque())
        if isinstance(metadata, dict):
            payload = metadata.copy()
        else:
            payload = {}
        payload.setdefault("name", name)
        self.controller_metadata[name] = payload
        self.logger.debug("Registered controller '%s'", name)

    def unregister_controller(self, name: str) -> None:
        """Remove a controller from orchestration (noop if unknown)."""
        self.controllers.pop(name, None)
        self._pending.pop(name, None)
        self.controller_metadata.pop(name, None)
        self.logger.debug("Unregistered controller '%s'", name)

    def get_controller_status(self, name: str) -> Dict[str, Any]:
        """Return the latest status dictionary reported by the controller."""
        controller = self._get_controller(name)
        try:
            status = controller.get_status()
            return status if isinstance(status, dict) else {}
        except Exception as exc:  # noqa: BLE001 - propagate minimal info
            self.logger.warning(
                "Failed to fetch status from controller '%s': %s", name, exc
            )
            return {}

    def get_pending_command_count(self, name: Optional[str] = None) -> int:
        """Return the number of queued commands (for one or all controllers)."""
        if name is not None:
            return len(self._pending.get(name, ()))
        return sum(len(queue) for queue in self._pending.values())

    def get_pending_commands(self, name: str) -> List[Tuple[str, bool]]:
        """Return a copy of queued commands for the requested controller."""
        return list(self._pending.get(name, ()))

    # ------------------------------------------------------------------ #
    # Command dispatch / automation awareness
    # ------------------------------------------------------------------ #

    def set_prompt_debug(
        self,
        enabled: bool,
        *,
        preview_chars: int = 200,
    ) -> None:
        """Enable or disable prompt debugging output."""
        self._debug_prompts = enabled
        if preview_chars is not None and preview_chars >= 0:
            self._debug_prompt_chars = int(preview_chars)

    def dispatch_command(
        self,
        controller_name: str,
        command: str,
        *,
        submit: bool = True,
    ) -> Dict[str, Any]:
        """
        Dispatch a command to the requested controller, respecting automation pauses.

        Returns:
            A dictionary describing the result. Keys include:
                - dispatched (bool): True if the controller executed the command.
                - queued (bool): True if the command was queued instead of sent.
                - queue_source (str): "orchestrator", "controller", or None.
                - reason (str|None): Pause reason reported by the controller.
                - manual_clients (list): Attached clients (if reported).
                - pending (int): Commands waiting in the orchestrator queue.
                - controller_pending (int|None): Pending count reported by controller.
        """
        if self._debug_prompts:
            preview_len = self._debug_prompt_chars or 0
            preview = command[:preview_len] if command else ""
            self.logger.info(
                "[prompt-debug] %s len=%d preview=%r",
                controller_name,
                len(command or ""),
                preview,
            )

        controller = self._get_controller(controller_name)
        status = self.get_controller_status(controller_name)
        paused, reason, manual_clients, controller_pending = self._extract_automation(status)

        if paused:
            summary = self._queue_command(
                controller_name,
                command,
                submit,
                reason=reason,
                manual_clients=manual_clients,
                controller_pending=controller_pending,
            )
            summary["queue_source"] = "orchestrator"
            return summary

        result = controller.send_command(command, submit=submit)
        if result:
            return {
                "dispatched": True,
                "queued": False,
                "queue_source": None,
                "reason": reason,
                "manual_clients": manual_clients,
                "pending": len(self._pending.get(controller_name, ())),
                "controller_pending": controller_pending,
            }

        # Command was not dispatched (e.g., automation paused between poll & send)
        status_after = self.get_controller_status(controller_name)
        paused_after, reason_after, manual_after, controller_pending_after = (
            self._extract_automation(status_after)
        )
        if paused_after:
            self.logger.info(
                "Controller '%s' paused during dispatch; relying on controller queue",
                controller_name,
            )
            return {
                "dispatched": False,
                "queued": True,
                "queue_source": "controller",
                "reason": reason_after,
                "manual_clients": manual_after,
                "pending": len(self._pending.get(controller_name, ())),
                "controller_pending": controller_pending_after,
            }

        return {
            "dispatched": False,
            "queued": False,
            "queue_source": None,
            "reason": reason_after,
            "manual_clients": manual_after,
            "pending": len(self._pending.get(controller_name, ())),
            "controller_pending": controller_pending_after,
        }

    # ------------------------------------------------------------------ #
    # Pending queue management
    # ------------------------------------------------------------------ #

    def process_pending(self, controller_name: str) -> Dict[str, Any]:
        """
        Attempt to flush queued commands for the specified controller.

        Returns:
            Dict describing the flush results:
                - flushed (int): Number of orchestrator-queued commands executed.
                - remaining (int): Commands still queued.
                - paused (bool): Whether automation remains paused.
                - reason (str|None): Pause reason, if paused.
        """
        controller = self._get_controller(controller_name)
        queue = self._pending.get(controller_name)
        if not queue:
            return {"flushed": 0, "remaining": 0, "paused": False, "reason": None}

        status = self.get_controller_status(controller_name)
        paused, reason, manual_clients, _ = self._extract_automation(status)

        if paused:
            self.logger.debug(
                "Controller '%s' still paused (%s); skipping flush",
                controller_name,
                reason or "unknown",
            )
            return {
                "flushed": 0,
                "remaining": len(queue),
                "paused": True,
                "reason": reason,
                "manual_clients": manual_clients,
            }

        flushed = 0
        while queue:
            command, submit = queue[0]
            result = controller.send_command(command, submit=submit)
            if not result:
                # Controller paused again or hit an error; stop flushing
                break
            queue.popleft()
            flushed += 1

        return {
            "flushed": flushed,
            "remaining": len(queue),
            "paused": False,
            "reason": None,
        }

    def process_all_pending(self) -> Dict[str, Dict[str, Any]]:
        """Flush queued commands for every controller and return per-controller summaries."""
        return {
            name: self.process_pending(name)
            for name in self.controllers.keys()
        }

    def tick(self) -> Dict[str, Dict[str, Any]]:
        """
        Convenience helper for external loops: process pending commands once.

        Returns the same payload as process_all_pending().
        """
        return self.process_all_pending()

    # ------------------------------------------------------------------ #
    # Higher-level helpers
    # ------------------------------------------------------------------ #

    def start_discussion(
        self,
        topic: str,
        *,
        participants: Optional[Sequence[str]] = None,
        max_turns: int = 10,
        context_manager: Any | None = None,
        message_router: Any | None = None,
        include_history: bool = True,
    ) -> Dict[str, Any]:
        """
        Run a facilitated discussion between registered controllers.

        Args:
            topic: Subject for the conversation.
            participants: Optional ordered list of controller names to include.
                Defaults to all registered controllers.
            max_turns: Maximum number of turns before stopping.
            context_manager: Optional context manager instance. If omitted a new
                ContextManager is created.
            message_router: Optional message router instance. A default router
                is created when not provided.

        Returns:
            Dict containing:
                - conversation: List of turn dictionaries.
                - manager: ConversationManager used for the exchange.
                - context_manager: Context manager instance (created or provided).
                - message_router: Message router instance (created or provided).
        """
        from .conversation_manager import ConversationManager  # local import to avoid cycles
        from .context_manager import ContextManager
        from .message_router import MessageRouter

        participant_list = list(participants or self.controllers.keys())
        if not participant_list:
            raise ValueError("start_discussion requires at least one participant")

        participant_metadata = {
            name: self.controller_metadata.get(name, {}).copy()
            for name in participant_list
            if name in self.controller_metadata
        }

        if context_manager is None:
            ctx_manager = ContextManager(participant_metadata=participant_metadata or None)
        else:
            ctx_manager = context_manager
            registrar = getattr(ctx_manager, "register_participant", None)
            if callable(registrar):
                for name, meta in participant_metadata.items():
                    try:
                        registrar(name, meta)
                    except TypeError:
                        registrar(name)
                    except Exception as exc:  # noqa: BLE001
                        self.logger.debug("Context manager metadata registration failed for '%s': %s", name, exc)

        msg_router = message_router or MessageRouter(participant_list, context_manager=ctx_manager)

        manager = ConversationManager(
            self,
            participant_list,
            context_manager=ctx_manager,
            message_router=msg_router,
            participant_metadata=participant_metadata or None,
            include_history=include_history,
        )
        conversation = manager.facilitate_discussion(topic, max_turns=max_turns)
        return {
            "conversation": conversation,
            "manager": manager,
            "context_manager": ctx_manager,
            "message_router": msg_router,
        }

    # ------------------------------------------------------------------ #
    # Internal helpers
    # ------------------------------------------------------------------ #

    def _get_controller(self, name: str) -> ControllerType:
        if name not in self.controllers:
            raise KeyError(f"Unknown controller '{name}'")
        return self.controllers[name]

    def _queue_command(
        self,
        controller_name: str,
        command: str,
        submit: bool,
        *,
        reason: Optional[str],
        manual_clients: Iterable[str],
        controller_pending: Optional[int],
    ) -> Dict[str, Any]:
        queue = self._pending.setdefault(controller_name, deque())
        queue.append((command, submit))
        self.logger.info(
            "Controller '%s' paused (%s); queued command. pending=%d controller_pending=%s",
            controller_name,
            reason or "unknown",
            len(queue),
            controller_pending,
        )
        return {
            "dispatched": False,
            "queued": True,
            "queue_source": "orchestrator",
            "reason": reason,
            "manual_clients": list(manual_clients),
            "pending": len(queue),
            "controller_pending": controller_pending,
        }

    @staticmethod
    def _extract_automation(status: Dict[str, Any]) -> Tuple[bool, Optional[str], List[str], Optional[int]]:
        """Return (paused, reason, manual_clients, controller_pending) tuple."""
        automation = status.get("automation") if isinstance(status, dict) else None
        if not isinstance(automation, dict):
            return False, None, [], None

        paused = bool(automation.get("paused"))
        reason = automation.get("reason")
        manual_clients_raw = automation.get("manual_clients") or []
        manual_clients = list(manual_clients_raw) if isinstance(manual_clients_raw, Iterable) else []
        controller_pending = automation.get("pending_commands")
        if isinstance(controller_pending, bool):
            controller_pending = int(controller_pending)  # guard misuse
        elif not isinstance(controller_pending, int):
            controller_pending = None

        return paused, reason, manual_clients, controller_pending
</file>

<file path="examples/README.md">
# Orchestrated Discussion Example

`run_orchestrated_discussion.py` wires the `DevelopmentTeamOrchestrator`,
`ConversationManager`, `ContextManager`, and `MessageRouter` together so Claude
and Gemini can exchange updates automatically.

## Prerequisites

- `tmux` installed and on `$PATH`
- Sandboxed wrapper scripts `safe_claude`, `safe_gemini`, and `safe_codex` available on `$PATH`
- (Optional) Existing tmux sessions named `claude` and `gemini`

If the sessions are not running you can allow the script to create them by
passing `--auto-start`.

## Usage

```bash
python examples/run_orchestrated_discussion.py "Decide next sprint focus" --auto-start
```

Important flags:

- `--claude-session` / `--gemini-session`: tmux session names (defaults: `claude`, `gemini`)
- `--claude-executable` / `--gemini-executable`: CLI command strings sourced from `config.yaml` (defaults typically `safe_claude --dangerously-skip-permissions`, `safe_gemini --yolo`)
- `--claude-bootstrap` / `--gemini-bootstrap`: Optional shell commands that run before the executable (useful for piping auto-confirm input, e.g., `echo "2"`)
- `--claude-startup-timeout` / `--gemini-startup-timeout`: Seconds to allow each CLI to become ready (defaults: 10s for Claude, 20s for Gemini)
- `--claude-init-wait` / `--gemini-init-wait`: Extra delay after spawning before the first input (useful for slower startups)
- `--claude-cwd` / `--gemini-cwd`: Working directories for the sessions
- `--max-turns`: Maximum number of turns the discussion should run (default: 6)
- `--log-file`: Write the transcript and context summary to the provided file (or directory)

## Manual Workflow

1. Start or verify Claude and Gemini tmux sessions:
   ```bash
   tmux new -s claude
   safe_claude --dangerously-skip-permissions
   tmux new -s gemini
   safe_gemini --yolo
   ```
2. Run the orchestrated discussion:
   ```bash
    python examples/run_orchestrated_discussion.py "Coordinate release plan"
   ```
3. Observe the transcript and context summary printed to stdout.

During a session you can still attach manually (`tmux attach -t claude`)—the
orchestrator will detect pauses, queue outgoing prompts, and resume once you
detach.
</file>

<file path="src/utils/output_parser.py">
"""
Output Parser

Utilities for parsing and cleaning Claude Code output captured from tmux.
"""

import re
from typing import List, Optional, Dict


class OutputParser:
    """Parse and clean Claude Code output."""

    # ANSI escape code pattern
    ANSI_ESCAPE = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
    AGENT_COMMAND_PATTERN = re.compile(r'^(?:>|\$)?\s*/agents\b', re.IGNORECASE)

    # Unicode box drawing characters used by Claude Code
    BOX_CHARS = ['─', '│', '┌', '┐', '└', '┘', '├', '┤', '┬', '┴', '┼', '═', '║', '╔', '╗', '╚', '╝', '╠', '╣', '╦', '╩', '╬']

    # Additional UI noise patterns
    TOOL_PREFIX_PATTERN = re.compile(r'^\s*⎿\s*')
    COLLAPSED_LINE_PATTERN = re.compile(r'^\s*… \+\d+\s+lines(?:\s*\([^)]+\))?$', re.IGNORECASE)
    SHORTCUT_HINT_PATTERN = re.compile(r'\((?:ctrl|shift|esc)[^)]*\)', re.IGNORECASE)
    PERMISSION_PROMPT_PATTERN = re.compile(r'^\s*⏵⏵')
    STATUS_DOT_PATTERN = re.compile(r'^\s*·\s+')
    STATUS_STAR_PATTERN = re.compile(r'^\s*\*\s+.*esc to interrupt', re.IGNORECASE)
    GEMINI_BOX_BORDER_PATTERN = re.compile(r'^\s*[╭╰]')
    GEMINI_EMPTY_PIPE_PATTERN = re.compile(r'^\s*│\s*$')
    PROMPT_PASTED_PATTERN = re.compile(r'^>\s*\[Pasted text.*\]$', re.IGNORECASE)
    GEMINI_FOOTER_PATTERN = re.compile(r'.*\b(?:gemini|claude)-[\w\.\-]+\b.*', re.IGNORECASE)

    DROP_IF_CONTAINS = (
        'YOLO mode',
        'Type your message',
        'Tips for getting started',
        'Using:',
        'no sandbox',
        'context left',
        'screen reader-friendly view',
        'thinking off',
        'thinking on',
    )

    # Claude Code UI patterns
    PROMPT_PATTERN = r'^>\s'
    SEPARATOR_PATTERN = r'^─+$'
    STATUS_LINE_PATTERN = r'\? for shortcuts.*Thinking (on|off)'
    HEADER_PATTERN = r'▐▛███▜▌.*Claude Code'

    def __init__(self):
        """Initialize OutputParser."""
        pass

    def strip_ansi(self, text: str) -> str:
        """
        Remove ANSI escape codes from text.

        Args:
            text: Input text with ANSI codes

        Returns:
            Text without ANSI codes
        """
        return self.ANSI_ESCAPE.sub('', text)

    PROMPT_MARKERS = ('>', '›')
    RESPONSE_MARKERS = ('●', '✦', '•')

    def clean_output(self, text: str, strip_ui: bool = True, strip_trailing_prompts: bool = False) -> str:
        """
        Clean Claude Code output by removing UI elements.

        Args:
            text: Raw output from tmux capture
            strip_ui: Whether to remove UI elements (header, separators, status)

        Returns:
            Cleaned output text
        """
        # Strip ANSI codes
        text = self.strip_ansi(text)

        if not strip_ui:
            return text

        lines = text.split('\n')
        cleaned_lines = []

        for line in lines:
            normalized = self._normalize_line(line)
            if normalized is not None:
                cleaned_lines.append(normalized)

        if strip_trailing_prompts:
            cleaned_lines = self._trim_trailing_prompts(cleaned_lines)

        return '\n'.join(cleaned_lines).rstrip('\n')

    def _normalize_line(self, line: str) -> Optional[str]:
        """Normalize or drop a single line of CLI output."""
        line = line.replace('\u00a0', ' ')
        stripped = line.strip()

        if not stripped:
            return None

        if stripped == '>':
            return None

        # Remove Gemini boxed prompt markers while preserving inner text
        if stripped.startswith('│'):
            inner = stripped.strip('│').strip()
            if not inner:
                return None
            line = inner
            stripped = inner

        # Skip header lines (Claude and Gemini art/logos)
        if any(token in stripped for token in ['▐▛███▜▌', '▝▜█████▛▘', '▘▘ ▝▝', '███']):
            return None

        # Skip broad separator or border lines
        if re.match(self.SEPARATOR_PATTERN, stripped):
            return None
        if self.GEMINI_BOX_BORDER_PATTERN.match(stripped):
            return None
        if self.GEMINI_EMPTY_PIPE_PATTERN.match(stripped):
            return None

        # Skip prompt-only placeholders and pasted text markers
        if re.match(self.PROMPT_PATTERN, stripped) and len(stripped) <= 2:
            return None
        if self.PROMPT_PASTED_PATTERN.match(stripped):
            return None

        # Skip known status/permission lines
        if re.search(self.STATUS_LINE_PATTERN, stripped):
            return None
        if self.PERMISSION_PROMPT_PATTERN.match(stripped):
            return None
        if self.COLLAPSED_LINE_PATTERN.match(stripped):
            return None
        if self.STATUS_DOT_PATTERN.match(stripped):
            return None
        if self.STATUS_STAR_PATTERN.match(stripped):
            return None
        if 'esc to interrupt' in stripped.lower():
            return None

        # Drop lines with configured substrings or footer patterns
        lowered = stripped.lower()
        if any(token.lower() in lowered for token in self.DROP_IF_CONTAINS):
            return None
        if self.GEMINI_FOOTER_PATTERN.match(stripped):
            return None

        # Remove tool prefix indicators but keep the payload
        if stripped.startswith('⎿'):
            stripped = self.TOOL_PREFIX_PATTERN.sub('', stripped).strip()
            if not stripped:
                return None
            line = stripped

        # Remove inline shortcut/tool hints
        line = self.SHORTCUT_HINT_PATTERN.sub('', line).rstrip()
        stripped = line.strip()
        if not stripped:
            return None

        # Skip agent invocation commands (e.g., > /agents codex "prompt")
        if self.AGENT_COMMAND_PATTERN.match(stripped):
            return None

        return line

    def extract_responses(self, text: str) -> List[Dict[str, str]]:
        """
        Extract question/response pairs from AI CLI output.

        Supports both Claude Code (●) and Gemini CLI (✦) response markers.

        Args:
            text: Raw or cleaned output

        Returns:
            List of dictionaries with 'question' and 'response' keys
        """
        text = self.strip_ansi(text)
        lines = text.split('\n')

        pairs = []
        current_question = None
        current_response = []
        in_response = False

        for line in lines:
            stripped = line.strip()

            # Skip box drawing characters
            if stripped.startswith('╭') or stripped.startswith('╰'):
                # Just skip box boundaries - don't save pairs here
                # Pairs will be saved when we encounter the next question
                continue

            # Detect boxed question (Gemini format): │  > Question  │
            if stripped.startswith('│') and '>' in stripped:
                # Extract question from box first
                question_text = stripped.replace('│', '').replace('>', '').strip()

                # Skip prompt line or empty questions
                if not question_text or len(question_text) <= 2 or 'Type your message' in question_text:
                    continue

                # Save previous pair if exists
                if current_question and current_response:
                    pairs.append({
                        'question': current_question,
                        'response': '\n'.join(current_response).strip()
                    })

                # Start new question
                current_question = question_text
                current_response = []
                in_response = False
                continue

            # Detect plain question (Claude format): > Question
            prompt_text = self._extract_prompt_text(stripped)
            if prompt_text and '│' not in line:
                # Save previous pair if exists
                if current_question and current_response:
                    pairs.append({
                        'question': current_question,
                        'response': '\n'.join(current_response).strip()
                    })

                # Start new question
                current_question = prompt_text
                current_response = []
                in_response = False
                continue

            # Detect response start (● for Claude or ✦ for Gemini)
            if stripped.startswith(tuple(self.RESPONSE_MARKERS)):
                in_response = True
                # Add response text (without marker)
                response_text = stripped[1:].strip()
                if response_text:
                    current_response.append(response_text)
                continue

            # Skip UI elements
            if (not stripped or
                re.match(self.SEPARATOR_PATTERN, stripped) or
                re.search(self.STATUS_LINE_PATTERN, stripped) or
                any(char in line for char in ['▐▛███▜▌', '▝▜█████▛▘'])):
                # End of response
                if in_response:
                    in_response = False
                continue

            # Collect response continuation lines
            if in_response and stripped:
                current_response.append(stripped)

        # Save last pair if exists
        if current_question and current_response:
            pairs.append({
                'question': current_question,
                'response': '\n'.join(current_response).strip()
            })

        return pairs

    def _extract_prompt_text(self, stripped_line: str) -> Optional[str]:
        """Return prompt text without leading marker."""
        for marker in self.PROMPT_MARKERS:
            if stripped_line.startswith(marker):
                prompt_text = stripped_line[len(marker):].strip()
                if prompt_text:
                    return prompt_text
        return None

    def _trim_trailing_prompts(self, lines: List[str]) -> List[str]:
        """Remove trailing prompt lines if a response is present."""
        if not lines:
            return lines

        if not any(self._line_has_response_marker(line) for line in lines):
            return lines

        trimmed = list(lines)
        while trimmed and self._is_prompt_line(trimmed[-1]):
            trimmed.pop()
        return trimmed

    def _is_prompt_line(self, line: str) -> bool:
        """Return True if the line looks like a CLI prompt (>, ›, etc)."""
        stripped = line.strip()
        if not stripped:
            return False
        return any(
            stripped.startswith(marker) and stripped[len(marker):].strip()
            for marker in self.PROMPT_MARKERS
        )

    def _line_has_response_marker(self, line: str) -> bool:
        stripped = line.strip()
        if not stripped:
            return False
        return stripped[0] in self.RESPONSE_MARKERS and stripped[1:].strip()

    def get_last_response(self, text: str) -> Optional[str]:
        """
        Extract just the last response from output.

        Args:
            text: Raw or cleaned output

        Returns:
            Last response text or None
        """
        pairs = self.extract_responses(text)
        if pairs:
            return pairs[-1]['response']
        return None

    def get_last_question(self, text: str) -> Optional[str]:
        """
        Extract just the last question from output.

        Args:
            text: Raw or cleaned output

        Returns:
            Last question text or None
        """
        pairs = self.extract_responses(text)
        if pairs:
            return pairs[-1]['question']
        return None

    def is_error_response(self, text: str) -> bool:
        """
        Detect if response contains an error.

        Args:
            text: Response text

        Returns:
            True if error detected, False otherwise
        """
        error_patterns = [
            r'error',
            r'failed',
            r'cannot',
            r'unable to',
            r'not found',
            r'invalid',
        ]

        text_lower = text.lower()
        return any(re.search(pattern, text_lower) for pattern in error_patterns)

    def format_conversation(self, text: str) -> str:
        """
        Format conversation in a readable way.

        Args:
            text: Raw output

        Returns:
            Formatted conversation
        """
        pairs = self.extract_responses(text)

        formatted = []
        for i, pair in enumerate(pairs, 1):
            formatted.append(f"Q{i}: {pair['question']}")
            formatted.append(f"A{i}: {pair['response']}")
            formatted.append("")  # Blank line between pairs

        return '\n'.join(formatted).strip()
</file>

<file path="src/orchestrator/conversation_manager.py">
"""
Conversation management layer that sits above the orchestrator.

The conversation manager owns turn-taking logic between controllers, captures
lightweight transcripts, and detects simple consensus/conflict signals so
higher-level workflows can decide when to stop or escalate a dialogue.
"""

from __future__ import annotations

import re
from collections import deque
from typing import Any, Deque, Dict, List, Optional, Sequence, Set, Tuple

from ..utils.logger import get_logger
from ..utils.output_parser import OutputParser
from ..utils.config_loader import get_config


class ConversationManager:
    """
    Coordinate turn-taking between registered controllers via the orchestrator.

    The manager keeps a rolling history of the conversation, selects the next
    speaker (round-robin by default), and dispatches prompts through the
    DevelopmentTeamOrchestrator. Responses are captured when controllers expose
    a ``get_last_output`` helper – fallbacks keep the scaffold safe even if the
    integration is not yet complete.
    """

    def __init__(
        self,
        orchestrator,
        participants: Sequence[str],
        *,
        context_manager: Any | None = None,
        message_router: Any | None = None,
        participant_metadata: Optional[Dict[str, Dict[str, Any]]] = None,
        max_history: int = 200,
        include_history: bool = True,
    ) -> None:
        if not participants:
            raise ValueError("ConversationManager requires at least one participant")

        self.logger = get_logger("orchestrator.conversation")
        self.orchestrator = orchestrator
        self.participants: List[str] = list(participants)
        self.context_manager = context_manager
        self.message_router = message_router
        metadata_source = participant_metadata or {}
        self.participant_metadata: Dict[str, Dict[str, Any]] = {}
        self._max_history = max(1, int(max_history))
        self._include_history = bool(include_history)
        self._turn_counter: int = 0
        self.history: Deque[Dict[str, Any]] = deque(maxlen=self._max_history)
        self._output_parsers: Dict[str, OutputParser] = {}
        self._conflict_code_pattern = re.compile(r"```.*?```", re.DOTALL)
        self._conflict_inline_code_pattern = re.compile(r"`[^`]*`")
        self._conflict_quoted_pattern = re.compile(r"\"[^\"]*\"|'[^']*'")
        tmux_cfg = get_config().get_section("tmux") or {}
        self._capture_tail_limit: int = int(tmux_cfg.get("capture_lines", 500) or 500)
        self._fallback_notices: Set[str] = set()

        if self.message_router is not None:
            for name in self.participants:
                register = getattr(self.message_router, "register_participant", None)
                if callable(register):
                    try:
                        register(name)
                    except Exception as exc:  # noqa: BLE001
                        self.logger.debug("Message router registration failed for '%s': %s", name, exc)

        # Prepare metadata for participants and forward to context manager when available.
        for name in self.participants:
            merged: Dict[str, Any] = {"name": name, "type": "cli"}
            candidate = metadata_source.get(name)
            if isinstance(candidate, dict):
                merged.update(candidate)
            merged.setdefault("type", "cli")
            self.participant_metadata[name] = merged

            if self.context_manager is not None:
                registrar = getattr(self.context_manager, "register_participant", None)
                if callable(registrar):
                    try:
                        registrar(name, merged)
                    except TypeError:
                        registrar(name)
                    except Exception as exc:  # noqa: BLE001
                        self.logger.debug("Context manager registration failed for '%s': %s", name, exc)

    # ------------------------------------------------------------------ #
    # Public API
    # ------------------------------------------------------------------ #

    def facilitate_discussion(self, topic: str, max_turns: int = 10) -> List[Dict[str, Any]]:
        """
        Run a short turn-based discussion around ``topic``.

        Returns:
            Ordered list of turn dictionaries. Each entry includes:
                - turn (int): Absolute turn index.
                - speaker (str): Controller name.
                - prompt (str): Command submitted to the controller.
                - dispatch (dict): Orchestrator dispatch summary.
                - response (str|None): Captured controller output, when available.
        """
        conversation: List[Dict[str, Any]] = []
        for _ in range(max_turns):
            speaker = self.determine_next_speaker(conversation)
            if speaker is None:
                self.logger.debug("No eligible speaker; stopping discussion on '%s'", topic)
                break

            prompt = self._build_prompt(speaker, topic, conversation)
            pre_snapshot = self._capture_snapshot(speaker)
            dispatch_summary = self.orchestrator.dispatch_command(speaker, prompt)
            is_queued = bool(dispatch_summary.get("queued"))
            response = None if is_queued else self._read_last_output(speaker, pre_snapshot)

            turn_record = {
                "turn": self._turn_counter,
                "speaker": speaker,
                "topic": topic,
                "prompt": prompt,
                "dispatch": dispatch_summary,
                "response": response,
            }
            conversation.append(turn_record)
            self._turn_counter += 1

            self._store_turn(turn_record)

            is_queued = bool(dispatch_summary.get("queued"))
            consensus = self.detect_consensus(conversation)
            conflict, reason = self.detect_conflict(conversation)

            metadata = turn_record.setdefault("metadata", {})
            if is_queued:
                metadata["queued"] = True
            if consensus:
                metadata["consensus"] = True
            if conflict:
                metadata["conflict"] = True
                if reason:
                    metadata["conflict_reason"] = reason

            self._record_with_context_manager(turn_record)
            self._route_message(turn_record, topic, dispatched=not is_queued)

            # Give the orchestrator a chance to drain any newly runnable work.
            try:
                self.orchestrator.tick()
            except AttributeError:
                self.logger.debug("Orchestrator tick unavailable; skipping background flush")

            if is_queued:
                self.logger.info(
                    "Turn %s queued because controller '%s' is paused; awaiting resume",
                    turn_record["turn"],
                    speaker,
                )
                break

            if consensus:
                self.logger.info("Consensus detected after turn %s on '%s'", turn_record["turn"], topic)
                self._notify_context_manager("consensus", turn_record)
                break

            if conflict:
                self.logger.warning(
                    "Conflict detected after turn %s on '%s': %s",
                    turn_record["turn"],
                    topic,
                    reason,
                )
                self._notify_context_manager("conflict", turn_record, reason=reason)
                break

        return conversation

    def determine_next_speaker(self, context: Sequence[Dict[str, Any]]) -> Optional[str]:
        """
        Pick the next controller to speak (round-robin by default).

        Context should be the running conversation log for the current session.
        If automation removed a controller mid-discussion, the manager skips it
        until it re-registers with the orchestrator.
        """
        active_participants = [
            name for name in self.participants if name in getattr(self.orchestrator, "controllers", {})
        ]
        if not active_participants:
            return None

        if not context:
            # Resume from the participant after the last global speaker, unless the last turn was queued.
            if self.history:
                last_turn = self.history[-1]
                last_speaker = last_turn.get("speaker")
                if last_speaker in active_participants:
                    last_metadata = last_turn.get("metadata") or {}
                    if last_metadata.get("queued"):
                        return last_speaker
                    idx = active_participants.index(last_speaker)
                    return active_participants[(idx + 1) % len(active_participants)]
            return active_participants[0]

        last_turn = context[-1]
        last_speaker = last_turn.get("speaker")
        last_metadata = last_turn.get("metadata") or {}
        if last_metadata.get("queued") and isinstance(last_speaker, str):
            return last_speaker if last_speaker in active_participants else active_participants[0]

        if last_speaker not in active_participants:
            return active_participants[0]

        idx = active_participants.index(last_speaker)
        return active_participants[(idx + 1) % len(active_participants)]

    def detect_consensus(self, conversation: Sequence[Dict[str, Any]]) -> bool:
        """
        Return True when the latest exchange signals consensus.

        Heuristics (subject to refinement):
            - Response text includes 'consensus' or 'agreement reached'.
            - Metadata flag ``consensus`` set truthy on the most recent turn.
        """
        if not conversation:
            return False

        latest = conversation[-1]
        metadata = latest.get("metadata", {})
        if metadata and metadata.get("consensus"):
            return True

        response = (latest.get("response") or "").lower()
        keywords = ("consensus", "agreement reached", "we agree", "aligned")
        return any(keyword in response for keyword in keywords)

    def detect_conflict(self, conversation: Sequence[Dict[str, Any]]) -> Tuple[bool, str]:
        """
        Return (conflict_detected, reason).

        Conflict triggers when:
            - The most recent message contains negative keywords (disagree, block).
            - Two consecutive turns expose diverging stances in their metadata.
        """
        if len(conversation) < 2:
            return False, ""

        latest = conversation[-1]
        previous = conversation[-2]

        response_normalized = self._normalize_for_conflict_text(latest.get("response") or "")
        conflict_keywords = ("disagree", "blocker", "conflict", "reject")
        conflict_phrases = ("cannot agree", "cannot accept", "cannot support", "cannot proceed", "cannot endorse")

        for keyword in conflict_keywords:
            if keyword in response_normalized:
                return True, f"Keyword '{keyword}' indicates disagreement"

        for phrase in conflict_phrases:
            if phrase in response_normalized:
                return True, f"Phrase '{phrase}' indicates disagreement"

        stance_latest = self._extract_stance(latest)
        stance_previous = self._extract_stance(previous)
        if stance_latest and stance_previous and stance_latest != stance_previous:
            return True, f"Stance mismatch: {stance_previous!r} vs {stance_latest!r}"

        return False, ""

    # ------------------------------------------------------------------ #
    # Internal helpers
    # ------------------------------------------------------------------ #

    def _build_prompt(
        self,
        speaker: str,
        topic: str,
        conversation: Sequence[Dict[str, Any]],
    ) -> str:
        """
        Construct a lightweight prompt for the next speaker.

        If a context manager exposes ``build_prompt`` the conversation manager
        defers to it, otherwise a pragmatic default string is used.
        """
        if self.context_manager is not None:
            builder = getattr(self.context_manager, "build_prompt", None)
            if callable(builder):
                try:
                    return builder(speaker, topic, include_history=self._include_history)
                except Exception as exc:  # noqa: BLE001
                    self.logger.warning("Context builder failed for '%s': %s", speaker, exc)

        turn_number = len(conversation)
        if not self._include_history:
            prompt = (
                f"[Turn {turn_number}] {speaker}, acknowledge the request '{topic}' "
                "and briefly confirm you can see it."
            )
        else:
            prompt = (
                f"[Turn {turn_number}] {speaker}, share your perspective on '{topic}'. "
                "Highlight progress, concerns, or next actions."
            )

        if self.message_router is not None:
            self._ensure_router_registration(speaker)
            formatter = getattr(self.message_router, "prepare_prompt", None)
            if callable(formatter):
                try:
                    prompt = formatter(
                        recipient=speaker,
                        topic=topic,
                        base_prompt=prompt,
                        include_history=self._include_history,
                    )
                except Exception as exc:  # noqa: BLE001
                    self.logger.debug("Message router prompt preparation failed: %s", exc)

        return prompt

    def _read_last_output(
        self,
        controller_name: str,
        pre_snapshot: Optional[List[str]],
    ) -> Optional[str]:
        controller = getattr(self.orchestrator, "controllers", {}).get(controller_name)
        if controller is None:
            return None

        self._wait_for_controller(controller_name, controller)

        capture = getattr(controller, "capture_scrollback", None)
        if callable(capture):
            try:
                post_snapshot = capture().splitlines()
            except Exception:  # noqa: BLE001
                self.logger.debug(
                    "Controller '%s' capture_scrollback failed; falling back to legacy output cache",
                    controller_name,
                    exc_info=True,
                )
            else:
                parser = self._output_parsers.setdefault(controller_name, OutputParser())
                if pre_snapshot is not None:
                    delta = self._compute_delta(pre_snapshot, post_snapshot, self._capture_tail_limit)
                else:
                    delta = post_snapshot[-self._capture_tail_limit :]
                if delta:
                    raw_text = "\n".join(delta)
                    cleaned = parser.clean_output(raw_text, strip_trailing_prompts=True)
                    return cleaned or None
                return None

        reader = getattr(controller, "get_last_output", None)
        if callable(reader):
            if controller_name not in self._fallback_notices:
                self.logger.warning(
                    "Controller '%s' lacks scrollback capture support; falling back to get_last_output().",
                    controller_name,
                )
                self._fallback_notices.add(controller_name)
            try:
                raw_output = reader()
            except Exception:  # noqa: BLE001
                self.logger.debug(
                    "Controller '%s' get_last_output fallback failed",
                    controller_name,
                    exc_info=True,
                )
                return None
            if not raw_output:
                return None
            parser = self._output_parsers.setdefault(controller_name, OutputParser())
            cleaned = parser.clean_output(raw_output, strip_trailing_prompts=True)
            return cleaned or None

        if controller_name not in self._fallback_notices:
            self.logger.warning(
                "Controller '%s' exposes neither capture_scrollback nor get_last_output; no response captured.",
                controller_name,
            )
            self._fallback_notices.add(controller_name)
        return None

    def _capture_snapshot(self, controller_name: str) -> Optional[List[str]]:
        controller = getattr(self.orchestrator, "controllers", {}).get(controller_name)
        if controller is None:
            return None

        capture = getattr(controller, "capture_scrollback", None)
        if not callable(capture):
            return None

        try:
            snapshot = capture()
        except Exception:  # noqa: BLE001
            self.logger.debug(
                "Controller '%s' pre-dispatch capture failed",
                controller_name,
                exc_info=True,
            )
            return None
        return snapshot.splitlines()

    def _wait_for_controller(self, controller_name: str, controller: Any) -> None:
        waiter = getattr(controller, "wait_for_ready", None)
        if callable(waiter):
            try:
                waiter()
            except Exception:  # noqa: BLE001
                self.logger.debug(
                    "Controller '%s' wait_for_ready failed",
                    controller_name,
                    exc_info=True,
                )

    @staticmethod
    def _compute_delta(
        previous: List[str],
        current: List[str],
        tail_limit: Optional[int],
    ) -> List[str]:
        if previous and len(current) >= len(previous):
            limit = min(len(previous), len(current))
            prefix = 0
            while prefix < limit and previous[prefix] == current[prefix]:
                prefix += 1
            delta = current[prefix:]
        else:
            delta = current

        if tail_limit is not None and len(delta) > tail_limit:
            delta = delta[-tail_limit:]
        return delta

    def _store_turn(self, turn: Dict[str, Any]) -> None:
        """Persist the turn in the rolling history buffer."""
        self.history.append(turn)

    def _record_with_context_manager(self, turn: Dict[str, Any]) -> None:
        """Forward the turn to the context manager if it exposes a compatible hook."""
        if self.context_manager is None:
            return

        for attr in ("record_turn", "append_turn", "save_turn"):
            handler = getattr(self.context_manager, attr, None)
            if callable(handler):
                try:
                    handler(turn)
                except Exception as exc:  # noqa: BLE001
                    self.logger.debug("Context manager hook '%s' failed: %s", attr, exc)
                return

    def _route_message(self, turn: Dict[str, Any], topic: str, *, dispatched: bool) -> None:
        if self.message_router is None or not dispatched:
            return

        deliver = getattr(self.message_router, "deliver", None)
        if not callable(deliver):
            return

        sender = turn.get("speaker")
        if not isinstance(sender, str):
            return

        response = turn.get("response") or ""
        metadata = turn.get("metadata")
        try:
            deliver(
                sender=sender,
                message=response,
                topic=topic,
                turn=turn.get("turn", 0),
                metadata=metadata if isinstance(metadata, dict) else None,
            )
        except Exception:  # noqa: BLE001
            self.logger.debug("Message routing failed for sender '%s'", sender, exc_info=True)

    def _normalize_for_conflict_text(self, text: str) -> str:
        if not text:
            return ""

        scrubbed = self._conflict_code_pattern.sub(" ", text)
        scrubbed = self._conflict_inline_code_pattern.sub(" ", scrubbed)
        scrubbed = self._conflict_quoted_pattern.sub(" ", scrubbed)
        return scrubbed.lower()

    def _ensure_router_registration(self, participant: str) -> None:
        if self.message_router is None:
            return

        register = getattr(self.message_router, "register_participant", None)
        if callable(register):
            try:
                register(participant)
            except Exception:  # noqa: BLE001
                self.logger.debug("Message router register failed for '%s'", participant, exc_info=True)

    def _notify_context_manager(self, event: str, turn: Dict[str, Any], *, reason: Optional[str] = None) -> None:
        if self.context_manager is None:
            return

        callbacks = []
        if event == "consensus":
            callbacks = ["record_consensus", "note_consensus", "log_consensus"]
        elif event == "conflict":
            callbacks = ["record_conflict", "note_conflict", "log_conflict"]

        for attr in callbacks:
            handler = getattr(self.context_manager, attr, None)
            if callable(handler):
                try:
                    if event == "conflict":
                        handler(turn, reason or "")
                    else:
                        handler(turn)
                except Exception as exc:  # noqa: BLE001
                    self.logger.debug("Context manager event '%s' failed via '%s': %s", event, attr, exc)
                break

    @staticmethod
    def _extract_stance(turn: Dict[str, Any]) -> Optional[str]:
        """Best-effort extraction of a stance label from turn metadata."""
        metadata = turn.get("metadata") or {}
        if isinstance(metadata, dict):
            stance = metadata.get("stance")
            if isinstance(stance, str):
                return stance.lower()
        stance = turn.get("stance")
        if isinstance(stance, str):
            return stance.lower()
        return None


__all__ = ["ConversationManager"]
</file>

<file path="config.yaml">
# Multi-AI CLI Interaction POC Configuration
# Values based on empirical testing and observation
# Supports: Claude Code, Gemini CLI, Codex CLI, and Qwen CLI
#
# IMPORTANT: Startup timeouts should be generous to handle real-world variability:
# - Network latency for credential loading
# - System resource availability
# - First-time initialization vs. cached startup
# - Better to wait longer than fail prematurely

claude:
  # Startup timing
  startup_timeout: 20  # Total seconds to wait for Claude to start (allows for variability)
  trust_wait: 3        # Wait after confirming trust prompt
  init_wait: 3         # Wait after initialization
  pane_width: 200      # tmux pane width in columns
  pane_height: 50      # tmux pane height in rows

  # Response timing
  response_timeout: 500     # Max seconds to wait for command response
  ready_check_interval: 0.5  # Seconds between output stability checks
  ready_stable_checks: 3     # Consecutive stable checks required
  debug_wait_logging: false  # Emit detailed wait_for_ready diagnostics
  ready_stabilization_delay: 1.0  # Pause after ready indicator before sending first command

  # Command patterns and indicators
  prompt_pattern: ">"                    # Input prompt (not reliable for ready detection)
  ready_indicators:                      # Patterns indicating ready state
    - "────────────────────────"         # Separator line
    - "? for shortcuts"                  # Status line
  loading_indicators:
    - "⎿"
    - "Running…"
    - "Waiting…"
    - "Working…"
    - "(esc to interrupt"
    - "esc to interrupt"
  thinking_indicator: "Lollygagging…"    # Shows when processing
  submit_key: "Enter"                    # Key tmux should send to submit commands
  text_enter_delay: 0.6                  # Delay between text and Enter

  # Path to Claude Code executable
  executable: "claude"  # Wrapper enforces sandboxed execution
  executable_args:
    - "--dangerously-skip-permissions"

  # Response marker
  response_marker: "●"  # Bullet point for Claude responses
  pause_on_manual_clients: false  # Allow read-only tmux attach without pausing automation

gemini:
  # Startup timing
  startup_timeout: 60  # Total seconds to wait for Gemini to start (allows for variability, credential loading, etc.)
  init_wait: 3         # Wait after initialization
  pane_width: 220      # Gemini often renders wide tables; give extra width
  pane_height: 50

  # Response timing
  response_timeout: 75      # Max seconds to wait for command response
  tool_timeout: 15          # Additional time for tool execution
  ready_check_interval: 0.5  # Seconds between output stability checks
  ready_stable_checks: 6     # Consecutive stable checks required
  debug_wait_logging: false  # Emit detailed wait_for_ready diagnostics
  ready_stabilization_delay: 2.0  # Gemini tends to need longer to accept first input

  # Command patterns and indicators
  prompt_pattern: ">"                    # Input prompt
  ready_indicators:                      # Patterns indicating ready state
    - "Type your message or @path/to/file"
    - "Model:"                              # Transcript prefix
  loading_indicators:                    # Shows when processing
    - "⠦"
    - "⠼"
    - "⠧"
    - "⠏"
    - "⠋"
    - "⠙"
    - "⠹"
    - "⠸"
    - "Enhancing..."
    - "Counting electrons..."
  loading_indicator_settle_time: 3.0
  response_complete_markers:
    - "› "
    - "Type your message or @path/to/file"
  submit_key: "C-m"                      # Gemini prefers Ctrl-M when running in tmux
  text_enter_delay: 0.5                  # Give Gemini extra time to ingest pasted text
  post_text_delay: 0.5                  # Pause after pasting before submitting

  # Response marker
  response_marker: "✦"  # Sparkle for Gemini responses
  pause_on_manual_clients: false  # Allow read-only tmux attach without pausing automation

  # Tool support
  supports_tools: true   # Gemini can use external tools
  tool_marker: "✓"       # Checkmark for successful tool execution

  # Path to Gemini executable
  executable: "gemini"  # Wrapper enforces sandboxed execution
  executable_args:
    - "--yolo"

codex:
  startup_timeout: 20
  init_wait: 1
  pane_width: 200
  pane_height: 50
  # Codex can take a while on longer completions; align with Claude's higher ceiling.
  response_timeout: 500
  ready_check_interval: 0.5
  ready_stable_checks: 4
  debug_wait_logging: false  # Emit detailed wait_for_ready diagnostics
  ready_stabilization_delay: 1.0
  prompt_pattern: ">"
  ready_indicators:
    - "OpenAI Codex"
    - "100% context left"
    - "Write tests for"
  loading_indicators:
    - "esc to interrupt)"
  loading_indicator_settle_time: 2.5
  response_complete_markers:
    - "Worked for"
    - "› "
  submit_key: "Enter"
  text_enter_delay: 0.1
  response_marker: "▸"
  executable: "codex"
  executable_args: []
  pause_on_manual_clients: false

qwen:
  # Startup timing
  startup_timeout: 25
  init_wait: 2
  pane_width: 200
  pane_height: 50

  # Response timing
  response_timeout: 500
  ready_check_interval: 0.5
  ready_stable_checks: 4
  debug_wait_logging: false

  # Command patterns and indicators
  ready_indicators:
    - "▸ Type your message or @path/to/file"
    - "Type your message or @path/to/file"
  loading_indicators:
    - "(esc to cancel"
    - "(escape to cancel"
  loading_indicator_settle_time: 1.5
  ready_stabilization_delay: 0.75
  submit_key: "Enter"
  text_enter_delay: 0.6
  post_text_delay: 0.0
  strip_ansi_for_indicators: true

  # Response marker and executable
  response_marker: "▸"
  executable: "qwen"
  executable_args: []
  pause_on_manual_clients: false

tmux:
  # Session configuration
  claude_session: "claude"   # Default Claude session name
  gemini_session: "gemini"   # Default Gemini session name
  codex_session: "codex"     # Default Codex session name
  qwen_session: "qwen"       # Default Qwen session name
  default_pane_width: 200
  default_pane_height: 50

  # Output capture settings
  capture_lines: 500     # Default lines to capture from pane
  capture_delay: 0.1     # Seconds to wait before capturing output

  # Command injection settings
  text_enter_delay: 0.1  # Delay between text and Enter key (seconds)

  # Session management
  kill_timeout: 2        # Seconds to wait after killing session

logging:
  # Logging configuration
  level: "DEBUG"          # DEBUG, INFO, WARNING, ERROR
  file: "logs/poc.log"   # Log file path
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  max_bytes: 10485760    # 10MB
  backup_count: 3        # Number of backup files to keep

worktree:
  # Git worktree configuration for multi-instance testing
  main_path: "/home/dgray/Projects/Orchestrator"
  tmux_path: "/home/dgray/Projects/TestOrch"

test_commands:
  # Sample commands for testing
  simple:
    - "What is 2 + 2?"
    - "What is Python?"
    - "List 3 programming languages"

  context:
    - "Read file: spec.md"
    - "Summarize the main goals"
    - "What is the project about?"

  file_operations:
    - "List files in src/"
    - "Read src/controllers/tmux_controller.py"
    - "Explain the wait_for_ready method"

performance:
  # Performance measurement settings
  measure_latency: true
  log_timings: true

  # Expected performance (for validation)
  expected_command_latency_ms: 100
  expected_capture_latency_ms: 500
  expected_startup_time_s: 10

experimental:
  # Experimental features (not yet implemented)
  auto_retry_on_failure: false
  max_retries: 3
  streaming_capture: false
  parallel_sessions: false
</file>

<file path="examples/run_orchestrated_discussion.py">
#!/usr/bin/env python3
"""
Kick off a multi-AI discussion using the DevelopmentTeamOrchestrator.

This script can coordinate Claude, Gemini, Codex, and Qwen CLI sessions. You
can run all of them together or choose a specific subset for focused testing.
Each controller may attach to an existing tmux session or launch the executable
on demand, then the orchestrator runs a short discussion on the supplied topic
and prints a concise turn-by-turn summary.
"""

from __future__ import annotations

import argparse
import sys
import textwrap
import shlex
from pathlib import Path
import logging
from typing import Dict, Optional, Sequence

from src.controllers import (
    ClaudeController,
    CodexController,
    GeminiController,
    QwenController,
    TmuxController,
)
from src.controllers.session_backend import SessionSpec
from src.controllers.tmux_controller import SessionBackendError, SessionNotFoundError
from src.orchestrator import ContextManager, DevelopmentTeamOrchestrator, MessageRouter
from src.utils.config_loader import get_config

logger = logging.getLogger(__name__)

AGENT_ORDER = ("claude", "gemini", "codex", "qwen")
AGENT_DISPLAY_NAMES = {
    "claude": "Claude",
    "gemini": "Gemini",
    "codex": "Codex",
    "qwen": "Qwen",
}
_STARTUP_TIMEOUT_FALLBACKS = {
    "claude": 20,
    "gemini": 60,
    "codex": 20,
    "qwen": 25,
}

CONTROLLER_REGISTRY = {
    "claude": ClaudeController,
    "gemini": GeminiController,
    "codex": CodexController,
    "qwen": QwenController,
}


def build_controller(
    *,
    agent_key: str,
    display_name: str,
    session_name: str,
    executable: str,
    working_dir: str | None,
    auto_start: bool,
    startup_timeout: int,
    init_wait: float | None,
    bootstrap: str | None,
    kill_existing: bool,
) -> TmuxController:
    normalized_key = agent_key.lower()
    controller_cls = CONTROLLER_REGISTRY.get(normalized_key)
    if controller_cls is None:
        raise ValueError(f"No controller registered for '{agent_key}'.")

    controller = controller_cls(
        session_name=session_name,
        working_dir=working_dir,
    )

    # Work on a copy so downstream tweaks don't mutate the global config loader.
    controller.config = dict(controller.config)

    # Apply runtime overrides to the controller configuration
    controller.config["startup_timeout"] = startup_timeout
    controller.startup_timeout = startup_timeout
    controller.config["pause_on_manual_clients"] = False
    controller._pause_on_manual_clients = False  # pylint: disable=protected-access
    if init_wait is not None:
        controller.config["init_wait"] = init_wait

    exe_parts = shlex.split(executable)
    if not exe_parts:
        raise ValueError(f"No executable provided for {display_name}")

    launch_executable = exe_parts[0]
    launch_args = exe_parts[1:]

    if bootstrap:
        shell_command = f"{bootstrap} && {executable}"
        launch_executable = "bash"
        launch_args = ["-lc", shell_command]

    controller.executable = launch_executable
    controller.executable_args = tuple(launch_args)
    controller.spec = SessionSpec(
        name=controller.session_name,
        executable=launch_executable,
        working_dir=controller.working_dir,
        args=controller.executable_args,
    )

    controller.reset_output_cache()

    if kill_existing and controller.session_exists():
        if not controller.kill_session():
            raise SessionBackendError(
                f"Failed to kill existing tmux session '{session_name}' for {display_name}."
            )

    if controller.session_exists():
        controller.resume_automation(flush_pending=True)
        return controller

    if not auto_start:
        raise SessionNotFoundError(
            f"Tmux session '{session_name}' not found for {display_name}. "
            "Start the CLI manually or pass --auto-start."
        )

    controller.start()
    controller.wait_for_ready()
    return controller


def run_discussion(
    *,
    controllers: Dict[str, TmuxController],
    topic: str,
    max_turns: int,
    history_size: int,
    start_with: str,
    debug_prompts: bool = False,
    debug_prompt_chars: int = 200,
    include_history: bool = True,
    context_manager: ContextManager | None = None,
    message_router: MessageRouter | None = None,
    participants: Optional[Sequence[str]] = None,
) -> Dict[str, object]:
    orchestrator = DevelopmentTeamOrchestrator(controllers)
    if debug_prompts:
        orchestrator.set_prompt_debug(True, preview_chars=debug_prompt_chars)
    context_manager = context_manager or ContextManager(history_size=history_size)
    canonical_map = {name.lower(): name for name in controllers}

    if participants is None:
        participants = list(controllers.keys())
    else:
        normalized = []
        for participant in participants:
            normalized_name = canonical_map.get(participant.lower())
            if normalized_name is None:
                raise ValueError(f"Unknown participant '{participant}'.")
            normalized.append(normalized_name)
        participants = normalized

    start_key = canonical_map.get(start_with.lower())
    if start_key is None:
        raise ValueError(f"Unknown --start-with value '{start_with}'.")
    if start_key in participants:
        start_idx = participants.index(start_key)
        participants = participants[start_idx:] + participants[:start_idx]

    router = message_router or MessageRouter(participants, context_manager=context_manager)

    result = orchestrator.start_discussion(
        topic,
        max_turns=max_turns,
        context_manager=context_manager,
        message_router=router,
        participants=participants,
        include_history=include_history,
    )
    return {
        "conversation": result["conversation"],
        "context_manager": context_manager,
        "message_router": router,
    }


def format_turn(turn: Dict[str, object]) -> str:
    speaker = turn.get("speaker", "unknown")
    prompt = (turn.get("prompt") or "").strip()
    response = (turn.get("response") or "").strip()
    metadata = turn.get("metadata") or {}
    status_bits = []
    if metadata.get("queued"):
        status_bits.append("queued")
    if metadata.get("consensus"):
        status_bits.append("consensus")
    if metadata.get("conflict"):
        status_bits.append("conflict")
    status_suffix = f" [{' '.join(status_bits)}]" if status_bits else ""

    prompt_block = textwrap.indent(prompt, "    ")
    response_block = textwrap.indent(response, "    ") if response else "    (no response captured yet)"

    return "\n".join(
        [
            f"{turn.get('turn')}: {speaker}{status_suffix}",
            "  Prompt:",
            prompt_block,
            "  Response:",
            response_block,
        ]
    )


def parse_args(argv: list[str]) -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Run a coordinated discussion between selected AI CLIs (Claude, Gemini, Codex, Qwen)."
    )
    config = get_config()

    def default_command(agent: str) -> str:
        try:
            return config.get_executable_command(agent)
        except (KeyError, TypeError) as exc:
            parser.error(
                f"Executable for '{agent}' is not configured correctly in config.yaml: {exc}"
            )

    executable_defaults = {agent: default_command(agent) for agent in AGENT_ORDER}
    startup_defaults: Dict[str, int] = {}
    for agent in AGENT_ORDER:
        config_value = config.get(f"{agent}.startup_timeout")
        fallback = _STARTUP_TIMEOUT_FALLBACKS[agent]
        try:
            startup_defaults[agent] = int(config_value)
        except (TypeError, ValueError):
            startup_defaults[agent] = fallback
    parser.add_argument("topic", help="Topic for the discussion.")
    parser.add_argument(
        "--agents",
        nargs="+",
        choices=list(AGENT_ORDER) + ["all"],
        default=["all"],
        help=(
            "Select which agents participate. Specify one or more agent names "
            f"({', '.join(AGENT_ORDER)}) or use 'all' to include every configured agent."
        ),
    )
    parser.add_argument(
        "--max-turns",
        type=int,
        default=6,
        help="Maximum number of turns to run (default: 6).",
    )
    parser.add_argument(
        "--history-size",
        type=int,
        default=20,
        help="Number of turns to retain in the shared context (default: 20).",
    )
    parser.add_argument(
        "--simple-prompts",
        action="store_true",
        help="Skip conversation history when building prompts (smoke-test mode).",
    )
    parser.add_argument(
        "--start-with",
        choices=list(AGENT_ORDER),
        default="gemini",
        help="Which AI should speak first (default: gemini).",
    )
    parser.add_argument(
        "--auto-start",
        action="store_true",
        help="Launch tmux sessions automatically if they are not running.",
    )
    parser.add_argument(
        "--log-file",
        default=None,
        help="Optional path to write the conversation transcript and summary.",
    )
    parser.add_argument(
        "--kill-existing",
        action="store_true",
        help="Kill existing tmux sessions for the selected agents before starting.",
    )
    parser.add_argument(
        "--cleanup-after",
        action="store_true",
        help="Kill the selected agent tmux sessions after the discussion completes.",
    )
    parser.add_argument(
        "--startup-timeout",
        type=int,
        default=None,
        help="Convenience override for all --*-startup-timeout values.",
    )
    parser.add_argument(
        "--debug-prompts",
        action="store_true",
        help="Log prompt diagnostics before each dispatch.",
    )
    parser.add_argument(
        "--debug-prompt-chars",
        type=int,
        default=200,
        help="How many characters of each prompt to include in debug logs (default 200).",
    )
    parser.add_argument(
        "--group-system-prompt",
        default=None,
        help="Optional system prompt sent to every AI before the discussion begins.",
    )
    parser.add_argument(
        "--group-system-prompt-file",
        default=None,
        help="Path to a briefing file; sends 'Read @<file>' to every AI before the discussion.",
    )
    for agent in AGENT_ORDER:
        display = AGENT_DISPLAY_NAMES[agent]
        default_exec = executable_defaults[agent]
        parser.add_argument(
            f"--{agent}-session",
            default=agent,
            help=f"Tmux session name for {display} (default: {agent}).",
        )
        parser.add_argument(
            f"--{agent}-executable",
            default=default_exec,
            help=f"Executable used to start {display} (default: '{default_exec}').",
        )
        parser.add_argument(
            f"--{agent}-startup-timeout",
            type=int,
            default=startup_defaults[agent],
            help=(
                f"Seconds to wait for {display} session readiness when auto-starting "
                f"(default: {startup_defaults[agent]})."
            ),
        )
        parser.add_argument(
            f"--{agent}-init-wait",
            type=float,
            default=None,
            help=f"Seconds to pause after spawning {display} before sending the first input.",
        )
        parser.add_argument(
            f"--{agent}-bootstrap",
            default=None,
            help=f"Command to run before launching the {display} executable.",
        )
        parser.add_argument(
            f"--{agent}-cwd",
            default=None,
            help=f"Working directory for the {display} session (defaults to current directory).",
        )
        parser.add_argument(
            f"--{agent}-system-prompt",
            default=None,
            help=f"Additional system prompt sent only to {display} before the discussion.",
        )
        parser.add_argument(
            f"--{agent}-system-prompt-file",
            default=None,
            help=f"Path to a briefing file sent only to {display} (as 'Read @<file>').",
        )

    args = parser.parse_args(argv)

    override = args.startup_timeout
    if override is not None:
        for agent in AGENT_ORDER:
            field = f"{agent}_startup_timeout"
            if getattr(args, field) == parser.get_default(field):
                setattr(args, field, override)

    return args


def cleanup_controller(controller: Optional[TmuxController], label: str) -> None:
    if controller is None:
        return

    try:
        if controller.session_exists():
            if controller.kill_session():
                print(f"[cleanup] Killed {label} session '{controller.session_name}'.")
            else:
                print(
                    f"[cleanup] Unable to kill {label} session '{controller.session_name}'.",
                    file=sys.stderr,
                )
    except (SessionNotFoundError, SessionBackendError) as exc:
        print(f"[cleanup] Error while killing {label} session: {exc}", file=sys.stderr)


def main(argv: list[str]) -> int:
    args = parse_args(argv)

    if args.debug_prompts:
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        )

    include_history = not args.simple_prompts
    effective_history_size = max(1, args.history_size if include_history else 1)

    if "all" in args.agents:
        selected_agents = list(AGENT_ORDER)
    else:
        seen = set()
        selected_agents = []
        for agent in args.agents:
            if agent not in seen:
                selected_agents.append(agent)
                seen.add(agent)

    if not selected_agents:
        print("[error] No agents selected. Use --agents to specify at least one CLI.", file=sys.stderr)
        return 1

    start_with = args.start_with
    if start_with not in selected_agents:
        replacement = selected_agents[0]
        print(
            f"[info] --start-with '{start_with}' is not in the selected agent list; "
            f"switching to '{replacement}'.",
            file=sys.stderr,
        )
        start_with = replacement

    controllers: Dict[str, TmuxController] = {}

    try:
        for agent in selected_agents:
            display_name = AGENT_DISPLAY_NAMES[agent]
            controller = build_controller(
                agent_key=agent,
                display_name=display_name,
                session_name=getattr(args, f"{agent}_session"),
                executable=getattr(args, f"{agent}_executable"),
                working_dir=getattr(args, f"{agent}_cwd"),
                auto_start=args.auto_start,
                startup_timeout=getattr(args, f"{agent}_startup_timeout"),
                init_wait=getattr(args, f"{agent}_init_wait"),
                bootstrap=getattr(args, f"{agent}_bootstrap"),
                kill_existing=args.kill_existing,
            )
            controllers[agent] = controller
    except (SessionNotFoundError, SessionBackendError) as exc:
        print(f"[error] {exc}", file=sys.stderr)
        return 1

    prompt_queue: Dict[str, list[str]] = {name: [] for name in controllers}
    if args.group_system_prompt or args.group_system_prompt_file:
        group_prompt = args.group_system_prompt or f"Read @{args.group_system_prompt_file}"
        for prompts in prompt_queue.values():
            prompts.append(group_prompt)

    for ai_name, controller in controllers.items():
        if controller is None:
            continue

        prompt_arg = getattr(args, f"{ai_name}_system_prompt", None)
        file_arg = getattr(args, f"{ai_name}_system_prompt_file", None)
        if prompt_arg or file_arg:
            prompt_queue[ai_name].append(prompt_arg or f"Read @{file_arg}")

    if any(prompts for prompts in prompt_queue.values()):
        for name, controller in controllers.items():
            if controller is None:
                continue

            for prompt in prompt_queue[name]:
                logger.info("Sending pre-discussion system prompt to %s", name)
                try:
                    controller.send_command(prompt)
                    controller.wait_for_ready(timeout=30)
                except Exception as exc:  # pylint: disable=broad-except
                    print(
                        f"[error] Failed to deliver pre-discussion prompt to {name}: {exc}",
                        file=sys.stderr,
                    )
                    return 1

    try:
        result = run_discussion(
            controllers=controllers,
            topic=args.topic,
            max_turns=args.max_turns,
            history_size=effective_history_size,
            start_with=start_with,
            debug_prompts=args.debug_prompts,
            debug_prompt_chars=args.debug_prompt_chars,
            include_history=include_history,
            participants=selected_agents,
        )
    finally:
        if args.cleanup_after:
            for agent, controller in controllers.items():
                cleanup_controller(controller, AGENT_DISPLAY_NAMES.get(agent, agent))

    conversation = result["conversation"]
    context_manager: ContextManager = result["context_manager"]

    print("\n=== Conversation Transcript ===")
    for turn in conversation:
        print(format_turn(turn))
        print("-")

    print("\n=== Shared Context Summary ===")
    summary = context_manager.summarize_conversation(context_manager.history)
    print(summary or "(no summary available)")

    if args.log_file:
        log_path = Path(args.log_file)
        if log_path.suffix:
            log_path.parent.mkdir(parents=True, exist_ok=True)
        else:
            log_path.mkdir(parents=True, exist_ok=True)
            log_path = log_path / "discussion.log"

        log_lines = ["=== Conversation Transcript ==="]
        log_lines.extend(format_turn(turn) + "\n-" for turn in conversation)
        log_lines.append("\n=== Shared Context Summary ===")
        log_lines.append(summary or "(no summary available)")
        log_path.write_text("\n".join(log_lines), encoding="utf-8")
        print(f"\n[log] Conversation written to {log_path}")

    return 0


if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))
</file>

<file path="src/controllers/tmux_controller.py">
"""
Tmux Controller for AI CLI Interaction

This module provides programmatic control over AI CLI tools
(Claude Code, Gemini CLI, etc.) running in tmux sessions.
"""

import subprocess
import time
import shutil
import re
from collections import deque
from typing import Optional, List, Dict, Any, Mapping, Sequence, Deque, Tuple

from .session_backend import (
    SessionBackend,
    SessionSpec,
    SessionBackendError,
    SessionNotFoundError
)
from ..utils.exceptions import (
    SessionAlreadyExists,
    SessionDead,
    SessionUnresponsive,
    SessionStartupTimeout,
    CommandTimeout,
    ExecutableNotFound,
    TmuxNotFound,
    TmuxError
)
from ..utils.logger import get_logger
from ..utils.config_loader import get_config
from ..utils.retry import retry_with_backoff, STANDARD_RETRY
from ..utils.health_check import HealthChecker
from ..utils.auto_restart import AutoRestarter, RestartPolicy


ANSI_ESCAPE_RE = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')


class TmuxController(SessionBackend):
    """
    Controls AI CLI tools running in tmux sessions.

    AI-agnostic controller that works with any interactive CLI tool.
    AI-specific behaviors are configured via parameters.
    """

    def __init__(
        self,
        session_name: str,
        executable: str,
        working_dir: Optional[str] = None,
        ai_config: Optional[Dict[str, Any]] = None,
        executable_args: Optional[Sequence[str]] = None,
    ):
        """
        Initialize TmuxController.

        Args:
            session_name: Name of the tmux session
            executable: Command to run (e.g., "claude", "gemini")
            working_dir: Working directory (defaults to current dir)
            ai_config: AI-specific configuration dictionary with:
                - startup_timeout: Seconds to wait for startup
                - response_timeout: Max seconds for responses
                - ready_check_interval: Seconds between ready checks
                - ready_stable_checks: Consecutive stable checks needed
                - ready_indicators: List of patterns indicating ready state
        """
        # Resolve working directory
        resolved_working_dir = working_dir or subprocess.check_output(
            ["pwd"], text=True
        ).strip()

        # Create SessionSpec and initialize parent
        exec_args = tuple(executable_args or ())

        spec = SessionSpec(
            name=session_name,
            executable=executable,
            working_dir=resolved_working_dir,
            args=exec_args
        )
        super().__init__(spec)

        # Maintain backward compatibility with direct attribute access
        self.session_name = spec.name
        self.executable = spec.executable
        self.working_dir = spec.working_dir
        self.executable_args: Tuple[str, ...] = exec_args

        # Set up logging
        self.logger = get_logger(f"{__name__}.{session_name}")
        self.logger.info(f"Initializing TmuxController for {executable} in session {session_name}")

        # AI-specific configuration with defaults
        self.config = ai_config or {}
        self.startup_timeout = self.config.get('startup_timeout', 10)
        self.response_timeout = self.config.get('response_timeout', 30)
        self.ready_check_interval = self.config.get('ready_check_interval', 0.5)
        self.ready_stable_checks = self.config.get('ready_stable_checks', 3)
        self.ready_indicators = self.config.get('ready_indicators', [])
        self.loading_indicators = self.config.get('loading_indicators', [])
        self.loading_indicator_settle_time = float(self.config.get('loading_indicator_settle_time', 1.0))
        self.response_complete_markers = self.config.get('response_complete_markers', [])
        self.submit_key = self.config.get('submit_key', 'Enter')
        self.text_enter_delay = float(self.config.get('text_enter_delay', 0.1))
        self.post_text_delay = float(self.config.get('post_text_delay', 0.0))
        fallback_keys = self.config.get('submit_fallback_keys', ())
        if isinstance(fallback_keys, str):
            fallback_keys = [fallback_keys]
        self.submit_fallback_keys = tuple(str(key).strip() for key in fallback_keys if key)
        self.submit_retry_delay = float(self.config.get('submit_retry_delay', 0.0))
        ready_delay_config = self.config.get('ready_stabilization_delay')
        if ready_delay_config is None:
            self.ready_stabilization_delay = 2.0 if self.executable == "gemini" else 1.0
            ready_delay_explicit = False
        else:
            self.ready_stabilization_delay = float(ready_delay_config)
            ready_delay_explicit = True
        self._strip_ansi_for_markers = bool(self.config.get('strip_ansi_for_indicators', True))
        self.debug_wait_logging = bool(self.config.get('debug_wait_logging', False))
        if self.post_text_delay > 0:
            self.logger.info(
                "Configured post_text_delay=%.3fs (text_enter_delay=%.3fs)",
                self.post_text_delay,
                self.text_enter_delay,
            )
        if ready_delay_explicit and self.ready_stabilization_delay >= 0:
            self.logger.info(
                "Configured ready_stabilization_delay=%.3fs for executable '%s'",
                self.ready_stabilization_delay,
                self.executable,
            )
        if self._strip_ansi_for_markers:
            self.logger.debug("ANSI stripping enabled for indicator detection")
        self._pause_on_manual_clients = bool(self.config.get('pause_on_manual_clients', True))

        # Verify environment on initialization
        self._verify_environment()

        # Initialize health checker
        self.health_checker = HealthChecker(
            check_interval=self.config.get('health_check_interval', 30.0),
            response_timeout=self.config.get('health_check_timeout', 5.0),
            max_failed_checks=self.config.get('max_failed_health_checks', 3)
        )

        # Initialize auto-restarter
        restart_policy_str = self.config.get('restart_policy', 'on_failure')
        try:
            restart_policy = RestartPolicy(restart_policy_str)
        except ValueError:
            self.logger.warning(f"Invalid restart_policy '{restart_policy_str}', using ON_FAILURE")
            restart_policy = RestartPolicy.ON_FAILURE

        self.auto_restarter = AutoRestarter(
            policy=restart_policy,
            max_restart_attempts=self.config.get('max_restart_attempts', 3),
            restart_window=self.config.get('restart_window', 300.0),
            initial_backoff=self.config.get('restart_initial_backoff', 5.0),
            max_backoff=self.config.get('restart_max_backoff', 60.0)
        )

        # Automation/manual takeover state
        self._automation_paused: bool = False
        self._automation_pause_reason: Optional[str] = None
        self._manual_clients: Sequence[str] = []
        self._pending_commands: Deque[Tuple[str, bool]] = deque()
        self._last_output_lines: List[str] = []

    def _verify_environment(self):
        """
        Verify that required executables are available.

        Raises:
            TmuxNotFound: If tmux is not installed
            ExecutableNotFound: If AI executable is not in PATH
        """
        # Check tmux
        if not shutil.which('tmux'):
            self.logger.error("tmux not found in PATH")
            raise TmuxNotFound("tmux is not installed or not in PATH")

        # Check AI executable
        if not shutil.which(self.executable):
            self.logger.error(f"Executable '{self.executable}' not found in PATH")
            raise ExecutableNotFound(self.executable)

        self.logger.debug("Environment verification passed")

    @retry_with_backoff(max_attempts=2, initial_delay=0.5, exceptions=(TmuxError,))
    def _run_tmux_command(self, args: List[str]) -> subprocess.CompletedProcess:
        """
        Run a tmux command with error handling and automatic retry.

        Args:
            args: Command arguments to pass to tmux

        Returns:
            CompletedProcess result

        Raises:
            TmuxError: If tmux command fails unexpectedly after retries
        """
        cmd = ["tmux"] + args
        try:
            result = subprocess.run(cmd, capture_output=True, text=True)

            # Log tmux errors (but don't raise for expected failures like has-session)
            if result.returncode != 0 and result.stderr:
                self.logger.debug(f"tmux command returned {result.returncode}: {' '.join(args)}")
                self.logger.debug(f"stderr: {result.stderr.strip()}")

            return result
        except Exception as e:
            self.logger.error(f"Failed to run tmux command: {' '.join(args)}")
            self.logger.error(f"Error: {e}")
            raise TmuxError(f"Failed to execute tmux command: {e}", command=cmd)

    def session_exists(self) -> bool:
        """
        Check if the tmux session exists.

        Returns:
            True if session exists, False otherwise
        """
        result = self._run_tmux_command(["has-session", "-t", self.session_name])
        return result.returncode == 0

    # ========================================================================
    # Automation / Manual Takeover Helpers
    # ========================================================================

    @property
    def automation_paused(self) -> bool:
        """Return True when automation is currently paused."""
        return self._automation_paused

    @property
    def automation_pause_reason(self) -> Optional[str]:
        """Reason describing why automation is paused (if any)."""
        return self._automation_pause_reason

    @property
    def manual_clients(self) -> Sequence[str]:
        """Return the most recently observed manual clients."""
        return self._manual_clients

    @property
    def pending_command_count(self) -> int:
        """Return the number of queued commands awaiting automation resume."""
        return len(self._pending_commands)

    def get_pending_commands(self) -> List[Tuple[str, bool]]:
        """Return a snapshot of queued commands."""
        return list(self._pending_commands)

    def pause_automation(self, reason: str = "manual") -> None:
        """Pause automation explicitly (commands will be queued)."""
        self._set_automation_paused(True, reason=reason, flush_pending=False)

    def resume_automation(self, flush_pending: bool = True) -> None:
        """
        Resume automation (optionally flushing any queued commands).

        Args:
            flush_pending: If True, execute queued commands after resuming.
        """
        self._set_automation_paused(False, flush_pending=flush_pending)

    def _send_literal_text(self, text: str) -> None:
        """
        Send text to tmux character-by-character in manageable chunks.

        Using tmux's literal mode ensures punctuation (e.g., apostrophes) is preserved.
        """
        if not text:
            return

        chunk_size = 100
        for idx in range(0, len(text), chunk_size):
            chunk = text[idx : idx + chunk_size]
            result = self._run_tmux_command([
                "send-keys", "-t", self.session_name, "-l", "--", chunk
            ])
            if result.returncode != 0:
                raise TmuxError(
                    f"Failed to send literal chunk: {result.stderr}",
                    command=["send-keys", "-l"],
                    return_code=result.returncode,
                )
    def _set_automation_paused(
        self,
        paused: bool,
        *,
        reason: Optional[str] = None,
        flush_pending: bool = True
    ) -> None:
        """
        Internal helper for toggling automation state.
        """
        if paused:
            if not self._automation_paused:
                self.logger.info(f"Pausing automation (reason: {reason})")
            self._automation_paused = True
            self._automation_pause_reason = reason
        else:
            if self._automation_paused:
                self.logger.info("Resuming automation")
            self._automation_paused = False
            self._automation_pause_reason = None
            if flush_pending:
                self._drain_pending_commands()

    def _update_manual_control_state(self) -> None:
        """
        Inspect tmux clients and pause/resume automation as appropriate.
        """
        try:
            clients = self.list_clients()
        except SessionNotFoundError:
            self._manual_clients = []
            return
        except SessionBackendError as exc:
            self.logger.debug(f"Failed to list clients for manual control state: {exc}")
            return

        previous_clients = list(self._manual_clients)
        self._manual_clients = clients

        if not self._pause_on_manual_clients:
            return

        if clients:
            self._set_automation_paused(True, reason="manual-attach", flush_pending=False)
        elif (
            previous_clients
            and self._automation_paused
            and self._automation_pause_reason == "manual-attach"
        ):
            self._set_automation_paused(False, flush_pending=True)

    def _enqueue_command(self, command: str, submit: bool) -> None:
        """Queue a command to be replayed once automation resumes."""
        self._pending_commands.append((command, submit))
        self.logger.info(
            "Queued command due to automation pause "
            f"(pending={len(self._pending_commands)})"
        )

    def _drain_pending_commands(self) -> None:
        """
        Dispatch queued commands now that automation has resumed.
        """
        if not self._pending_commands:
            return

        self.logger.info(f"Draining {len(self._pending_commands)} queued command(s)")
        while self._pending_commands and not self._automation_paused:
            command, submit = self._pending_commands.popleft()
            try:
                self._send_command_internal(command, submit)
            except Exception as exc:  # noqa: BLE001 - log and requeue
                self.logger.error(
                    "Failed to flush queued command; leaving in queue",
                    exc_info=exc
                )
                self._pending_commands.appendleft((command, submit))
                break

    def _send_command_internal(self, command: str, submit: bool) -> bool:
        """
        Core implementation shared by send_command() and the queue flusher.

        Returns:
            True if the command was dispatched successfully.
        """
        if not self.session_exists():
            self.logger.error(f"Cannot send command - session '{self.session_name}' does not exist")
            raise SessionDead(f"Session '{self.session_name}' does not exist")

        self._snapshot_output_state()

        text_to_send = command.replace("\r\n", "\n")
        if "\n" in text_to_send:
            # Avoid premature submission in CLIs that treat literal newlines as Enter
            self.logger.debug("Normalizing multiline command for tmux send-keys")
        text_to_send = " ".join(filter(None, text_to_send.splitlines()))

        self._send_literal_text(text_to_send)

        if self.post_text_delay > 0:
            self.logger.info(
                "Sleeping %.3fs between literal send and submit",
                self.post_text_delay,
            )
            time.sleep(self.post_text_delay)

        if submit:
            if self.text_enter_delay > 0:
                self.logger.info(
                    "Sleeping %.3fs before sending submit key '%s'",
                    self.text_enter_delay,
                    self.submit_key,
                )
                time.sleep(self.text_enter_delay)
            else:
                self.logger.info("Sending submit key '%s' immediately", self.submit_key)

            result = self._run_tmux_command([
                "send-keys", "-t", self.session_name, self.submit_key
            ])
            stderr = result.stderr.strip() if result.stderr else ""
            log_suffix = f" (stderr: {stderr})" if stderr else ""
            self.logger.info(
                "Submit key '%s' send-keys returned %s%s",
                self.submit_key,
                result.returncode,
                log_suffix,
            )

            if result.returncode != 0:
                self.logger.error(f"Failed to submit command: {result.stderr}")
                raise TmuxError(
                    f"Failed to submit command: {result.stderr}",
                    command=["send-keys", "Enter"],
                    return_code=result.returncode
                )

            if self.submit_key and self.submit_key != "Enter":
                fallback = self._run_tmux_command([
                    "send-keys", "-t", self.session_name, "Enter"
                ])
                fallback_stderr = fallback.stderr.strip() if fallback.stderr else ""
                fallback_suffix = (
                    f" (stderr: {fallback_stderr})" if fallback_stderr else ""
                )
                self.logger.info(
                    "Fallback Enter send-keys returned %s%s",
                    fallback.returncode,
                    fallback_suffix,
                )
                if fallback.returncode != 0:
                    self.logger.warning(
                        "Fallback Enter send failed: %s",
                        fallback.stderr.strip() if fallback.stderr else "unknown",
                    )

            if self.submit_fallback_keys:
                self._trigger_fallback_submit_if_needed()

        self.logger.debug("Command sent successfully")
        return True

    def _snapshot_output_state(self) -> None:
        """
        Cache the current pane contents so subsequent output deltas only include new text.
        """
        try:
            raw_output = self.capture_output()
        except SessionBackendError:
            self._last_output_lines = []
            return

        self._last_output_lines = raw_output.splitlines()

    def _submission_in_progress(self) -> bool:
        """
        Detect whether the CLI has started processing the previously submitted command.

        We treat the presence of any configured loading indicator as evidence that the
        command was accepted and is currently running.
        """
        if not self.loading_indicators:
            return False
        if not self.session_exists():
            return False

        try:
            output = self.capture_output()
        except SessionBackendError:
            return False

        tail_text = "\n".join(self._tail_lines(output, limit=20))
        sanitized_tail = self._indicator_text(tail_text)
        return any(
            indicator and indicator in sanitized_tail
            for indicator in self.loading_indicators
        )

    def _trigger_fallback_submit_if_needed(self) -> None:
        """
        Send additional submit keys when the primary submit sequence appears to stall.
        """
        if not self.submit_fallback_keys:
            return

        delay = max(0.0, self.submit_retry_delay)
        if delay:
            time.sleep(delay)

        if self._submission_in_progress():
            self.logger.debug("Submission in progress; fallback submit keys not required")
            return

        for key in self.submit_fallback_keys:
            self.logger.warning(
                "Primary submit key did not trigger processing; sending fallback key '%s'",
                key,
            )
            result = self._run_tmux_command([
                "send-keys", "-t", self.session_name, key
            ])
            stderr = result.stderr.strip() if result.stderr else ""
            suffix = f" (stderr: {stderr})" if stderr else ""
            self.logger.info(
                "Fallback submit key '%s' send-keys returned %s%s",
                key,
                result.returncode,
                suffix,
            )

            if result.returncode != 0:
                continue

            post_delay = delay if delay > 0 else 0.1
            if post_delay > 0:
                time.sleep(post_delay)

            if self._submission_in_progress():
                break

    # ========================================================================
    # SessionBackend Interface Implementation
    # ========================================================================

    def start(self) -> None:
        """
        Launch the CLI process according to the session specification.

        This is the SessionBackend interface method. Calls start_session() internally.

        Raises:
            SessionBackendError: If the session fails to start.
        """
        try:
            self.start_session(auto_confirm_trust=True)
        except (SessionAlreadyExists, SessionStartupTimeout, TmuxError) as e:
            raise SessionBackendError(f"Failed to start session: {e}") from e

    def send_text(self, text: str) -> None:
        """
        Inject literal text into the session input buffer without submitting.

        Raises:
            SessionNotFoundError: If the session does not exist.
            SessionBackendError: If the backend cannot deliver the text.
        """
        if not self.session_exists():
            raise SessionNotFoundError(f"Session '{self.session_name}' does not exist")

        try:
            normalized = text.replace("\r\n", "\n")
            normalized = " ".join(filter(None, normalized.splitlines()))
            self._send_literal_text(normalized)
        except TmuxError as e:
            raise SessionBackendError(f"Failed to send text: {e}") from e

    def send_enter(self) -> None:
        """
        Submit the current line (send Enter key).

        Raises:
            SessionNotFoundError: If the session does not exist.
            SessionBackendError: If the backend cannot deliver the keystroke.
        """
        if not self.session_exists():
            raise SessionNotFoundError(f"Session '{self.session_name}' does not exist")

        try:
            time.sleep(self.text_enter_delay)  # Brief pause before Enter
            result = self._run_tmux_command([
                "send-keys", "-t", self.session_name, self.submit_key
            ])
            if result.returncode != 0:
                raise SessionBackendError(f"Failed to send Enter: {result.stderr}")
            if self.submit_key and self.submit_key != "Enter":
                fallback = self._run_tmux_command([
                    "send-keys", "-t", self.session_name, "Enter"
                ])
                if fallback.returncode != 0:
                    self.logger.debug(
                        "Fallback Enter send failed in send_enter: %s",
                        fallback.stderr.strip() if fallback.stderr else "unknown",
                    )
            if self.submit_fallback_keys:
                self._trigger_fallback_submit_if_needed()
        except TmuxError as e:
            raise SessionBackendError(f"Failed to send Enter: {e}") from e

    def send_ctrl_c(self) -> None:
        """
        Interrupt the current operation (Ctrl+C equivalent).

        Raises:
            SessionNotFoundError: If the session does not exist.
            SessionBackendError: If the backend cannot deliver the signal.
        """
        if not self.session_exists():
            raise SessionNotFoundError(f"Session '{self.session_name}' does not exist")

        try:
            result = self._run_tmux_command([
                "send-keys", "-t", self.session_name, "C-c"
            ])
            if result.returncode != 0:
                raise SessionBackendError(f"Failed to send Ctrl+C: {result.stderr}")
        except TmuxError as e:
            raise SessionBackendError(f"Failed to send Ctrl+C: {e}") from e

    def capture_output(
        self,
        *,
        start_line: Optional[int] = None,
        lines: Optional[int] = None,
    ) -> str:
        """
        Capture text from the session's visible buffer.

        Args:
            start_line: Starting line offset (tmux semantics: 0 = top of buffer,
                negative values = offset from top). If omitted, captures visible pane.
            lines: Number of lines to include (not used in tmux implementation,
                controlled by tmux's default capture window).

        Returns:
            Captured output as a single string.

        Raises:
            SessionNotFoundError: If the session does not exist.
            SessionBackendError: If the backend cannot capture output.

        Note:
            Tmux's -S flag uses top-relative indexing where 0 is the first line
            in the scrollback. Use negative values to offset from the top.
        """
        if not self.session_exists():
            raise SessionNotFoundError(f"Session '{self.session_name}' does not exist")

        try:
            args = ["capture-pane", "-t", self.session_name, "-p"]
            if start_line is not None:
                args.extend(["-S", str(start_line)])
            result = self._run_tmux_command(args)
            return result.stdout
        except TmuxError as e:
            raise SessionBackendError(f"Failed to capture output: {e}") from e

    def capture_scrollback(self) -> str:
        """
        Capture the full scrollback buffer for post-mortem analysis.

        Returns:
            The complete scrollback as a single string.

        Raises:
            SessionNotFoundError: If the session does not exist.
            SessionBackendError: If the backend cannot capture output.
        """
        if not self.session_exists():
            raise SessionNotFoundError(f"Session '{self.session_name}' does not exist")

        try:
            result = self._run_tmux_command([
                "capture-pane", "-t", self.session_name, "-p", "-S", "-"
            ])
            return result.stdout
        except TmuxError as e:
            raise SessionBackendError(f"Failed to capture scrollback: {e}") from e

    def list_clients(self) -> Sequence[str]:
        """
        Enumerate active client connections (for manual takeover detection).

        Returns:
            A sequence of client identifiers.

        Raises:
            SessionNotFoundError: If the session does not exist.
            SessionBackendError: If the backend cannot list clients.
        """
        if not self.session_exists():
            raise SessionNotFoundError(f"Session '{self.session_name}' does not exist")

        try:
            result = self._run_tmux_command([
                "list-clients", "-t", self.session_name
            ])
            if result.returncode == 0 and result.stdout.strip():
                return [line.strip() for line in result.stdout.strip().split('\n')]
            return []
        except TmuxError as e:
            raise SessionBackendError(f"Failed to list clients: {e}") from e

    def attach(self, read_only: bool = False) -> None:
        """
        Attach the current terminal to the session for manual observation.

        Args:
            read_only: If True, attach in read-only mode.

        Raises:
            SessionNotFoundError: If the session does not exist.
            SessionBackendError: If attachment fails.
        """
        if not self.session_exists():
            raise SessionNotFoundError(f"Session '{self.session_name}' does not exist")

        try:
            args = ["attach-session", "-t", self.session_name]
            if read_only:
                args.append("-r")
            if self._pause_on_manual_clients:
                # Preemptively pause automation before handing control to a human
                self.pause_automation(reason="manual-attach")
            # This will block and take over the terminal
            subprocess.run(["tmux"] + args, check=True)
        except subprocess.CalledProcessError as e:
            raise SessionBackendError(f"Failed to attach: {e}") from e
        finally:
            # Re-evaluate client list on detach to resume automation as needed
            self._update_manual_control_state()

    def kill(self) -> None:
        """
        Terminate the underlying session.

        Raises:
            SessionNotFoundError: If no session exists to terminate.
        """
        if not self.session_exists():
            raise SessionNotFoundError(f"Session '{self.session_name}' does not exist")

        try:
            result = self._run_tmux_command([
                "kill-session", "-t", self.session_name
            ])
            if result.returncode != 0:
                raise SessionBackendError(f"Failed to kill session: {result.stderr}")
        except TmuxError as e:
            raise SessionBackendError(f"Failed to kill session: {e}") from e

    def get_status(self) -> Mapping[str, object]:
        """
        Return backend-specific status information for debugging.

        Overrides base implementation to include health and restart stats.
        """
        return {
            "session": self.spec.name,
            "exists": self.session_exists(),
            "working_dir": self.spec.working_dir,
            "executable": self.spec.executable,
            "automation": {
                "paused": self._automation_paused,
                "reason": self._automation_pause_reason,
                "pending_commands": self.pending_command_count,
                "manual_clients": list(self._manual_clients),
            },
            "health": self.get_health_stats(),
            "restart": self.get_restart_stats()
        }

    # ========================================================================
    # Legacy Methods (maintain backward compatibility)
    # ========================================================================

    def start_session(self, auto_confirm_trust: bool = True) -> bool:
        """
        Start AI CLI in a new tmux session.

        Args:
            auto_confirm_trust: Automatically confirm trust prompt (for Claude/Gemini)

        Returns:
            True if session started successfully

        Raises:
            SessionAlreadyExists: If session with this name already exists
            SessionStartupTimeout: If session fails to become ready in time
        """
        self.logger.info(f"Starting session '{self.session_name}'")

        if self.session_exists():
            self.logger.error(f"Session '{self.session_name}' already exists")
            raise SessionAlreadyExists(f"Session '{self.session_name}' already exists")

        tmux_defaults = {}
        try:
            tmux_defaults = get_config().get_section("tmux") or {}
        except Exception:  # pragma: no cover - config loader errors bubble later
            tmux_defaults = {}

        pane_width = self.config.get('pane_width')
        if pane_width is None:
            pane_width = tmux_defaults.get('default_pane_width')
        pane_height = self.config.get('pane_height')
        if pane_height is None:
            pane_height = tmux_defaults.get('default_pane_height')

        def _normalize_dimension(value: Any) -> Optional[int]:
            if value is None:
                return None
            try:
                numeric = int(value)
            except (TypeError, ValueError):
                return None
            return numeric if numeric > 0 else None

        pane_width_int = _normalize_dimension(pane_width) or 200
        pane_height_int = _normalize_dimension(pane_height) or 50

        # Create detached tmux session with AI executable
        self.logger.debug(
            "Creating tmux session with executable: %s (pane %dx%d)",
            self.executable,
            pane_width_int,
            pane_height_int,
        )
        command = [
            "new-session",
            "-d",  # Detached
            "-s", self.session_name,  # Session name
            "-c", self.working_dir,  # Working directory
            "-x", str(pane_width_int),
            "-y", str(pane_height_int),
            self.executable,  # Command to run (claude, gemini, etc.)
            *self.executable_args,
        ]
        result = self._run_tmux_command(command)

        if result.returncode != 0:
            self.logger.error(f"Failed to create tmux session: {result.stderr}")
            raise TmuxError(
                f"Failed to start session: {result.stderr}",
                command=["new-session"],
                return_code=result.returncode
            )

        # Wait for AI to start (brief initial wait for process to spawn)
        init_wait = self.config.get('init_wait', 3)
        self.logger.debug(f"Waiting {init_wait}s for AI process to spawn")
        time.sleep(init_wait)

        # Auto-confirm trust prompt if requested
        if auto_confirm_trust:
            self.logger.debug("Auto-confirming trust prompt")
            # Press Enter to confirm "Yes, proceed" (works for Claude/Gemini)
            self._run_tmux_command([
                "send-keys", "-t", self.session_name, "Enter"
            ])
            # Brief wait for Enter to be processed
            time.sleep(1)

        # Wait for AI to be fully ready (detect ready indicators)
        self.logger.debug("Waiting for AI to be fully ready...")
        if not self.wait_for_startup(timeout=self.startup_timeout):
            self.logger.error("AI failed to show ready indicators within timeout")
            raise SessionStartupTimeout(f"Session failed to be ready within {self.startup_timeout}s")

        # Stabilization delay after detecting ready indicator
        # Ensures input buffer is fully initialized and ready for first command
        # Critical for Gemini which can show prompt before buffer is ready
        stabilization_delay = max(0.0, float(self.ready_stabilization_delay))
        if stabilization_delay > 0:
            self.logger.debug(
                "Ready indicator found, allowing input buffer to stabilize (%.3fs)...",
                stabilization_delay,
            )
            time.sleep(stabilization_delay)
        else:
            self.logger.debug("Ready indicator found; no additional stabilization delay configured")

        # Verify session is actually ready
        if not self.session_exists():
            self.logger.error("Session creation appeared to succeed but session doesn't exist")
            raise SessionStartupTimeout("Session failed to start properly")

        self.logger.info(f"Session '{self.session_name}' started successfully and ready")
        return True

    @retry_with_backoff(max_attempts=3, initial_delay=1.0, exceptions=(TmuxError,))
    def send_command(self, command: str, submit: bool = True) -> bool:
        """
        Send a command to AI CLI with automatic retry on transient failures.

        CRITICAL: Text and Enter must be sent separately to avoid multi-line input.

        Args:
            command: The text command to send
            submit: If True, send Enter to submit the command

        Returns:
            True if command sent successfully, False if it was queued due to
            automation being paused.

        Raises:
            SessionDead: If session no longer exists (not retried)
            TmuxError: If command fails after retries
        """
        self.logger.info(f"Sending command: {command[:50]}{'...' if len(command) > 50 else ''}")

        self._update_manual_control_state()
        if self._automation_paused:
            pause_reason = self._automation_pause_reason or "unknown"
            self.logger.warning(
                "Automation currently paused (reason: %s); queueing command",
                pause_reason
            )
            self._enqueue_command(command, submit)
            return False

        try:
            return self._send_command_internal(command, submit)
        except SessionDead:
            raise
        except TmuxError:
            raise

    def wait_for_startup(self, timeout: Optional[int] = None) -> bool:
        """
        Wait until AI has fully started and is ready for first input.

        Looks for startup ready indicators AND ensures no loading indicators present.
        This is different from wait_for_ready() which waits for response completion.

        Args:
            timeout: Maximum seconds to wait (uses startup_timeout from config if not specified)

        Returns:
            True if startup indicators detected and no loading indicators, False if timeout
        """
        if not self.session_exists():
            return False

        timeout = timeout or self.startup_timeout
        check_interval = 0.5
        start_time = time.time()

        self.logger.debug(f"Waiting for startup ready indicators: {self.ready_indicators}")
        if self.loading_indicators:
            self.logger.debug(f"Will check for absence of loading indicators: {self.loading_indicators}")

        while (time.time() - start_time) < timeout:
            output = self.capture_output()
            search_output = self._indicator_text(output)

            # Check for AI-specific ready indicators
            if self.ready_indicators:
                self.logger.debug(f"Checking for indicators in {len(output)} chars of output")

                # First check if ready indicator is present
                ready_indicator_found = False
                for indicator in self.ready_indicators:
                    if indicator and indicator in search_output:
                        ready_indicator_found = True
                        self.logger.debug(f"Startup ready indicator found: '{indicator}'")
                        break

                if ready_indicator_found:
                    # Now check that no loading indicators are present
                    if self.loading_indicators:
                        has_loading = any(
                            loading_ind and loading_ind in search_output
                            for loading_ind in self.loading_indicators
                        )
                        if has_loading:
                            self.logger.debug("Ready indicator found but loading indicator still present, waiting...")
                            time.sleep(check_interval)
                            continue

                    # Ready indicator present and no loading indicators
                    self.logger.debug("Startup complete: ready indicator found, no loading indicators")
                    return True
                else:
                    self.logger.debug(f"Indicators not found. Looking for: {self.ready_indicators}")
            else:
                # Fallback: if no indicators configured, just check for any output
                if len(output.strip()) > 50:  # Arbitrary threshold for "has started"
                    return True

            time.sleep(check_interval)

        self.logger.warning(f"Startup timeout after {timeout}s")
        return False

    def get_last_output(self, *, tail_lines: int = 50) -> str:
        """
        Return newly captured output since the previous snapshot.

        Args:
            tail_lines: Maximum number of trailing lines to return if no delta
                can be computed (fallback for buffer resets).
        """
        if not self.session_exists():
            return ""

        try:
            raw_output = self.capture_output()
        except SessionBackendError:
            return ""

        if not raw_output:
            return ""

        current_lines = raw_output.splitlines()
        delta: List[str]

        if self._last_output_lines and len(current_lines) >= len(self._last_output_lines):
            prefix_length = self._common_prefix_length(self._last_output_lines, current_lines)
            delta = current_lines[prefix_length:]
        else:
            delta = current_lines[-tail_lines:]

        self._last_output_lines = current_lines
        return "\n".join(delta).strip()

    def reset_output_cache(self) -> None:
        """Forget cached output so the next capture returns the latest pane contents."""
        self._last_output_lines = []

    @staticmethod
    def _tail_lines(output: str, limit: int = 26) -> List[str]:
        if not output:
            return []
        lines = [line.rstrip() for line in output.splitlines() if line.strip()]
        return lines[-limit:]

    @staticmethod
    def _contains_any(haystack: str, needles: Sequence[str]) -> bool:
        return any(needle and needle in haystack for needle in needles)

    def _indicator_text(self, text: str) -> str:
        if not text:
            return ""
        if self._strip_ansi_for_markers:
            return ANSI_ESCAPE_RE.sub('', text)
        return text

    def _log_wait_debug(self, message: str, *args) -> None:
        if self.debug_wait_logging:
            self.logger.debug(message, *args)

    def _is_response_ready(self, tail_lines: Sequence[str]) -> bool:
        if not tail_lines:
            return False

        sanitized = [self._indicator_text(line) for line in tail_lines]
        relevant = list(sanitized[-5:]) if len(sanitized) > 5 else list(sanitized)
        tail_text = "\n".join(relevant)

        markers_found = [marker for marker in self.response_complete_markers if marker and marker in tail_text]
        indicators_found = [indicator for indicator in self.ready_indicators if indicator and indicator in tail_text]

        ready = True
        if self.response_complete_markers and not markers_found:
            ready = False
        if self.ready_indicators and not indicators_found:
            ready = False

        if self.debug_wait_logging:
            preview = tail_text[-400:] if len(tail_text) > 400 else tail_text
            self._log_wait_debug(
                "Ready check tail preview=%r markers_found=%s indicators_found=%s -> %s",
                preview,
                markers_found,
                indicators_found,
                ready,
            )

        return ready

    @staticmethod
    def _common_prefix_length(first: Sequence[str], second: Sequence[str]) -> int:
        limit = min(len(first), len(second))
        for idx in range(limit):
            if first[idx] != second[idx]:
                return idx
        return limit

    def wait_for_ready(self, timeout: Optional[int] = None, check_interval: Optional[float] = None) -> bool:
        """
        Wait until AI is ready for next input.

        Strategy: Capture output repeatedly and wait until it stabilizes
        (no changes between captures), indicating AI has finished responding.

        Args:
            timeout: Maximum seconds to wait (uses config if not specified)
            check_interval: Seconds between checks (uses config if not specified)

        Returns:
            True if ready detected, False if timeout
        """
        if not self.session_exists():
            return False

        # Use configured values if not overridden
        timeout = timeout or self.response_timeout
        check_interval = check_interval or self.ready_check_interval
        required_stable_checks = self.ready_stable_checks

        start_time = time.time()
        previous_output = ""
        stable_count = 0
        half_timeout_warning_emitted = False
        saw_loading_indicator = False
        loading_cleared_time: Optional[float] = None
        ready_gate_released = True

        self._log_wait_debug(
            "wait_for_ready start timeout=%ss interval=%.3fs stable_checks=%d",
            timeout,
            check_interval,
            required_stable_checks,
        )

        while (time.time() - start_time) < timeout:
            elapsed = time.time() - start_time
            if (
                not half_timeout_warning_emitted
                and timeout
                and elapsed >= (timeout / 2)
            ):
                self.logger.warning(
                    "wait_for_ready has been waiting %.2fs (>=50%% of timeout %ss) for session '%s'",
                    elapsed,
                    timeout,
                    self.session_name,
                )
                half_timeout_warning_emitted = True

            current_output = self.capture_output()
            tail_lines = self._tail_lines(current_output)
            sanitized_tail_lines = [self._indicator_text(line) for line in tail_lines]

            if sanitized_tail_lines and self.loading_indicators:
                tail_window = sanitized_tail_lines[-6:] if len(sanitized_tail_lines) > 6 else sanitized_tail_lines
                tail_text = "\n".join(tail_window)
                loading_present = self._contains_any(tail_text, self.loading_indicators)
                if loading_present:
                    if loading_cleared_time is not None:
                        self._log_wait_debug(
                            "Loading indicator reappeared after %.2fs; resetting settle timer",
                            time.time() - loading_cleared_time,
                        )
                    if not saw_loading_indicator:
                        self.logger.info("wait_for_ready detected processing start for session '%s'", self.session_name)
                    saw_loading_indicator = True
                    loading_cleared_time = None
                    ready_gate_released = False
                    self._log_wait_debug("Loading indicator detected; waiting for completion")
                    stable_count = 0
                    previous_output = current_output
                    time.sleep(check_interval)
                    continue
                if saw_loading_indicator and not loading_present:
                    if loading_cleared_time is None:
                        loading_cleared_time = time.time()
                        self.logger.info(
                            "wait_for_ready detected loading indicator cleared for session '%s'",
                            self.session_name,
                        )
                    cleared_elapsed = time.time() - loading_cleared_time
                    # Allow brief settling period after indicator clears
                    settle_required = max(check_interval, self.loading_indicator_settle_time)
                    if cleared_elapsed < settle_required:
                        self._log_wait_debug(
                            "Loading indicator just cleared (%.2fs); waiting one more interval for output to settle",
                            cleared_elapsed,
                        )
                        previous_output = current_output
                        time.sleep(check_interval)
                        continue
                    ready_gate_released = True
                    self._log_wait_debug(
                        "Loading indicator cleared and settle requirement satisfied (%.2fs >= %.2fs)",
                        cleared_elapsed,
                        settle_required,
                    )

            # Check if output has stabilized (no changes)
            if current_output == previous_output:
                stable_count += 1
                elapsed = time.time() - start_time
                self._log_wait_debug(
                    "Output stable (%d/%d) after %.2fs",
                    stable_count,
                    required_stable_checks,
                    elapsed,
                )
                if (
                    stable_count >= required_stable_checks
                    and ready_gate_released
                    and self._is_response_ready(sanitized_tail_lines)
                ):
                    self._log_wait_debug("Ready confirmed after %.2fs", elapsed)
                    if saw_loading_indicator:
                        self.logger.info(
                            "wait_for_ready processed completion via stability fallback for session '%s'",
                            self.session_name,
                        )
                    return True
            else:
                if stable_count:
                    elapsed = time.time() - start_time
                    self._log_wait_debug(
                        "Output changed after %.2fs; reset stable_count (was %d)",
                        elapsed,
                        stable_count,
                    )
                stable_count = 0  # Reset if output changed

            previous_output = current_output
            time.sleep(check_interval)

        elapsed_total = time.time() - start_time
        self._log_wait_debug("wait_for_ready timed out after %.2fs", elapsed_total)
        return False  # Timeout

    def kill_session(self) -> bool:
        """
        Terminate the tmux session (legacy method for backward compatibility).

        Delegates to kill() interface method.

        Returns:
            True if session killed successfully, False otherwise
        """
        try:
            self.kill()
            return True
        except (SessionNotFoundError, SessionBackendError):
            return False

    def attach_for_manual(self, read_only: bool = False) -> None:
        """
        Attach to the session for manual interaction (legacy method).

        Delegates to attach() interface method.

        Note: This method will block until the user detaches.
        Use read_only=True to prevent accidental input.

        Args:
            read_only: If True, attach in read-only mode
        """
        try:
            self.attach(read_only=read_only)
        except (SessionNotFoundError, SessionBackendError) as e:
            print(f"Failed to attach: {e}")

    def perform_health_check(self, check_type: str = "session_exists") -> dict:
        """
        Perform health check on the session.

        Args:
            check_type: Type of health check to perform:
                - "session_exists": Basic liveness check
                - "output_responsive": Check if session produces output
                - "command_echo": Full responsiveness test with test command

        Returns:
            Dictionary with health check results

        Raises:
            ValueError: If check_type is invalid
        """
        if check_type == "session_exists":
            result = self.health_checker.check_session_exists(self.session_exists)
        elif check_type == "output_responsive":
            result = self.health_checker.check_output_responsive(
                lambda: self.capture_output(lines=50),
                min_output_length=10
            )
        elif check_type == "command_echo":
            result = self.health_checker.check_command_echo(
                send_command_func=lambda cmd: self.send_command(cmd, submit=True),
                wait_func=self.wait_for_ready,
                capture_func=self.capture_output,
                test_command="# health_check"
            )
        else:
            raise ValueError(f"Invalid check_type: {check_type}")

        return {
            "healthy": result.healthy,
            "timestamp": result.timestamp.isoformat(),
            "check_type": result.check_type,
            "details": result.details,
            "error_message": result.error_message,
            "consecutive_failures": self.health_checker.consecutive_failures,
            "is_healthy": self.health_checker.is_healthy()
        }

    def get_health_stats(self) -> dict:
        """
        Get health check statistics.

        Returns:
            Dictionary with health metrics
        """
        return self.health_checker.get_stats()

    def is_healthy(self) -> bool:
        """
        Check if session is currently considered healthy.

        Returns:
            True if session is healthy, False otherwise
        """
        return self.health_checker.is_healthy()

    def restart_session(self, reason: str = "manual", auto_confirm_trust: bool = True) -> bool:
        """
        Restart the session (kill and start fresh).

        Args:
            reason: Reason for restart (for logging)
            auto_confirm_trust: Auto-confirm trust prompt on restart

        Returns:
            True if restart succeeded, False otherwise
        """
        self.logger.info(f"Restarting session (reason: {reason})")

        # Kill existing session if it exists
        if self.session_exists():
            self.logger.debug("Killing existing session")
            self.kill_session()
            time.sleep(1)  # Brief pause to ensure cleanup

        # Start new session
        try:
            self.start_session(auto_confirm_trust=auto_confirm_trust)
            self.logger.info("Session restarted successfully")

            # Reset health checker after successful restart
            self.health_checker.reset()

            return True
        except Exception as e:
            self.logger.error(f"Failed to restart session: {e}")
            return False

    def auto_restart_if_needed(self, reason: str = "unknown") -> bool:
        """
        Automatically restart session if policy allows and conditions are met.

        Args:
            reason: Reason for potential restart

        Returns:
            True if restart was attempted and succeeded, False otherwise
        """
        def restart_func():
            return self.restart_session(reason=reason)

        return self.auto_restarter.attempt_restart(
            restart_func=restart_func,
            reason=reason,
            wait_before_restart=True
        )

    def get_restart_stats(self) -> dict:
        """
        Get auto-restart statistics.

        Returns:
            Dictionary with restart metrics
        """
        return self.auto_restarter.get_stats()
</file>

</files>
